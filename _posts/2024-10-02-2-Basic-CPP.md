---
author: Frank
beforetoc: null
categories:
    - Matemática
    - Linguagens Formais
    - Programação
description: The document explores C++20 competitive programming techniques, covering control structures, algorithms, container handling, and performance strategies.
draft: null
featured: false
image: assets/images/prog_dynamic.webp
keywords: |-
    - C++20 Competitive Programming
    - Control Structures
    - Algorithm Implementation
    - Container Manipulation
    - `std::ranges::views`
    - Parallel Execution
    - Array Handling
    - Performance Optimization
    - Standard Library Algorithms
    - Input Size Management
lastmod: 2024-10-21T20:23:43.654Z
layout: post
preview: This document covers competitive programming in C++20, discussing both basic and advanced topics like control structures, algorithms, and data manipulation. It explores features such as `std::ranges::views` and parallel execution, offering insights into efficient programming strategies and handling of complex inputs.
published: true
rating: 5
slug: journey-begins
tags:
    - Matemática
    - Linguagens Formais
    - C++ 20
    - Competitive Programming
title: C++ Here the Journey Begins
toc: true
date: 2024-10-23T18:51:39.796Z
---

This chapter explores the fundamental building blocks of C++20 that are essential for competitive programming. By understanding and mastering these concepts, programmers can write more efficient and effective code to solve complex problems.

Throughout the chapter, we'll focus on techniques for efficient input and output handling, which is critical in competitive programming when dealing with large datasets. We'll cover I/O optimizations, such as using `std::ios_base::sync_with_stdio(false)` and `std::cin.tie(nullptr)` to reduce synchronization overhead, and explore how to use `mmap` for fast file I/O.

After I/O and errors we'll deal with vectors and matrices, two data structures that are widely used in competitive programming algorithms. C++20 introduces new features, such as `std::span` and `std::ranges`, which provide additional ways to work with these data structures. We'll explore how to leverage these features to handle and process data in a competitive environment.

Next, we delve into loops, which are a core part of any C++ program. We'll look at various types of loops, from traditional `for` loops to the new range-based `for` loops in C++20. We'll also investigate how to optimize loops using techniques like early exit conditions and the `std::execution::par` execution policy for parallel execution.

By the end of this chapter, you'll have a solid understanding of the fundamental C++20 concepts and techniques that are essential for competitive programming. You'll be well-prepared to apply these skills to solve a variety of programming challenges efficiently and effectively.

## 2.1. Working with File I/O

_In competitive programming contests, especially with large datasets, programs often need to read input from big files_. In C++20, file input and output (I/O) operations are managed using classes from the `<fstream>` library. The main classes are `std::ifstream`, `std::ofstream`, and `std::fstream`. These classes serve different purposes:

- `std::ifstream`: Used for reading from files.
- `std::ofstream`: Used for writing to files.
- `std::fstream`: Used for both reading and writing to files.

![This Section Mind Map](/assets/images/FileI_OMM.webp)

_Figure 2.1.A: Working with File I/O Mind Map_{: class="legend"}

The `std::ifstream` class, allows reading data either line by line or in segments, while handling error checking and file status management.

In your code, use `std::ifstream` to open a text file and read its contents:

```cpp
std::ifstream file("path_to_file");
```

The line `std::ifstream file("path_to_file");` opens a file. It uses the file name given `path_to_file`. If the file does not open, the stream becomes invalid. Of course, you can use `std::ifstream` to provide a command-line argument to a program while it's running. As you can see in Code 2.1.A:

```cpp
#include <fstream>  // Includes the library for file input/output operations
#include <iostream> // Includes the library for input/output operations on the console
#include <string>   // Includes the string library for handling strings

int main(int argc, char* argv[]) {
    // Checks if the program received exactly one argument (filename) besides the program name
    if (argc != 2) {
        std::cerr << "Usage: " << argv[0] << " <filename>\n"; // Prints an error message with the correct usage
        return 1; // Returns 1 to indicate an error occurred
    }

    // Opens the file specified by the command-line argument for reading
    std::ifstream file(argv[1]);

    // Checks if the file was opened successfully
    if (!file.is_open()) {
        std::cerr << "Error: Could not open the file " << argv[1] << "\n"; // Prints an error message if the file couldn't be opened
        return 1; // Returns 1 to indicate an error occurred
    }

    std::string line; // Declares a string variable to store each line of the file

    // Reads the file line by line and outputs each line to the console
    std::cout << "Contents of the file:\n";
    while (std::getline(file, line)) { // Reads each line from the file into the 'line' variable
        std::cout << line << "\n"; // Prints the current line to the console
    }

    file.close(); // Closes the file after reading
    return 0; // Returns 0 to indicate successful execution
}
```

_Code 2.1.A: Reading the filename from a command-line argument_{: class="legend"}

The Code 2.1.A starts by checking the number of command-line arguments:

```cpp
if (argc != 2) {
    std::cerr << "Usage: " << argv[0] << " <filename>\n";
    return 1;
}
```

> In C++, `argc` and `argv` are used to handle command-line arguments. They are part of the parameters for the main function:
>
> ```cpp
> int main(int argc, char* argv[])
> ```
>
> `argc` stands for "argument count". It tells you how many command-line arguments were passed to the program. The count includes the program's name itself, so `argc` is always at least $1$.
>
> `argv` stands for "argument vector". It is an array of pointers to strings. Each string is a command-line argument. The first element, `argv[0]`, is always the program’s name. The other elements, `argv[1]`, `argv[2]`, and so on, are the arguments given by the user.
>
> When you run a program from the command line, you can pass additional data right after the program’s name. For example:
>
> ```shell
> ./program file.txt
> ```
>
> Here, `argc` will be $2$. `argv[0]` is `./program`, and `argv[1]` is file.txt.
>
> The command line is read by the operating system before your program starts. The system stores each space-separated word as a string. The program reads this input using `argc` and `argv`. By checking `argc`, you can make sure the user provided the correct number of arguments. `argv` lets you access and use those arguments directly inside your code.
>
> It’s a simple way to pass information when starting a program, especially useful for filenames, options, or parameters that the program needs to operate correctly.

It expects one argument besides the program name. If there is no filename, it prints a usage message and stops. Next, the program tries to open the file:

```cpp
std::ifstream file(argv[1]);
```

The line `std::ifstream file(argv[1]);` creates a file stream named `file`. It tries to open the file specified by `argv[1]`, which is the first command-line argument given by the user.

> A file stream, provided by the `<fstream>` library, creates a connection between your program and a file. It acts as a bridge for reading and writing data, while managing the file and handling errors automatically.
>
> If the file exists and can be opened, `file` is ready to read from that file. If it fails, `file` will be invalid, and nothing can be read. This line sets up a direct link between the program and the file, letting the program read the file’s content.

```cpp
if (!file.is_open()) {
    std::cerr << "Error: Could not open the file " << argv[1] << "\n";
    return 1;
}
```

`file.is_open()` checks if the file stream opened the file. If it’s open, it returns `true`. If not, it returns `false`. This helps you know if you can read or write.

> `std::cerr` prints error messages. It’s fast and shows messages right away. We also have `std::cout` prints regular output. It’s used to show results or messages to the user and `std::cin` reads input from the user. It takes what you type and gives it to the program.
>
> Use `std::cout` to show, `std::cin` to read, and `std::cerr` to warn.

```cpp
while (std::getline(file, line)) {
    std::cout << line << "\n";
}
```

`std::getline` reads one line at a time from the file and puts it in line. It starts reading at the beginning of the line and stops when it reaches the end. It looks for the newline character to know when the line ends. After reading, it moves to the next line and repeats. Each line is printed right away with `std::cout`. This loop keeps going until there are no more lines left in the file.

```cpp
file.close();
```

`file.close()` ends the link to the file. It tells the program you are finished with it. Closing keeps things tidy and safe. It frees resources and makes sure all data is saved. Always close the file when you’re done.

It then ends successfully, returning zero.

We didn’t use `std::ofstream` in the code, but it’s key to know. `std::ofstream` writes to files. It comes from `std::ostream`, which handles all output in C++.

To open a file for writing, you use it like `std::ifstream`:

```cpp
std::ofstream outFile("output.txt");
```

This line creates or opens output.txt for writing. If the file exists, it clears the old contents first. It’s ready to write new data right away.

`std::fstream` combines what `std::ifstream` and `std::ofstream` do. It lets you read from and write to the same file. It comes from `std::iostream`, which handles input and output both ways.

Here’s how you open a file for reading and writing:

```cpp
std::fstream file("data.txt", std::ios::in | std::ios::out);
```

This line opens `data.txt` for both reading and writing. The flags `std::ios::in | std::ios::out` tell the stream to allow both input and output. You can read and write without closing the file in between. Or to use files read from command line we could use:

```cpp
#include <fstream>  // Includes the library for file input/output operations
#include <iostream> // Includes the library for console input/output
#include <string>   // Includes the string library for string manipulation

int main(int argc, char* argv[]) {
    // Checks if the correct number of arguments is provided.
    // The program expects exactly one argument besides the program name.
    if (argc != 2) {
        std::cerr << "Usage: " << argv[0] << " <filename>\n"; // Prints a usage message to the error stream if arguments are incorrect.
        return 1; // Exits with an error code 1 indicating incorrect usage.
    }

    // Opens the file specified by the command-line argument for both reading and writing.
    // std::ios::in | std::ios::out allows input (reading) and output (writing).
    std::fstream file(argv[1], std::ios::in | std::ios::out);

    // Checks if the file was opened successfully.
    if (!file.is_open()) {
        std::cerr << "Error: Could not open the file " << argv[1] << "\n"; // Prints an error message if the file can't be opened.
        return 1; // Exits with an error code 1 indicating failure to open the file.
    }

    std::string line; // Declares a string variable to store each line read from the file.

    // Reads the file line by line and prints each line to the console.
    std::cout << "Contents of the file:\n";
    while (std::getline(file, line)) { // Reads each line from the file and stores it in the 'line' variable.
        std::cout << line << "\n"; // Prints the current line to the console.
    }

    // Resets the file stream state to clear any error flags (like EOF).
    file.clear(); // Clears any error flags that might have been set during reading.
    // Repositions the file pointer to the beginning of the file for further operations.
    file.seekg(0, std::ios::beg); // Moves the file's read position back to the start.

    // Writes a new line at the end of the file.
    file << "\nNew line added to the file.\n"; // Adds a new line to the file content.

    // Clears any error flags again and repositions the file pointer to the beginning.
    file.clear(); // Clears flags that may have been set after writing.
    file.seekg(0, std::ios::beg); // Moves the read position back to the beginning.

    std::cout << "\nUpdated contents of the file:\n";

    // Reads and prints the updated content of the file.
    while (std::getline(file, line)) { // Reads the file again after the new line is added.
        std::cout << line << "\n"; // Prints each updated line to the console.
    }

    file.close(); // Closes the file to release resources.
    return 0; // Returns 0 indicating successful execution.
}
```

_Code 2.1.B: Sample code to reading and writing files using command line arguments._{: class="legend"}

The Code 2.1.B shows how to opens a file for reading and writing. Here’s how it manages the reading and writing positions with the pointers. First, the program reads the file line by line:

```cpp
while (std::getline(file, line)) {
    std::cout << line << "\n";
}
```

This loop reads every line until the end. The pointer for reading (`seekg`) moves to the end of the file by the time the loop finishes. The pointer for writing (`seekp`) also ends up at the end because it follows the reading operations. This is why, when you write later, the text goes to the end. Next, the code resets the state and positions:

```cpp
file.clear(); // Clears any flags like EOF.
file.seekg(0, std::ios::beg); // Moves the read pointer to the start of the file.
```

`file.clear()` resets any error flags. `file.seekg(0, std::ios::beg)` moves only the reading pointer back to the beginning of the file. It doesn’t move the writing pointer. The write pointer remains at the end. Then, the program writes a new line:

```cpp
file << "\nNew line added to the file.\n";
```

This writes at the current write pointer position, which is still at the end. The read pointer is at the beginning, but it doesn’t affect where the writing happens. The writing pointer (`seekp`) hasn’t been moved, so it writes right where it was at the end.

Finally, the code resets the state again:

```cpp
file.clear(); // Clears flags after writing.
file.seekg(0, std::ios::beg); // Moves the read pointer back to the start again.
```

This prepares for reading the updated content from the beginning, but again, it only affects the read pointer. The write pointer is unaffected and remains where it finished writing.

In summary, the code reads to the end, clears state, and moves only the read pointer back. The write pointer stays at the end, which is why the new line is added at the end of the file, not somewhere else.

When opening files, you can set different modes using values from the `std::ios_base::openmode` enumeration. Each mode controls how the file is accessed.

`std::ios::in` opens the file for reading, which is the default for `std::ifstream`. `std::ios::out` opens it for writing, the default for `std::ofstream`. _`std::ios::app` opens the file for writing but always writes at the end without erasing the existing content_. `std::ios::ate` opens the file and moves the pointer directly to the end. `std::ios::trunc` opens the file and clears all its contents, starting fresh. `std::ios::binary` opens the file in binary mode, treating the file data as raw bytes.

### 2.1.1. Reading Lines More Efficiently

While the basic file I/O operations we've discussed provide a solid foundation, they may not be optimal when dealing with the large-scale data processing demands common in competitive programming. Consider a scenario where you need to process millions of lines from an input file - using `std::getline()` for each line, while convenient, could introduce significant performance overhead. The Figure 2.1.B shows the Reading Lines section mind map.

![This section mind map](/assets/images/ReadingLinesEfficientlyMM.webp)

_Figure 2.1.B: Reading lines Section Mind Map_{: class="legend"}

The challenge lies in the repetitive nature of line-by-line reading: each call to `std::getline()` triggers a system call, creating unnecessary overhead when dealing with large files. By implementing a custom buffering strategy, we can dramatically reduce these system calls and improve our program's performance.

By storing more data in one go, you reduce the number of I/O operations and make reading much faster. This approach minimizes the repetitive calls to the I/O functions, which is often the bottleneck in processing big text files. Let' see a example in Code 2.1.B.

```cpp
#include <iostream>   // Includes the standard input/output stream library
#include <fstream>    // Includes the file stream library
#include <vector>     // Includes the vector library for dynamic arrays
#include <string>     // Includes the string library for string manipulation
#include <sstream>    // Includes the string stream library to handle buffer splitting

int main(int argc, char* argv[]) {
    // Checks if the program received exactly one argument (filename) besides the program name
    if (argc != 2) {
        std::cerr << "Usage: " << argv[0] << " <filename>\n"; // Prints error message if arguments are incorrect
        return 1; // Returns 1 to indicate incorrect usage
    }

    // Opens the specified file in binary mode for reading
    std::ifstream file(argv[1], std::ios::in | std::ios::binary);
    // Checks if the file opened successfully
    if (!file) {
        std::cerr << "Error: Could not open the file " << argv[1] << "\n"; // Prints error message if file can't be opened
        return 1; // Returns 1 to indicate failure in opening the file
    }

    // Moves the file pointer to the end to determine the file size
    file.seekg(0, std::ios::end);
    size_t fileSize = file.tellg(); // Gets the file size in bytes
    file.seekg(0, std::ios::beg);   // Resets the file pointer to the beginning

    // Allocates a buffer to hold the entire file contents
    std::vector<char> buffer(fileSize);
    // Reads the entire file into the buffer
    file.read(buffer.data(), fileSize);

    // Pre-allocates memory for the string to avoid reallocation
    std::string data;
    data.reserve(fileSize); 
    // Copies the buffer content into the string
    data.assign(buffer.begin(), buffer.end());  

    // Creates a string stream to process lines efficiently from the buffer
    std::istringstream dataStream(data);
    std::string line;

    // Reads lines from the string stream without calling std::getline() on the file directly
    std::cout << "Contents of the file read using custom buffering:\n";
    while (std::getline(dataStream, line)) {
        std::cout << line << "\n"; // Prints each line to the console
    }

    file.close(); // Closes the file after reading
    return 0; // Returns 0 to indicate successful execution
}
```

_Code 2.1.B: How to use a buffer to make reading files more efficient._{: class="legend"}

Let's break down the most important parts of Code 2.1.B:

```cpp
std::vector<char> buffer(fileSize);
```

This line creates a buffer using `std::vector<char>`, with a size that matches `fileSize`, representing the total number of bytes in the file. The `std::vector` class manages memory allocation automatically, ensuring that the entire file can fit into the buffer. This buffer will hold all the file's data in memory, making the next operations more efficient.

```cpp
file.read(buffer.data(), fileSize);
```

The `file.read()` function loads the entire file into the buffer in a single operation, minimizing multiple read calls. It directly transfers the file’s content into a pre-allocated buffer, making the reading process faster. The `buffer.data()` method returns a pointer to the beginning of the buffer, while $fileSize$ specifies how many bytes should be read. By loading everything at once, the function reduces the need for repeated I/O operations, speeding up the overall file reading by reducing disk access.

```cpp
std::string data;
data.reserve(fileSize);
data.assign(buffer.begin(), buffer.end());
```

These lines convert the buffer into a string. The `reserve(fileSize)` function pre-allocates memory for the string, preventing unnecessary reallocations. The `assign(buffer.begin(), buffer.end())` method copies the content of the buffer into the string. Now, the raw bytes are treated as text, making it easy to process, split, or manipulate the data.

```cpp
std::istringstream dataStream(data);
std::string line;
```

This code creates an `std::istringstream` from the string. The stream treats the string like an in-memory file, allowing line-by-line reading without accessing the file again. This keeps the data in memory, ready for fast line-by-line processing.

```cpp
std::cout << "Contents of the file read using custom buffering:\n";
while (std::getline(dataStream, line)) {
    std::cout << line << "\n"; // Prints each line to the console
}
```

This loop reads each line from the in-memory stream rather than from the file. `std::getline()` operates on the string in memory, making the process fast. By avoiding additional file reads, the loop demonstrates efficient buffering and memory handling. It prints each line of the file content, showing how effective this approach is for reading and processing files in C++.

```cpp
std::cout << "Contents of the file read using custom buffering:\n";
while (std::getline(dataStream, line)) {
    std::cout << line << "\n"; // Prints each line to the console
}
```

This loop reads each line from the stream, not the file. `std::getline()` works on the string in memory, so it’s faster. No more file reads, just reading what’s already loaded. It prints each line, showing how efficient buffering and memory processing can be. This method keeps the file read quick and the processing smooth.

After this review of the input and output process through file reading and writing, we can see how these methods can be suitable for use in competitive programming. The way we read and write data will impact programming contests focused on artificial intelligence and statistics. In these cases, the problems often involve handling large volumes of data.

#### 2.1.1.1 Competitive File I/O

There are faster ways to open and handle files in C++, especially when dealing with large data sets in competitive programming. These techniques can speed up file processing.

Use `std::ios::sync_with_stdio(false);` to disable the synchronization between C++ streams and C streams (`stdio` functions). This makes input and output faster because it removes the overhead of syncing with C-style input/output.

Turn off the synchronization with `cin.tie(nullptr);`. This disconnects `cin` from `cout`, so `cout` doesn’t flush every time `cin` is used. This can save time when reading and writing a lot of data.

Use larger buffers when reading and writing to minimize the number of operations. Reading a chunk of data at once, rather than line by line, can make your program faster.

Combine `std::ios::in | std::ios::out | std::ios::binary` when opening files to read and write in binary mode, reducing the time spent on formatting operations. These tweaks make your file operations lean and quick, perfect for big data tasks.

While standard file I/O operations serve well for basic needs, they can become a bottleneck when dealing with large datasets common in competitive programming. This is where manual buffering comes into play, offering a way to significantly improve I/O performance through careful memory management[^book1].

### 2.1.2. Manual Buffering

Manual buffering addresses the overhead of repeated I/O operations by reading data in large chunks instead of small, frequent reads. This approach reduces system calls and improves overall performance, making it particularly valuable in competitive programming scenarios where every millisecond counts.

![Manual buffering section mind map](/assets/images/ManualBufferingMM.webp)

_Figure 2.1.C: Manual Buffering Mind Map_{: class="legend"}

Manual buffering speeds up file handling by reading data in large chunks instead of line by line. This cuts down the overhead of repeated I/O operations. The Code 2.1.C shows how to read the whole file into a buffer efficiently, followed by an explanation of each step.

```cpp
#include <fstream>  // Includes the library for file input/output operations.
#include <iostream> // Includes the library for input/output operations on the console.
#include <vector>   // Includes the vector library for using dynamic arrays.

int main(int argc, char* argv[]) {
    // Checks if exactly one argument (the file name) is provided besides the program name.
    if (argc != 2) {
        std::cerr << "Usage: " << argv[0] << " <file_name>\n"; // Prints usage instructions if incorrect arguments are provided.
        return 1; // Returns 1 to indicate an error in the number of arguments.
    }

    // Opens the file specified by the first command-line argument in binary mode for reading.
    std::ifstream file(argv[1], std::ios::in | std::ios::binary);
    // Checks if the file was opened successfully.
    if (!file) {
        std::cerr << "Error opening file: " << argv[1] << "\n"; // Prints an error message if the file cannot be opened.
        return 1; // Returns 1 to indicate failure in opening the file.
    }

    // Moves the file pointer to the end to determine the file size.
    file.seekg(0, std::ios::end); // Sets the file position to the end of the file.
    size_t fileSize = file.tellg(); // Uses tellg() to get the size of the file in bytes.
    file.seekg(0, std::ios::beg); // Moves the file pointer back to the beginning for reading.

    // Creates a buffer of the same size as the file to hold the file contents.
    std::vector<char> buffer(fileSize); // Allocates a vector of characters to store the entire file.

    // Reads the entire file into the buffer in one read operation.
    file.read(buffer.data(), fileSize); // Reads the file content into the buffer from start to end.

    // Processes the buffer contents.
    // Example: Prints the first 100 characters of the file or up to the file size if smaller.
    for (int i = 0; i < 100 && i < fileSize; ++i) {
        std::cout << buffer[i]; // Outputs each character to the console.
    }

    // Exits the program successfully.
    return 0;
}
```

_Code 2.1.C: Reading files using buffers._{: class="legend"}

Let’s break down the key lines that make this file reading efficient.

```cpp
file.seekg(0, std::ios::end);
```

This line moves the file pointer to the end. The function `seekg` sets where the next read starts. The $0$ means no offset, and `std::ios::end` moves the pointer straight to the end of the file. This step lets us find out the size of the file, which we need to create a buffer big enough to hold everything.

```cpp
size_t fileSize = file.tellg();
```

With the pointer at the end, `tellg()` gets the current position of the pointer, now at the file’s end. This position equals the total size of the file in bytes. We store this size in `fileSize`. Knowing this size allows us to set up a buffer that matches the file’s length exactly.

```cpp
file.seekg(0, std::ios::beg);
```

After we know the size, we move the pointer back to the start. `seekg(0, std::ios::beg)` places the pointer at the first byte of the file. Now, the file is ready to be read from the beginning.

```cpp
std::vector<char> buffer(fileSize);
```

Next, we create a buffer with `std::vector<char>` that’s as big as the file. This buffer holds the entire content of the file in memory. The vector automatically manages the memory, making it easier to handle large data. We access its data with `buffer.data()`.

```cpp
file.read(buffer.data(), fileSize);
```

Here, `file.read()` reads the whole file into the buffer. `buffer.data()` gives us the pointer to where the data will go. `fileSize` tells the program how many bytes to read. Since `fileSize` matches the file’s size, it reads everything in one go.

_Using `seekg()` to find the size and then reading everything at once cuts down on I/O operations. Instead of reading line by line or byte by byte, we grab all the data in a single action. This reduces system calls and slashes overhead, making it much faster, especially for large files_.

### 2.1.3. Using `mmap` for Faster File I/O

In competitive programming, especially in [ICPC](https://icpc.global/) contests on Unix-based systems, every optimization matters. One effective technique is using `mmap`. It’s a fast way to handle large files by mapping them directly into memory. This allows almost instant access to file content, reducing the overhead of repeated reads. The Figure 2.1.D shows `mmap`section mind map.

![mmap section mind map](/assets/images/FasterFileI_OMM.webp)

_Figure 2.1.D: Using `mmap` Mind Map._{: class="legend"}

`mmap` maps a file into your program’s memory. Once mapped, the file becomes part of the program’s memory space. You access its contents through pointers instead of read operations. It turns the file into a simple array in memory, removing the need for constant I/O calls. The Figure 2.1.E shows this concept:

![shows the concept of mmap getting data from physical devices and mapping it in virtual memory](/assets/images/mmap1.webp)

_Figure 2.1.E: `mmap` maps data from physical devices to virtual memory_{: class="legend"}

This approach is highly effective in environments like [ICPC](https://icpc.global/), where files are large, and speed is critical. However, remember that `mmap` works only on Unix-based systems. It’s not portable and won’t run on Windows. Use it when efficiency is key, but know its limitations.

Here's an example of how you can use `mmap` to read a file efficiently in C++ on a Unix-based system:

```cpp
#include <sys/mman.h>  // Includes the library for memory mapping functions
#include <fcntl.h>     // Includes the library for file control options (like open)
#include <unistd.h>    // Includes the library for POSIX operating system API (like close)
#include <sys/stat.h>  // Includes the library for obtaining file status (like fstat)
#include <iostream>    // Includes the library for input/output operations

int main(int argc, char* argv[]) {
    // Checks if exactly one argument (the file name) is provided besides the program name
    if (argc != 2) {
        std::cerr << "Usage: " << argv[0] << " <file_name>\n"; // Prints usage instructions if the argument is missing
        return 1; // Returns 1 to indicate incorrect usage
    }

    // Open the file in read-only mode
    int fd = open(argv[1], O_RDONLY);
    // Checks if the file was opened successfully
    if (fd == -1) {
        std::cerr << "Error opening file: " << argv[1] << "\n"; // Prints an error message if the file cannot be opened
        return 1; // Returns 1 to indicate failure in opening the file
    }

    // Get the size of the file using fstat
    struct stat sb; // Declares a struct to hold the file status
    if (fstat(fd, &sb) == -1) {
        std::cerr << "Error getting file size\n"; // Prints an error message if unable to get file size
        close(fd); // Closes the file descriptor since it won't be used further
        return 1; // Returns 1 to indicate failure in getting the file status
    }
    size_t fileSize = sb.st_size; // Retrieves the file size from the stat struct

    // Memory-map the file into the process’s address space
    char* fileData = (char*)mmap(nullptr, fileSize, PROT_READ, MAP_PRIVATE, fd, 0);
    // Checks if mmap failed to map the file
    if (fileData == MAP_FAILED) {
        std::cerr << "Error mapping file to memory\n"; // Prints an error message if mapping fails
        close(fd); // Closes the file descriptor since the mapping failed
        return 1; // Returns 1 to indicate failure in memory mapping
    }

    // Process the file data (example: print the first 100 characters)
    for (size_t i = 0; i < 100 && i < fileSize; ++i) {
        std::cout << fileData[i]; // Prints each character to the console up to the first 100 or file size
    }

    // Unmap the file from memory and close the file descriptor
    if (munmap(fileData, fileSize) == -1) {
        std::cerr << "Error unmapping file\n"; // Prints an error message if unmapping fails
    }
    close(fd); // Closes the file descriptor to release the resource

    return 0; // Returns 0 to indicate successful execution
}
```

_Code 2.1.D: Using mmap for faster file I/O._{: class="legend"}

The Code 2.1.D is not specific to C++20. It uses system calls and C libraries, not features of C++. Functions like `open`, `close`, `fstat`, and `mmap` are part of the Unix POSIX API, written in C. These work in C++ because C++ is compatible with C.

The libraries `<sys/mman.h>`, `<fcntl.h>`, `<unistd.h>`, and `<sys/stat.h>` are low-level C libraries used for file handling and memory mapping on Unix systems. They are not C++ libraries and are outside the C++ standard library.

In C++, especially in C++20, we have tools like `std::filesystem` that offer modern, safe ways to handle files. So while this code runs in C++, it does not use C++20 features. It’s C code running within a C++ program.

Let's to understand what is happening in Code 2.2.2.A block by block.

```cpp
int fd = open(argv[1], O_RDONLY);
```

This line opens the file in read-only mode using `open()`. The `O_RDONLY` flag specifies that the file is opened for reading only, with no writing allowed. The function returns a file descriptor (`fd`), an integer that acts as a handle for the file, allowing the system to manage file operations. Other flags include `O_WRONLY` for write-only access and `O_RDWR` for both reading and writing. You can also use `O_CREAT` to create a file if it doesn’t exist, `O_TRUNC` to truncate an existing file, and `O_APPEND` to append data to the end of the file. The file descriptor is a key element in Unix-like systems, serving as a link between the program and the file, allowing efficient I/O operations.

```cpp
if (fd == -1) {
    std::cerr << "Error opening file: " << argv[1] << "\n";
    return 1;
}
```

This block checks if the file opened. If `fd` is $-1$, it means opening failed. The reasons can be the file doesn’t exist or lacks permissions. If it fails, it prints an error and exits with code $1$.

```cpp
struct stat sb;
if (fstat(fd, &sb) == -1) {
    std::cerr << "Error getting file size\n";
    close(fd);
    return 1;
} size_t fileSize = sb.st_size;
```

The `stat` structure is predefined in C++ as part of the POSIX standard, specifically within the `<sys/stat.h>` header. It holds metadata about a file.When we call the `fstat()` function, it populates the `stat` structure with various details, such as the file size, which can be accessed using `sb.st_size`. The `stat` structure also contains other important information, like the file's last modification time, permissions, and type. In this context, we are primarily using it to determine the file size. If the `fstat()` call fails, it indicates an error occurred while retrieving the file’s information, prompting us to print an error message and close the file. The size stored in `fileSize` determines how much memory is needed to map the file.

> The `stat` structure is part of the POSIX standard and is included in the `<sys/stat.h>` header file. It is used to retrieve metadata about a file, directory, or symbolic link. In C++20, it is often utilized for low-level file operations that require detailed information about the file system objects. The `stat` structure contains several fields, each storing specific information about the file. Below is a breakdown of the most important fields:
>
> 1. `st_dev`: Type: `dev_t`, stores the `ID` of the device on which the file resides. This field is useful for identifying the specific device when working with multiple storage devices.
>
> 2. `st_ino`: Type: `ino_t`, represents the inode number. `Inodes` are unique identifiers for files within a file system for managing file metadata.
>
> 3. `st_mode`: Type: `mode_t`, indicates the file type and its permissions. The file type can be a regular file, directory, symbolic link, or other special types, while the permissions specify read, write, and execute access for the user, group, and others.
>
> 4. `st_nlink`: Type: `nlink_t`, stores the number of hard links to the file. This value helps determine how many directory entries reference the file.
>
> 5. `st_uid`: Type: `uid_t`, holds the user `ID` of the file's owner. This is useful for managing ownership and access control of files.
>
> 6. `st_gid`: Type: `gid_t`, represents the group `ID` of the file’s owner. It helps manage group-based access permissions for the file.
>
> 7. `st_rdev`: Type: `dev_t`, only applicable to special files (e.g., device files). It contains the `ID` of the device represented by the file.
>
> 8. `st_size`: Type: `off_t`, indicates the size of the file in bytes. This is one of the most commonly used fields when determining memory requirements for reading or mapping a file.
>
> 9. `st_blksize`: Type: `blksize_t`, specifies the preferred block size for efficient file I/O operations. It can be used to optimize read and write operations based on the underlying file system.
>
> 10. `st_blocks`: Type: `blkcnt_t`, represents the number of 512-byte blocks allocated to the file. This value helps estimate the physical space occupied by the file on disk.
>
> 11. `st_atime`: Type: `time_t`, stores the time of the last access. This field is updated whenever the file is read or executed.
>
> 12. `st_mtime`: Type: `time_t`, represents the time of the last modification to the file’s content. It is useful for version control and tracking changes.
>
> 13. `st_ctime`: Type: `time_t`, folds the time of the last status change. Unlike `st_mtime`, this field records changes to file metadata, such as ownership, permissions, or links.
>
>When using the `stat` structure in C++20, you typically call the `fstat()` or `stat()` functions, passing a file descriptor or a file path, respectively. The structure is then populated with file metadata, allowing you to access and manipulate the file properties based on the fields listed above.
>
>**Example usage**:
>
> ```cpp
> #include <iostream>
> #include <sys/stat.h>
> 
> int main() {
>     struct stat sb;
>     if (stat("example.txt", &sb) == 0) {
>         std::cout << "File size: " << sb.st_size << " bytes\n";
>         std::cout << "Last modified: " << sb.st_mtime << "\n";
>         std::cout << "Number of links: " << sb.st_nlink << "\n";
>         std::cout << "File permissions: " << sb.st_mode << "\n";
>     } else {
>         std::cerr << "Error retrieving file info.\n";
>     }
>     return 0;
> }
> ```

The next line in Code 2.2.2.A deals with mapping the file in memory.

```cpp
char* fileData = (char*)mmap(nullptr, fileSize, PROT_READ, MAP_PRIVATE, fd, 0);
```

This line maps the file into memory with `mmap()`. We use `nullptr` as the first argument, letting the system choose where to place the file in memory. `nullptr` means the pointer is empty; it’s a safe way to say we don’t care where it goes.

`fileSize` tells `mmap()` how much of the file to map, starting from the beginning. `PROT_READ` sets the memory as read-only. You can use `PROT_WRITE` to make it writable, `PROT_EXEC` to make it executable, or `PROT_NONE` to block access.

`MAP_PRIVATE` means any changes you make won’t affect the file. You could use `MAP_SHARED` if you want changes to be saved back to the file, or `MAP_ANONYMOUS` if you want to map memory without a file.

`fileData` becomes a pointer to the file’s data in memory. It acts like an array, making the file easy to read without constant I/O operations. You handle the file’s data directly in memory, which speeds up access and keeps things simple.

```cpp
if (fileData == MAP_FAILED) {
    std::cerr << "Error mapping file to memory\n";
    close(fd);
    return 1;
}
```

This block checks if mapping worked. If `fileData` equals `MAP_FAILED`, mapping failed, likely due to lack of permissions or memory. If it fails, it prints an error and closes the file.

```cpp
    for (size_t i = 0; i < 100 && i < fileSize; ++i) {
    std::cout << fileData[i];
}
```

This loop reads the first $100$ characters from the mapped memory. If the file is smaller, it stops at the file’s end. This is fast because it accesses the file directly in memory without extra read calls.

```cpp
if (munmap(fileData, fileSize) == -1) {
    std::cerr << "Error unmapping file\n";
}
close(fd);
```

This unmaps the file from memory with `munmap()`, freeing the memory used by the mapping. If it fails, it prints an error. The file descriptor is closed to free the resource, ensuring no leaks. This cleanup keeps the program tidy and avoids using system resources longer than needed.

So, `mmap` is fast because it maps the file directly into memory, cutting out repeated system calls. Once mapped, the file acts like an array, making it easy to work with. It’s also efficient with memory. `mmap` loads only the parts of the file you need, instead of pulling the whole file into a buffer. This is a big win when dealing with large files.

Remember, `mmap` works only on POSIX systems like Linux, macOS, and other Unix-like setups. It’s not built into Windows, which can limit where your code runs. If you need your program to work on Windows too, consider alternatives or libraries that mimic `mmap` on different platforms. In programming contests like ICPC, where the environment is controlled and often Linux, `mmap` is a good choice. But if you need your code to run everywhere, use more universal methods like `std::ifstream` or `fread`, which work across all major operating systems.

_When using `mmap`, always ensure you call `munmap()` to unmap the file when you’re done. Failing to unmap can lead to memory leaks, as the mapped memory remains reserved until the program ends. Use `munmap()` with the correct pointer and size to free up memory. Also, make sure to handle errors from `munmap()` gracefully, just as you would with `mmap()`. Proper cleanup keeps your program stable and avoids wasting system resources_.

While `mmap` provides excellent performance for direct memory access on Unix-based systems, it has limitations in terms of portability and flexibility. As applications grow more complex and need to handle multiple I/O operations simultaneously, a different approach becomes necessary. This brings us to asynchronous I/O, a technique that offers a more flexible and platform-independent solution for handling file operations efficiently.

Asynchronous I/O allows your program to initiate I/O operations without waiting for their completion, making it particularly useful when dealing with multiple files or when you need to perform other tasks while I/O operations are in progress. Unlike `mmap`, which is limited to Unix-based systems, asynchronous I/O techniques are available across different platforms and can be implemented using standard C++20 features.

Let's explore how modern C++ provides tools for asynchronous I/O through `std::future` and `std::async`, offering solutions that combine efficiency with portability.

### 2.1.4. Modern Asynchronous I/O

In competitive programming, every millisecond counts. While `mmap` is a powerful tool for direct memory access, it's limited to Unix-based systems and specific use cases. For more flexibility and non-blocking operations, asynchronous I/O with `std::future` and `std::async` C++20 offers an effective alternative. This approach allows your program to continue running while waiting for I/O operations to complete, improving overall performance.

![Just asynchronous section mind map](/assets/images/AsynchronousI_OMM.webp)

_Figure 2.1.F: Asynchronous I/O Mind Map._{: class="legend"}

Asynchronous I/O separates file reading and writing tasks from the main execution flow. Instead of waiting for an operation to finish before moving on, the program can keep running, doing other work. This is especially useful when handling large files or when the program performs multiple I/O operations simultaneously. By offloading I/O tasks, you reduce idle time and make your program more responsive.

While `mmap` provides direct memory access on Unix-based systems, its platform-specific nature can limit its use. Asynchronous I/O with `std::future` and `std::async` in C++20 offers a platform-independent alternative for handling file operations efficiently.

Asynchronous I/O operations split program execution into two parallel paths: the main thread and an I/O thread. As the main thread executes program logic, the I/O thread manages file operations in the background. This parallel execution allows the program to process data while waiting for I/O completion and utilize CPU time when it would otherwise be idle. As we can view in Figure 2.1.G.

![shows two paths one for the main thread and another for the io asynchronous thread](/assets/images/IOAsynchro.webp)

_Figure 2.1.G: Diagram of the asynchronous I/O operations showing a support threading running I/O operations._{: class="legend"}

The execution flow follows a consistent pattern. The main thread starts an asynchronous I/O operation through `std::async`, which creates a separate I/O thread for the task. The I/O thread handles the file operation while the main thread continues its work. Using `std::future`, the main thread can check the operation's status or get results when needed. The main thread only waits if it requests results before the I/O operation completes.

This approach works well in programming contests where you need to process large input files during calculations, handle multiple data streams, or maintain program responsiveness during I/O operations. The ability to continue processing while waiting for file operations helps maximize CPU usage.

There are two classes to study now: `std::future` and `std::async`.

`std::future` and `std::async` are part of the C++ Standard Library’s support for concurrency. `std::async` launches a function asynchronously, usually in a separate thread, while `std::future` is used to retrieve the result once the function completes. For I/O tasks, you can use these tools to read from or write to files in the background, keeping your main thread free for other tasks.

When your program runs asynchronously, the main thread and I/O thread each handle specific tasks. The main thread initiates I/O operations, processes other tasks, checks for completed operations, and handles results. Meanwhile, the I/O thread manages file system interactions, handles data transfer, and signals when operations complete.

This design allows programs to submit multiple I/O requests in parallel, process existing data while waiting for new data, and continue other operations without blocking. In programming contests, this means you can read input files while performing calculations or updating program state, making efficient use of available processing time.

Here’s an example of how asynchronous I/O works in practice:

```cpp
#include <iostream>    // Includes the standard input/output stream library
#include <fstream>     // Includes the file stream library for file handling
#include <future>      // Includes the library for asynchronous operations using std::future and std::async
#include <string>      // Includes the string library for string manipulation
#include <vector>      // Includes the vector library (not used directly here but commonly for dynamic arrays)

// Function to read a file asynchronously
std::string readFileAsync(const std::string& filename) {
    // Opens the file in input mode
    std::ifstream file(filename, std::ios::in);
    // Checks if the file opened successfully
    if (!file.is_open()) {
        // Throws an exception if the file cannot be opened
        throw std::runtime_error("Error opening file: " + filename);
    }

    // Reads the entire file content into a string using stream iterators
    std::string content((std::istreambuf_iterator<char>(file)), std::istreambuf_iterator<char>());
    return content; // Returns the content of the file as a string
}

int main(int argc, char* argv[]) {
    // Checks if exactly one argument (the filename) is provided besides the program name
    if (argc != 2) {
        std::cerr << "Usage: " << argv[0] << " <filename>\n"; // Prints usage instructions if the argument is missing
        return 1; // Returns 1 to indicate incorrect usage
    }

    // Launch readFileAsync asynchronously, starting it in a separate thread
    std::future<std::string> result = std::async(std::launch::async, readFileAsync, argv[1]);

    // Main thread continues to run, doing other work without waiting for the file read to complete
    std::cout << "File is being read asynchronously...\n";

    // Retrieve the result once the async task completes
    try {
        // Blocks if necessary until the async task finishes and then retrieves the file content
        std::string content = result.get();
        // Prints the first 100 characters of the file content to the console
        std::cout << "File content:\n" << content.substr(0, 100) << "...\n";
    } catch (const std::exception& e) {
        // Catches and prints any errors that occurred during the async operation
        std::cerr << "Error: " << e.what() << '\n';
    }

    return 0; // Returns 0 to indicate successful execution
}
```

_Code 2.1.E: Using asynchronous I/O in C++20 for deal with big data files_{: class="legend"}

Breaking down the code again, we will have:

```cpp
std::string readFileAsync(const std::string& filename) {
    std::ifstream file(filename, std::ios::in);
    if (!file.is_open()) {
        throw std::runtime_error("Error opening file: " + filename);
    }

    std::string content((std::istreambuf_iterator<char>(file)), std::istreambuf_iterator<char>());
    return content;
}
```

`readFileAsync` is a function that reads the entire file into a string. It opens the file and uses `std::istreambuf_iterator` to read from start to finish in one go. `std::istreambuf_iterator` is an iterator that reads raw data from the file stream and puts it directly into a string. This way, the whole file is loaded fast without multiple reads or loops.

This method is quick because it handles the file as a single block. It’s simple and avoids the overhead of reading line by line. Alternatives include reading with `std::getline()` or using a `std::vector<char>` and reading chunks into it. But `std::istreambuf_iterator` is often faster when you need the whole file at once.

```cpp
std::future<std::string> result = std::async(std::launch::async, readFileAsync, argv[1]);
```

`std::async` starts `readFileAsync` in a new thread. The flag `std::launch::async` forces the function to run right away, not waiting until you call `result.get()`. This keeps the main thread free to keep working.

```cpp
std::cout << "File is being read asynchronously...\n";
```

While the file is being read, the main thread keeps going. This lets your program handle other tasks, like updating the UI, processing data, or waiting for user input. You’re not stuck waiting for the file read to finish.

```cpp
std::string content = result.get();
```

To get the file content, use `result.get()`. This line waits only if the file reading isn’t finished yet. If it’s done, it gives you the content right away. This way, the main thread pauses only when it really needs the result. This technique is important in cases where the program needs to handle tasks beyond reading input data, like updating interfaces, logging, or managing network connections. In competitive programming, these situations are rare since most programs focus on processing input data directly. However, for real-world applications where multitasking asynchronous I/O keeps the program responsive while still handling file operations in the background.

Asynchronous I/O with `std::async` and `std::future` has clear advantages. Your program keeps running while files are being read or written. The main thread doesn’t wait. It keeps working. This reduces idle time and makes your program responsive.

It also lets your program handle many tasks at once. Reading and writing happen in the background. The main thread can do something else. This uses the full power of multi-core processors.

`std::async` and `std::future` are also simple. They fit right into the C++ Standard Library. No need for complex threading or low-level code. You can turn a blocking task into a background job with just a few lines. Your program stays efficient. Your code stays clean.

_Asynchronous I/O boosts performance but doesn’t match `mmap` for direct memory access_. It still uses standard file operations. The data has to be read into memory the usual way. This makes it slower than `mmap` for random access in large files or when you need the file to act like an array in memory.

_Unlike `mmap`, asynchronous I/O works across all major platforms: Windows, Linux, and macOS. It’s great for cross-platform development_. Real-time systems also benefit. They need quick responses and can’t afford to wait on I/O. In multitasking environments, like servers or data processing programs, asynchronous I/O shines. It handles multiple operations at once, boosting performance and keeping everything running smoothly.

We can mix asynchronous I/O and `mmap`in a Unix environment.

```cpp
#include <iostream>   // Includes the standard input/output library for console I/O
#include <fcntl.h>    // Includes file control options (for open() flags)
#include <unistd.h>   // Includes POSIX operating system API (for close(), lseek())
#include <sys/mman.h> // Includes memory mapping functions (for mmap())
#include <aio.h>      // Includes asynchronous I/O (AIO) functions
#include <cstring>    // Includes string manipulation functions (for memset())

int main() {
    // Open the file for reading only (O_RDONLY)
    // The file descriptor (fd) is used to refer to the opened file
    int fd = open("example.txt", O_RDONLY);
    if (fd == -1) { // Check if the file opening was successful
        std::cerr << "Error: Unable to open the file.\n"; // Error message if file couldn't be opened
        return 1; // Return error code 1 to indicate failure
    }

    // Determine the file size by moving the file pointer to the end
    // lseek() returns the size of the file in bytes
    off_t fileSize = lseek(fd, 0, SEEK_END);
    if (fileSize == -1) { // Check if lseek() was successful
        std::cerr << "Error: Unable to determine file size.\n"; // Error message for failure
        close(fd); // Close the file to release resources
        return 1; // Return error code 1 to indicate failure
    }
    lseek(fd, 0, SEEK_SET); // Reset the file pointer to the beginning for subsequent reads

    // Map the file into memory
    // mmap() creates a memory mapping of the file, making the file's content accessible as memory
    // Parameters:
    // - nullptr: Let the OS choose the address
    // - fileSize: Size of the mapped memory region (equal to the file size)
    // - PROT_READ: Set the protection to read-only
    // - MAP_PRIVATE: Create a private copy-on-write mapping
    // - fd: File descriptor for the file to be mapped
    // - 0: Start mapping from the beginning of the file
    void* mapped = mmap(nullptr, fileSize, PROT_READ, MAP_PRIVATE, fd, 0);
    if (mapped == MAP_FAILED) { // Check if mmap() succeeded
        std::cerr << "Error: mmap() failed.\n"; // Error message for mapping failure
        close(fd); // Close the file to release resources
        return 1; // Return error code 1 to indicate failure
    }

    // Set up the asynchronous I/O control block for reading
    // The aiocb struct defines parameters for asynchronous operations
    struct aiocb cb;
    memset(&cb, 0, sizeof(struct aiocb)); // Initialize the aiocb struct to zero
    cb.aio_fildes = fd;           // Set the file descriptor for the asynchronous operation
    cb.aio_buf = mapped;          // Set the buffer to the memory-mapped file region
    cb.aio_nbytes = fileSize;     // Set the number of bytes to read (entire file)
    cb.aio_offset = 0;            // Set the read offset to the beginning of the file

    // Initiate asynchronous read operation
    // aio_read() starts an asynchronous read, returning immediately
    if (aio_read(&cb) == -1) { // Check if aio_read() succeeded
        std::cerr << "Error: aio_read() failed.\n"; // Error message for async read failure
        munmap(mapped, fileSize); // Unmap memory if read fails
        close(fd); // Close the file to release resources
        return 1; // Return error code 1 to indicate failure
    }

    // Wait for the asynchronous read to complete
    // aio_error() returns EINPROGRESS while the operation is still ongoing
    while (aio_error(&cb) == EINPROGRESS) {
        // Can perform other tasks here while waiting for the read to complete
    }

    // Check the result of the asynchronous read
    // aio_return() returns the number of bytes read or -1 if an error occurred
    int status = aio_return(&cb);
    if (status != fileSize) { // Check if the read operation was successful
        std::cerr << "Error: Asynchronous read incomplete.\n"; // Error message if read fails
    } else {
        std::cout << "Asynchronous read complete: " << status << " bytes read.\n"; // Success message
    }

    // Clean up resources
    // Unmap the memory-mapped file region
    munmap(mapped, fileSize);
    // Close the file descriptor to release the file handle
    close(fd);
    return 0; // Return 0 to indicate successful execution
}
```

_Code 2.1.F: Mixing `mmap` and asynchronous I/O._ {: class="legend"}

`Code 2.1.F` demonstrates a combination of `mmap` and asynchronous I/O (`aio`) for handling file operations in a Unix environment. This approach leverages the strengths of both methods: the efficiency of memory mapping and the non-blocking nature of asynchronous I/O.

In this code, the file is first opened for reading, and its size is determined using `lseek()`. Next, `mmap` is used to map the file's content into memory. This technique allows direct memory access to the file’s data, making it appear as a part of the program’s address space. So, the memory-mapped region acts as a buffer for asynchronous operations, which is managed by the `aiocb` structure.

> The `aiocb` structure, short for _Asynchronous I/O Control Block_, is defined in the `<aio.h>` header and is used in POSIX-compliant systems to manage asynchronous I/O operations. It serves as a data structure that holds all the necessary information for non-blocking I/O operations, such as reading or writing files without stopping the program's execution. Each asynchronous operation uses an `aiocb` instance to specify its parameters, including the file descriptor, buffer, number of bytes, and more. Below is a detailed breakdown of the most important fields within the `aiocb` structure:
>
> 1. `aio_fildes`: Type: `int`, description: This field represents the file descriptor of the file to be read from or written to. It is used to identify the file associated with the asynchronous operation.
>
> 2. `aio_offset`: Type: `off_t`, description: Specifies the starting offset (in bytes) in the file where the read or write operation should begin, allowing random access within the file.
>
> 3. `aio_buf`: Type: `volatile void*`, description: A pointer to the buffer in memory where data will be read into (for reads) or written from (for writes). The buffer size must be sufficient to accommodate `aio_nbytes`.
>
> 4. `aio_nbytes`: Type: `size_t`, description: Indicates the number of bytes to be read or written during the operation, specifying the amount of data to transfer.
>
> 5. `aio_reqprio`: Type: `int`, description: Sets the request priority for the asynchronous operation, with lower values indicating higher priority. It controls the execution order of concurrent I/O operations.
>
> 6. `aio_sigevent`: Type: `struct sigevent`, description: Defines the notification mechanism for the completion of the asynchronous operation, supporting signals, callback functions, or other forms of notification.
>
> 7. `aio_lio_opcode`: Type: `int`, description: Used in list I/O operations, it specifies whether the operation is a read, write, or no-op (no operation).
>
> Before starting an asynchronous read or write, an instance of `aiocb` must be populated with all the relevant fields, such as the file descriptor, buffer, and offset. The asynchronous operation is then initiated using functions like `aio_read()` or `aio_write()`, which take a pointer to the `aiocb` structure as an argument.
>
> As the operation progresses, the state of the `aiocb` structure is monitored using functions like `aio_error()`, which returns the current status of the I/O request. Once the operation completes, `aio_return()` is used to retrieve the result, such as the number of bytes read or written.
>
> The `aiocb` structure enables a more flexible approach to I/O, allowing applications to handle I/O-intensive tasks without blocking the main thread. This makes it a useful tool in applications that require high concurrency, such as servers, real-time systems, and data processing programs.

The asynchronous read is initiated with `aio_read()`, which returns immediately, allowing the program to continue executing while the read operation progresses in the background. The code then enters a loop, checking the status of the asynchronous operation with `aio_error()`. When the operation finishes, `aio_return()` retrieves the result, indicating how many bytes were read successfully.

By combining `mmap` and asynchronous I/O, this code provides a powerful way to handle large files efficiently. The memory-mapped region allows for direct memory access, minimizing the overhead of copying data from kernel space to user space. Simultaneously, asynchronous I/O enables the application to process data in a non-blocking manner, making it ideal for multitasking environments.

The next section will introduce `io_uring`, a more advanced and efficient interface available in Linux kernels starting from version 5.1. Unlike traditional asynchronous I/O, `io_uring` offers a unified approach to handling I/O operations, including file I/O and network sockets, with lower latency and improved throughput.

While the combination of `mmap` and asynchronous I/O provides a powerful solution for file handling, modern Linux kernels offer an even more sophisticated approach. Enter `io_uring`, a revolutionary interface introduced in Linux 5.1 that represents the next generation of asynchronous I/O.

`io_uring` addresses many of the limitations found in traditional asynchronous I/O implementations, offering lower latency, better throughput, and a more unified approach to handling both file and network I/O. By utilizing a pair of ring buffers for submission and completion queues, `io_uring` minimizes kernel overhead and provides a more efficient way to manage I/O operations.

#### 2.1.4.1. Using ´io_uring` in Linux

`io_uring` is a modern interface introduced in Linux 5.1 (released in May 2019) to handle asynchronous I/O more effectively. It was designed to address the limitations of previous asynchronous I/O mechanisms like `aio`, offering a more efficient and flexible approach for handling various types of I/O operations, such as file and network I/O. The primary concept behind `io_uring` is to provide a pair of rings (queues) for submission and completion, allowing userspace programs to submit I/O requests and receive their results with minimal kernel interaction. The Figure 2.1.H shows the ìo_uring innovation.

![the io_uring circular buffers diagram](/assets/images/io_uring.webp)

_Figure 2.1.H: The two circular buffers in `io_uring` algorithm._{: class="legend"}

The core innovation of `io_uring` lies in its use of two circular ring buffers that work together to manage I/O operations efficiently. Think of these rings as a coordinated system where the application and kernel communicate through shared memory spaces, eliminating the overhead of traditional system calls.

The first ring, called the Submission Queue (SQ), serves as a staging area for I/O requests. When your program needs to perform an I/O operation, it places the request in this queue. The kernel monitors this queue and processes these requests as efficiently as possible, often batching multiple operations together to reduce overhead.

The second ring, the Completion Queue (CQ), is where the kernel reports the results of completed I/O operations. As operations finish, the kernel places their results in this queue, allowing your program to check for completions without making explicit system calls. This design means your program can submit multiple requests and continue working on other tasks, checking the completion queue periodically for results.

Both rings operate in a circular fashion, which allows for continuous operation without the need to allocate new memory or reset positions. The shared memory space between the application and kernel means that communication happens with minimal overhead - there's no need to copy data between user and kernel space, and no context switching is required for basic operations.

This efficient design makes `io_uring` particularly valuable in competitive programming scenarios where performance is crucial. Instead of getting blocked waiting for I/O operations to complete, your program can submit multiple requests at once and process results as they become available, maximizing CPU utilization and minimizing latency.

The introduction of `io_uring` coincided with efforts to make asynchronous I/O more accessible in C++20. While `io_uring` itself is a Linux-specific feature implemented in C, it is often used in C++ applications due to its compatibility with C++20's coroutines and asynchronous programming paradigms. C++20 introduced features like coroutines, which provide a natural way to write asynchronous code, and `io_uring` can be integrated with these features to perform non-blocking I/O operations seamlessly. The use of `io_uring` in C++20 applications is still manual, as there is no standard library integration for it, but it can be combined with C++20's coroutines to simplify the handling of I/O operations.

The core components of `io_uring` are the submission queue (SQ) and the completion queue (CQ). The submission queue allows applications to submit I/O requests without immediately invoking system calls. Instead, the kernel processes batches of requests, improving throughput. Meanwhile, the completion queue notifies the application when the I/O operations finish, also reducing system call overhead by sharing results directly with userspace. This mechanism is efficient because it minimizes the overhead of context switching and syscall latency, especially in scenarios that require high-performance I/O.

To use `io_uring` in a C++20 context, applications typically interact with its low-level API via the `<liburing>` library. The process involves initializing the ring, preparing submission queue entries, and handling completion events. C++20's coroutines can be used to represent asynchronous tasks, making it easier to structure I/O-heavy applications. Below is a basic example of how `io_uring` can be implemented in C++20 to perform an asynchronous read operation:

```cpp
#include <liburing.h>
#include <fcntl.h>
#include <unistd.h>
#include <iostream>
#include <coroutine>

// Basic asynchronous task definition using coroutines
struct AsyncTask {
    struct promise_type {
        AsyncTask get_return_object() { return {}; }
        std::suspend_never initial_suspend() { return {}; }
        std::suspend_never final_suspend() noexcept { return {}; }
        void return_void() {}
        void unhandled_exception() { std::terminate(); }
    };
};

// Asynchronous read operation using io_uring
AsyncTask async_read(const char* filename) {
    io_uring ring;
    io_uring_queue_init(8, &ring, 0); // Initialize io_uring with 8 entries

    int fd = open(filename, O_RDONLY);
    if (fd < 0) {
        std::cerr << "Error opening file.\n";
        co_return;
    }

    char buffer[4096]; // Buffer for reading
    iovec iov = { .iov_base = buffer, .iov_len = sizeof(buffer) };

    io_uring_sqe* sqe = io_uring_get_sqe(&ring); // Get a submission queue entry
    io_uring_prep_readv(sqe, fd, &iov, 1, 0);    // Prepare read request
    io_uring_submit(&ring);                      // Submit to the ring

    io_uring_cqe* cqe;
    io_uring_wait_cqe(&ring, &cqe); // Wait for completion

    if (cqe->res < 0) {
        std::cerr << "Error reading file.\n";
    } else {
        std::cout << "Read " << cqe->res << " bytes: " << buffer << "\n";
    }

    io_uring_cqe_seen(&ring, cqe); // Mark CQE as seen
    io_uring_queue_exit(&ring);    // Clean up
    close(fd);                     // Close the file
}
```

_Code 2.1.G: Using `io_uring` for asynchronous I/O in Linux_. {: class="legend"}

In Code 2.1.G, an asynchronous task is defined using C++20 coroutines, and the I/O operation is managed by `io_uring`. The code demonstrates how a coroutine-based asynchronous read operation can be implemented, leveraging the submission and completion queues provided by `io_uring`.

>Coroutines in C++20 offer a new paradigm for asynchronous programming, enabling functions to pause and resume execution at specific points. This approach is useful for asynchronous I/O operations, as it allows a sequential flow of code without blocking the main program.
>
>Coroutines in C++20 are specialized functions that use three main keywords:
>
> - `co_await`: suspends execution until the awaited task completes.
> - `co_yield`: returns a value while keeping the coroutine active.
> - `co_return`: exits the coroutine and returns a final value.
>
>Unlike regular functions, coroutines can be suspended and resumed multiple times during execution, allowing efficient handling of asynchronous operations like I/O.
>
>`io_uring` is an interface introduced in Linux $5.1$ that handles asynchronous I/O efficiently. It uses a pair of ring buffers for submission and completion of I/O operations, minimizing system call overhead. Coroutines can be integrated with `io_uring` to simplify code structure and manage asynchronous read and write operations.
>
>In Windows, asynchronous I/O operations are managed using APIs like `ReadFileEx`and `WriteFileEx`, often in combination with I/O Completion Ports (IOCP). Coroutines can be integrated with IOCP to streamline asynchronous operations, allowing non-blocking file handling. Here’s an example of using coroutines for asynchronous I/O in Windows:
>
> ```cpp
> #include <windows.h>
> #include <iostream>
> #include <coroutine>
> 
> // Structure for asynchronous task using coroutines
> struct AsyncTask {
>     struct promise_type {
>         AsyncTask get_return_object() { return {}; }
>         std::suspend_never initial_suspend() { return {}; }
>         std::suspend_never final_suspend() noexcept { return {}; }
>         void return_void() {}
>         void unhandled_exception() { std::terminate(); }
>     };
> };
> 
> // Asynchronous file read operation with Windows API
> AsyncTask async_read(const char* filename) {
>     HANDLE file = CreateFileA(
>         filename, GENERIC_READ, 0, nullptr, OPEN_EXISTING,
>         FILE_FLAG_OVERLAPPED, nullptr
>     );
>     if (file == INVALID_HANDLE_VALUE) {
>         std::cerr << "Error opening file.\n";
>         co_return;
>     }
> 
>     char buffer[4096]; // Buffer for reading
>     OVERLAPPED overlapped = {};
>     
>     if (!ReadFile(file, buffer, sizeof(buffer), nullptr, &overlapped)) {
>         if (GetLastError() != ERROR_IO_PENDING) {
>             std::cerr << "Error initiating read.\n";
>             CloseHandle(file);
>             co_return;
>         }
>     }
> 
>     // Wait for asynchronous I/O completion
>     WaitForSingleObject(file, INFINITE);
>     std::cout << "Read completed: " << buffer << "\n";
>     CloseHandle(file);
> }
> ```
>
>In this example, the coroutine manages asynchronous file reading using the Windows API. The `async_read` function initiates a non-blocking read operation, suspending the coroutine until completion.

Parallel I/O fits when there are many read/write tasks or when the program needs to handle big data while still reading or writing files. You see this in AI competitions and hackathons. It helps when you work with large datasets or need fast input/output handling, like in "big data" challenges. But due to its complexity, save `std::async` and threading for when parallelism gives a clear edge over regular I/O. Keep it for the moments when it really counts.

### 2.1.5. Summary of Techniques for File I/O

| Function/Operation               | Most Efficient Technique                                                                    | Description                                                                                                                                               |
| -------------------------------- | ------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Reading from file (small to medium files) | `std::ifstream` (line-by-line or block read with `std::istreambuf_iterator`)               | Provides standard file input operations. Reading with `std::istreambuf_iterator` loads the entire file efficiently, suitable for small to medium files.  |
| Reading from file (large files) | `mmap` (Unix-based)                                                                         | Maps files into memory, allowing direct access as if they were part of the program's memory space, reducing I/O operations and overhead.                 |
| Asynchronous file reading        | `std::future`/`std::async`                                                                 | Allows for non-blocking reading of files, running in a separate thread, and improving performance by keeping the main thread active.                      |
| Parallel I/O on Unix/Linux       | `io_uring`                                                                                 | Offers fast, low-latency asynchronous I/O operations with submission and completion queues, making it ideal for high-performance parallel I/O tasks.      |
| Handling large data volumes      | Manual buffering (`fread` or custom buffer with `std::vector<char>`)                       | Reads data in large chunks, minimizing I/O operations, suitable for handling large files or datasets, reducing overhead from repeated read calls.         |
| Mixed parallel I/O               | Combination of `mmap` and asynchronous I/O (`aio`)                                         | Uses `mmap` for mapping large files into memory and asynchronous I/O for handling non-blocking operations simultaneously, ideal for Unix-based systems.   |
| Efficient I/O on command-line    | Disable synchronization (`std::ios::sync_with_stdio(false)`) and `std::cin.tie(nullptr)`   | Disables sync between C++ streams and C streams, reducing overhead for input/output operations in competitive programming contexts.                       |

Efficient file handling is a competitive vantage, especially in competitive programming where input sizes can be large. Optimizing file I/O can be the difference between a solution that completes on time and one that fails. Using the right technique for each scenario ensures that your program handles data quickly and efficiently.

### 2.1.6. I/O Efficiency for Bulk Data

Having explored various file I/O techniques, from basic operations to advanced asynchronous methods, we now turn our attention to a crucial aspect of competitive programming: handling bulk data operations. In many programming contests, especially those focused on data processing or artificial intelligence, the ability to efficiently process large amounts of data can make the difference between success and failure. The Figure 2.1.I shows a mind map of this section.

![shows the mind map for this section](/assets/images/BulkDataMM.webp)

_Figure 2.1.I: Efficient Bulk Data I/O Mind Map._{: class="legend"}

The C functions `fread` and `fwrite` stand out as powerful tools for this purpose, offering raw performance that can surpass more sophisticated C++ stream operations when dealing with bulk data. These functions are particularly valuable in competitions where input sizes push the limits of standard I/O methods.

Let's examine how these functions can be leveraged to achieve maximum I/O performance:

`fread` and `fwrite` are made for speed with big data. They handle data in blocks, reducing the system calls that drag performance down. Large inputs are common in competitions focused on big data, AI, and statistics. That’s why we study these techniques. This guide is about competitive programming, but we’re also shaping good professionals. Use `fread` and `fwrite` when you need to move big chunks of data fast, and keep in mind the skills you build here go beyond the contest.

`fread` reads bytes from a file or `stdin` into a buffer. It grabs everything in one go, reducing overhead. This is ideal when you need to pull in large chunks of data fast.

```cpp
#include <cstdio>      // Include the C standard input-output library for functions like fread and putchar

// Main function
int main() {
    // Declare a buffer array of 1024 characters to temporarily hold the data read from input
    char buffer[1024];  // 1 KB manual buffer

    // Use fread to read data from standard input (stdin) into the buffer
    // fread returns the total number of elements successfully read, stored in bytesRead
    size_t bytesRead = fread(buffer, 1, sizeof(buffer), stdin);

    // Loop through each byte that was read into the buffer
    for (size_t i = 0; i < bytesRead; ++i) {
        // Use putchar to output each character from the buffer to standard output (stdout)
        // putchar prints one character at a time from the buffer to the console
        putchar(buffer[i]);
    }

    // Return 0 to indicate successful execution of the program
    return 0;
}
```

`fread` reads up to the specified number of items and stores them in your buffer. In the example, `fread(buffer, 1, sizeof(buffer), stdin)` reads up to $1024$ bytes and stores them in `buffer`. It returns the number of bytes read, so you know exactly what was processed.

Let’s break down the line `size_t bytesRead = fread(buffer, 1, sizeof(buffer), stdin);` step by step.

Starting from `size_t`: This is an unsigned integer type. It’s used to represent sizes and counts without negative values. `size_t` is used because it’s safe for indexing and size calculations. It automatically matches the correct size for the system, 32-bit or 64-bit. We use `size_t` here because `fread` returns the number of items read, and it’s always a positive number.

Following we have `fread`: This function reads data from a stream into a buffer. It’s designed for bulk reading, pulling data in chunks instead of piece by piece.

**Arguments of `fread`**:

1. **`buffer`**: This is the destination where `fread` will store the data it reads. It’s an array of characters, `char buffer[1024]`. This buffer holds up to $1024$ bytes of input data. Think of it as a container where `fread` dumps what it reads.

2. **`1`**: This is the size of each element to read. Here, it’s set to `1`, which means one byte at a time. It’s a straightforward way to read raw bytes without worrying about formatting or specific data types.

3. **`sizeof(buffer)`**: This tells `fread` how many bytes in total to read. `sizeof(buffer)` calculates the size of the buffer, which is $1024$ bytes. So, `fread` will attempt to read up to $1024$ bytes in one go. It won’t read more than the buffer can hold, keeping everything safe.

4. **`stdin`**: This is the input stream—standard input, usually the keyboard or data redirected from a file. `fread` pulls data from this stream and fills the buffer.

Putting it all together, `fread(buffer, 1, sizeof(buffer), stdin)` reads up to $1024$ bytes of data from standard input and stores it in the buffer. It does this in one operation, reducing the time spent on input compared to reading character by character.

For fast writing, `fwrite` is your go-to. It pushes data from your buffer to a file or `stdout` in one sweep. It’s fast because it doesn’t stop for formatting.

```cpp
#include <cstdio>      // Include the C standard input-output library for functions like fwrite
#include <vector>      // Include the vector library (not used in this code but commonly included for dynamic arrays)

// Main function
int main() {
    // Define a constant character pointer pointing to a string of data
    const char* data = "Outputting large blocks of data quickly\n";
    // Calculate the size of the data string using strlen
    // strlen returns the length of the string excluding the null terminator
    size_t dataSize = strlen(data);

    // Write the data from the buffer to standard output using fwrite
    fwrite(data, 1, dataSize, stdout);

    // Return 0 to indicate successful execution of the program
    return 0;
}

```

`fwrite` sends data from your buffer in a single operation. `fwrite(data, 1, dataSize, stdout)` writes `dataSize` bytes to `stdout`, avoiding the slowdown of smaller writes. Use `fread` and `fwrite` when you need raw speed without the fluff of formatting. They’re built for bulk I/O and shine when performance is key. Let's understand this code:

Starting from `const char* data`. It’s a pointer to a constant string. The string lives in read-only memory, which means you can’t change it. This string holds the message you want to send out to the output. It’s fixed, and it’s fast.

Following we have `size_t dataSize = strlen(data);`: `strlen` counts the characters in the string, skipping the `null` terminator. It tells you exactly how many bytes `fwrite` will handle. We use `size_t` because it’s safe on any system, whether you’re on a 32-bit or 64-bit machine. It handles sizes without fuss.

Finally, we get `fwrite(data, 1, dataSize, stdout);`: `fwrite` pushes the data straight from the buffer to the output. It’s designed to move data in bulk, making it faster and more efficient. It's arguments are:

1. **`data`**: The buffer with your data. It’s the source.
2. **`1`**: The size of each piece of data to write, in bytes. Here, it’s one byte per character.
3. **`dataSize`**: The number of bytes `fwrite` needs to write, which `strlen` calculated for us.
4. **`stdout`**: The output stream, usually your screen or console.

This setup makes `fwrite` do the work in a single shot. It doesn’t break the data into tiny pieces. It just moves it all at once, cutting down on system calls that waste time.

`fwrite` handles data in blocks, unlike `putchar` or `printf` that deal with one character at a time. This bulk operation makes it quicker and perfect for competitive programming when you need to dump large amounts of data fast. It’s built to speed up the process, especially when every second counts.

Having explored various techniques for optimizing file I/O, we must address an often-overlooked aspect in competitive programming: error handling. Competitive programming presents unique challenges where the balance between safety and performance requires careful consideration.

Error handling in competitive programming differs significantly from production code, as contest environments often provide guaranteed constraints and well-defined input formats. Understanding when and how to implement error checking can make the difference between an optimized solution and one that wastes precious processing time on unnecessary validations.

### 2.1.7. Error Handling

Whenever we work with input and output, we need to check for errors. Maximize this practice in production environments. This is part of what Dijkstra called defensive programming. However, this book is not dedicated to production systems and is focused on competition. Validating errors can be an unnecessary luxury in competitions. The Figure 2.1.J show a mind map of this section.

![Mental map showing all parts of this section](/assets/images/ErrorHandlingMM.webp)

_Figure 2.1.J: Mind map of error handling._{: class="legend"}

Error handling in competitive programming differs from production code. While robust error handling is crucial in production environments, competitive programming prioritizes speed and code conciseness.

In competitive programming, prefer using `assert()` for critical validations that should fail fast upon encountering invalid states:

```cpp
// Competitive programming approach
std::ifstream file(filename);
assert(file.is_open()); // Quick check that terminates if file isn't open
```

Note that `assert()` statements can be disabled if the `NDEBUG` macro is defined (typically in release builds to improve performance). When `NDEBUG` is defined, all `assert()` checks are removed during compilation, and the expressions inside them are not evaluated. To define `NDEBUG`, you can:

```cpp
// Disable assert() by defining NDEBUG
#define NDEBUG
#include <cassert>
```

Alternatively, you can pass the `-DNDEBUG` flag to the compiler when compiling your code:

 ```shell
// Compile with NDEBUG defined
g++ -DNDEBUG -O2 -std=c++17 main.cpp -o main
```

It was easy to verify that `NDEBUG` is not among the compilation options in ICPC contests (`-x c++ -g -O2 -std=gnu++20 -static {files} -lm`), but I couldn't confirm this flag in other competitions. In other words, it's up to you to ensure this.

> - `-x c++`: Specifies that the input files are to be compiled as C++ code, overriding any file extensions.
>
> - `-g`: Includes debugging information in the compiled executable. Useful for debugging but may increase the file size.
>
> - `-O2`: Enables level 2 optimizations, balancing compilation time and performance improvements.
>
> - `-std=gnu++20`: Sets the language standard to GNU C++20, enabling all C++20 features along with GNU extensions.
>
> - `-static`: Links all libraries statically, producing a standalone executable that doesn't depend on shared libraries at runtime.
>
> - `{files}`: Placeholder for the source file names to be compiled.
>
> - `-lm`: Links the math library. Necessary when using mathematical functions like `sin`, `cos`, `sqrt`, etc.

Be careful, in competitive programming, optimization flags might unintentionally define `NDEBUG`, disabling your assertions.

Exceptions can introduce overhead in competitive programming. Although throwing an exception is not typically an $O(n)$ operation, it can impact performance due to stack unwinding and hinder compiler optimizations. It's preferable to use early returns or simple conditional checks:

```cpp
// Avoid try-catch blocks in performance-critical sections
bool processData(const char* data, size_t size) {
    if (!data || size == 0) return false; // Early return for invalid input
    // Process data...
    return true;
}
```

In competitions, input data often adheres strictly to specified constraints. You can leverage this to reduce redundant checks:

```cpp
// Assuming n is within the specified limits
int n;
std::cin >> n;
// Proceed without additional checks
```

However, if you want to ensure that the data meets the constraints, a single `assert()` can be used:

```cpp
assert(1 <= n && n <= 100000); // Quick range validation
```

_Avoid expensive error checking inside tight loops to improve performance_:

```cpp
// Avoid unnecessary checks inside critical loops
for (int i = 0; i < n; ++i) {
    result += arr[i]; // Direct access without bounds checking
}
```

Ensure that such optimizations do not introduce undefined behavior. Trust the problem's constraints and verify that indices are within valid ranges. By reducing unnecessary overhead, the time complexity can be improved from:

$$T(n) = O(n \cdot m \cdot \log n)$$

to:

$$T(n) = O(n \cdot m)$$

where the $\log n$ factor is eliminated by reducing operations like comparisons or function calls within loops.

While aggressive optimizations can improve performance, it's essential to balance the need for speed with code readability and safety. Use these practices understanding the specific constraints of the competition, and always test your code thoroughly to avoid subtle errors.

## 2.2. Fast Command-Line I/O

In competitive programming, inputs often come from the command line. First, you get the size of the array, then the array elements, separated by spaces. You must read this data fast and print the results quickly, especially with large datasets. Let's start with pure C++.

```cpp
#include <iostream>  // Include the standard input-output stream library
#include <vector>    // Include the vector library for dynamic arrays
#include <cstdio>    // Include C standard input-output header (optional in this context)

// Main function
int main() {
    // Disable synchronization between C and C++ standard streams for faster I/O operations
    std::ios::sync_with_stdio(false);
    // Untie cin from cout, ensuring cin is not flushed every time cout is used (improves speed)
    std::cin.tie(nullptr);

    // Declare an integer to store the size of the array
    int n;
    // Read the size of the array from standard input
    std::cin >> n;

    // Create a vector of integers with size 'n' to store the array elements
    std::vector<int> arr(n);

    // Loop to read 'n' integers into the vector
    for (int i = 0; i < n; ++i) {
        std::cin >> arr[i];  // Read each element and store it in the vector
    }

    // Loop to output each element of the vector
    for (int i = 0; i < n; ++i) {
        std::cout << arr[i] << " ";  // Print each element followed by a space
    }

    // Print a newline at the end of the output
    std::cout << std::endl;

    // Return 0 to indicate successful execution
    return 0;
}
```

_Code 2.1.H: Handling I/O faster with C++._ {: class="legend"}

Disabling I/O synchronization with `std::ios::sync_with_stdio(false);` speeds up the program. As it stops `std::cin` and `std::cout` from syncing with `scanf` and `printf`. This saves time during input and output.

Unlinking `cin` and `cout` is another step. The command `std::cin.tie(nullptr);` stops `std::cout` from flushing before every input. Now, the program flushes only when you decide, not after every read. This gives you control and makes I/O faster.

_On both Windows and Linux, this code works well. But on Linux, it matters more_. Linux systems rely on I/O synchronization more, so turning it off boosts speed. On Windows, the effect is smaller but still helpful.

>_When using C++ streams, the choice between `std::endl` and `'\n'` impacts performance significantly_. While `std::endl` adds a newline and flushes the buffer, `'\n'` only adds the newline character. Consider this example:
>
> ```cpp
> // Slower version with std::endl
> for(int i = 0; i < n; ++i) {
>     std::cout << arr[i] << std::endl;  // Flushes buffer each iteration
> }
> 
> // Faster version with '\n'
> for(int i = 0; i < n; ++i) {
>     std::cout << arr[i] << '\n';  // Only adds newline
> }
> std::cout << std::flush;  // Single flush at the end if needed
> ```
>
> The performance difference becomes more significant as dataset size increases. With `std::endl`, each iteration forces a buffer flush, resulting in $n$ flushes for $n$ elements. In contrast, using `'\n'` with a single `std::flush` at the end performs only one buffer flush after all writes are complete. While both approaches have linear time complexity, `std::endl` adds the overhead of $n-1$ additional buffer flushes, making it considerably slower for large datasets.
>
> For a mathematical perspective, if each flush takes time $c$, the total time $T$ for each approach is:
>
> $$T_{endl} = n(t_{write} + c)$$
>
> $$T_{newline} = n(t_{write}) + c$$
>
> Where $t_{write}$ is the time to write a single element. In practice, $c$ is often much larger than $t_{write}$, especially on buffered terminals and files.

While `std::cin` and `std::cout` are fast after disabling sync, some Unix-based systems like ICPC allow even quicker methods. We can use `scanf` and `printf`.

While `scanf` and `printf` are standard C functions that handle complex formatting and are thread-safe due to internal synchronization mechanisms, they are generally considered unsafe because they do not perform bounds checking. This lack of input validation can lead to buffer overflows and other security vulnerabilities if not used carefully. For this reason, development environments discourage their use by default and suggest safer alternatives like `scanf_s` and `printf_s`.

In competitive programming, `scanf` and `printf` are commonly used due to their efficiency and familiarity. Programmers must ensure they handle inputs correctly to avoid potential issues. Never, ever, under any circumstances, for any reason, use scanf or `printf` in professional code_. Now that you know the risks, let’s look at an example.

```cpp
#include <cstdio>      // Include the C standard input-output header for scanf and printf functions
#include <vector>      // Include the vector library for using dynamic arrays

// Main function
int main() {
    // Declare an integer to store the size of the array
    int n;
    // Read the size of the array from standard input using scanf, a C function that reads formatted input
    scanf("%d", &n);

    // Create a vector of integers with size 'n' to store the array elements
    std::vector<int> arr(n);

    // Loop to read 'n' integers into the vector
    for (int i = 0; i < n; ++i) {
        // Read each element and store it in the vector using scanf
        scanf("%d", &arr[i]);
    }

    // Loop to output each element of the vector
    for (int i = 0; i < n; ++i) {
        // Print each element followed by a space using printf, which outputs formatted data
        printf("%d ", arr[i]);
    }

    // Print a newline at the end of the output to move the cursor to the next line
    printf("\n");

    // Return 0 to indicate that the program has executed successfully
    return 0;
}
```

_Code 2.1.I: Using `scanf` and `printf` for performance._ {: class="legend"}

> Below is a detailed explanation of how to use `scanf` and `printf`, with examples demonstrating reading arrays, characters, and printing integers, floats, strings, and characters.
>
> `scanf` reads formatted input from the standard input (keyboard). It requires format specifiers to interpret the data type of the input and pointers (memory addresses) to store the read values.
>
> To read an integer, use the `%d` specifier. You must provide the address of the variable using the `&` operator.
>
> ```cpp
> int n;
> scanf("%d", &n);  // Reads an integer from input and stores it in 'n'
> ```
>
> To read multiple integers into an array, `scanf` is used inside a loop. Here, `%d`reads each integer, and `&arr[i]` passes the address of each element in the array.
>
> ```cpp
> std::vector<int> arr(n); // Creates a vector to store 'n' integers
>
> for (int i = 0; i < n; ++i) {
>    scanf("%d", &arr[i]);  // Reads each integer and stores it in the array
> }
> ```
>
> Use `%c` to read a single character. When reading characters, be cautious of whitespace issues; `scanf` may read unintended newline characters.
>
> ```cpp
> char ch;
> scanf(" %c", &ch);  // Reads a single character, the space before %c ignores any whitespace
> ```
>
> Strings are read using `%s`. scanf stops reading at the first whitespace, so it cannot handle multi-word strings without additional handling.
>
> ```cpp
> char str[100];
> scanf("%s", str);  // Reads a string and stores it in the character array 'str'
> ```
>
> For floats, use `%f`, and for doubles, use `%lf`. You still need to provide the variable's address.
>
> ```cpp
> float f;
> scanf("%f", &f);  // Reads a float value and stores it in 'f'
> ```
>
> `printf` outputs formatted data to the standard output (console). It also uses format specifiers to determine the data type of what is being printed.
>
> To print integers, use `%d`.
>
> ```cpp
> int x = 10;
> printf("%d\n", x);  // Prints the integer value of 'x'
> ```
>
> Printing arrays involves looping through each element and printing them one by one.
>
> ```cpp
> for (int i = 0; i < n; ++i) {
>    printf("%d ", arr[i]);  // Prints each element of the array followed by a space
> }
> printf("\n");  // Prints a newline after the array elements
> ```
>
> Use `%c` to print single characters.
>
> ```cpp
> char ch = 'A';
> printf("%c\n", ch);  // Prints the character 'A'
> ```
>
> To print strings, use `%s`.
>
> ```cpp
> char str[] = "Hello";
> printf("%s\n", str);  // Prints the string "Hello"
> ```
>
> Use `%f` for floats and `%lf` for doubles. You can also specify the precision.
>
> ```cpp
> float f = 3.14;
> printf("%.2f\n", f);  // Prints the float value with two decimal places
> ```
>
> When using `scanf`, variables are passed by reference using pointers, meaning you provide the memory address of the variable (`&` operator). This approach allows `scanf` to modify the variable directly. For example, `scanf("%d", &n);` reads an integer and stores it at the address of `n`.
>
> When printing with `printf`, you directly provide the value to print, without needing the address.

When thread safety isn’t a concern, faster options are available. Use `putchar` for single characters, and `puts` or `fputs` for unformatted strings. If you need formatted output without thread safety, go for `printf_unlocked`. For input, `getchar_unlocked` reads characters fast, skipping safety checks, ideal for large data or custom input parsing. It’s faster than `getchar`, which is thread-safe and still beats `scanf` for simple reads. Custom input with buffers using `fread` or `read` allows reading large blocks at once but requires manual data handling. Finally, `scanf_unlocked` is a faster, unsafe version of `scanf`, best when speed is critical, and threads don’t matter.

For maximum I/O performance, custom buffers with raw C-style implementations provide the fastest possible I/O. Here's a bare-metal implementation:

```cpp
// Input buffer
char _inp[1 << 16];  // 64KB input buffer
unsigned int _inp_pos = 0;
unsigned int _inp_size = 0;

inline char next_char() {
    if (_inp_pos >= _inp_size) {
        _inp_size = fread(_inp, 1, 1 << 16, stdin);
        if (!_inp_size) return EOF;
        _inp_pos = 0;
    }
    return _inp[_inp_pos++];
}

inline int next_int() {
    char c;
    while ((c = next_char()) <= ' ');
    bool neg = (c == '-');
    int res = neg ? 0 : (c - '0');
    while ((c = next_char()) >= '0' && c <= '9') {
        res = res * 10 + (c - '0');
    }
    return neg ? -res : res;
}

// Output buffer
char _out[1 << 16];  // 64KB output buffer
unsigned int _out_pos = 0;

inline void write_char(char c) {
    if (_out_pos == (1 << 16)) {
        fwrite(_out, 1, _out_pos, stdout);
        _out_pos = 0;
    }
    _out[_out_pos++] = c;
}

inline void write_int(int x) {
    if (x < 0) {
        write_char('-');
        x = -x;
    }
    
    char temp[12];  // For 32-bit integers
    int len = 0;
    do {
        temp[len++] = x % 10 + '0';
        x /= 10;
    } while (x);
    
    while (len--) write_char(temp[len]);
}

// Don't forget to flush at the end of your program!
inline void flush_out() {
    if (_out_pos) {
        fwrite(_out, 1, _out_pos, stdout);
        _out_pos = 0;
    }
}
```

_Code Fragment 2.2.A: High-performance custom I/O buffers for competitive programming._{: class="legend"}   

For a file of size $N$, we make approximately $\lceil \frac{N}{B} \rceil$ system calls instead of $N$ calls for character-by-character reading, where $B = 2^{16}$ is the buffer size.

For a sequence of $m$ integers with average length $k$, this reduces the number of system writes from $O(mk)$ to $O(\lceil \frac{mk}{B} \rceil)$. In competitions where time limits are tight, this optimization can be decisive.

_Important: remember to call `flush_out()` before your program ends or you might lose data in the buffer!_

The choice of buffer size significantly impacts performance. While our example uses $2^{16}$ (64KB), let's understand why:

```cpp
// Testing different buffer sizes
const int SIZE_4KB = 1 << 12;   // 4KB
const int SIZE_16KB = 1 << 14;  // 16KB
const int SIZE_64KB = 1 << 16;  // 64KB
const int SIZE_256KB = 1 << 18; // 256KB

// Example with different sizes
char buffer_small[SIZE_4KB];
char buffer_medium[SIZE_64KB];
char buffer_large[SIZE_256KB];
```

Smaller buffers ($4$KB) result in more system calls but use less memory. For input size $N$, a $4$KB buffer requires $\lceil \frac{N}{4096} \rceil$ system calls. Larger buffers ($256$KB) make fewer calls ($\lceil \frac{N}{262144} \rceil$) but consume more memory.

_Competitive programming systems typically provide L1 cache of $32$KB to $64$KB, use $4$KB page sizes, and impose time limits of $1$-$2$ seconds with memory limits between $256$MB and $512$MB_. Within these constraints, the $64$KB buffer size provides an optimal balance. It fits entirely in L1 cache, aligns perfectly with the page size as it equals $16$ pages, and is large enough to minimize system calls while leaving ample memory for other data structures.

Consider a typical competitive programming input of $10^6$ integers. With a $4$KB buffer, we need approximately:

$$
\text{System Calls}_{4KB} = \left\lceil \frac{10^6 \times 4}{4096} \right\rceil \approx 977 \text{ calls}
$$

While with our $64$KB buffer, this reduces to:

$$
\text{System Calls}_{64KB} = \left\lceil \frac{10^6 \times 4}{65536} \right\rceil \approx 61 \text{ calls}
$$

This $64$KB buffer choice reduces system calls by $94\%$ compared to $4$KB, while maintaining optimal cache utilization, a definitive performance factor in competitive programming.

Let’s see an example with `printf_unlocked` and `scanf_unlocked`, swapping them in for `printf` and `scanf`. They’re faster because they skip thread safety checks and internal locking mechanisms. These functions work on Linux because they’re part of `glibc`, the GNU C Library for Unix systems. You won’t find them on Windows, as these unlocked versions are specific to `glibc`. 

Windows libraries implement thread safety differently from Unix-based systems. While both platforms support thread-safe operations, Windows tends to integrate safety checks more deeply into its standard library implementations, making it harder to bypass these mechanisms for raw performance. This design choice reflects Windows' focus on enterprise environments where consistent behavior across different threading scenarios often takes precedence over maximum single-threaded performance. This explains why functions like `printf_unlocked` and `scanf_unlocked` aren't available in the Windows standard library - they would break the consistency guarantees that Windows developers rely on.

```cpp
#include <cstdio>      // Include the C standard input-output header for scanf_unlocked and printf_unlocked functions
#include <vector>      // Include the vector library for using dynamic arrays

// Main function
int main() {
    // Declare an integer to store the size of the array
    int n;
    // Read the size of the array from standard input using scanf_unlocked, a faster version of scanf without thread safety
    scanf_unlocked("%d", &n);

    // Create a vector of integers with size 'n' to store the array elements
    std::vector<int> arr(n);

    // Loop to read 'n' integers into the vector
    for (int i = 0; i < n; ++i) {
        // Read each element and store it in the vector using scanf_unlocked
        scanf_unlocked("%d", &arr[i]);
    }

    // Loop to output each element of the vector
    for (int i = 0; i < n; ++i) {
        // Print each element followed by a space using printf_unlocked, a faster variant without thread safety
        printf_unlocked("%d ", arr[i]);
    }

    // Print a newline at the end of the output to move the cursor to the next line
    printf_unlocked("\n");

    // Return 0 to indicate that the program has executed successfully
    return 0;
}
```

_Code 2.1.J: Using even more unsecure functions in performance quest._{: class="legend"}

`printf_unlocked` and `scanf_unlocked` use the same arguments as their safer counterparts, `printf` and `scanf`. For `printf_unlocked`, you provide a format string followed by the values to print, just like `printf`. For `scanf_unlocked`, you give a format string and pointers to where the input should be stored. The key difference is speed and safety: `unlocked` versions skip thread checks, making them faster but unsafe in multi-threaded contexts. Use them when you control the environment and need every bit of speed.

`printf_unlocked` and `scanf_unlocked` are part of the GNU C Library (`glibc`) and were introduced in version 2.3.2. From `glibc` 2.3.4 onwards, these functions are marked with `__attribute__((deprecated))` when compiling with `-D_GNU_SOURCE` and strict POSIX compliance, though they remain fully functional. On recent Linux distributions (using `glibc` 2.35+), these functions are implemented as inlined wrappers around their locked counterparts when compiler optimization flags like `-O2` or `-O3` are used, with the compiler automatically removing lock operations in single-threaded contexts. _This means maximum performance can be achieved even without explicitly using the `_unlocked` variants, provided appropriate compiler optimizations are enabled_. Note that these functions are absent from other C library implementations like musl libc[^lib1] or Microsoft's C runtime library, making them specifically a `glibc` feature.

`printf_unlocked` and `scanf_unlocked` are useful in competitive programming on Linux, especially when you need complex output and don’t use threads. They are faster than `printf` and `scanf`, making them a good choice when speed matters. But they aren’t the fastest options.

For even quicker I/O, use `putchar`, `puts`, `fputs`, and `getchar_unlocked`. These functions skip complex formatting and, in the case of `getchar_unlocked`, safety checks, giving you maximum speed when every millisecond counts. Note that `getchar_unlocked` is specific to Unix-like systems and not available on Windows, while `putchar`, `puts`, and `fputs` are standard C functions available on all platforms.

While `fgets` is a standard C function that safely reads strings and is available on both Linux and Windows, it does not skip safety checks or formatting. It is designed to prevent buffer overflows by requiring the buffer size and is thread-safe, making it reliable but not necessarily faster than the other functions mentioned for raw speed.

_`putchar` is the fastest for printing a single character. It skips formatting and works well for repetitive character output_. `puts` is quick for printing strings; it doesn’t format and adds a newline at the end. `fputs` is similar to `puts` but doesn’t add a newline, giving you more control over output flow and can be faster in some cases. `fgets` reads strings efficiently, ideal for reading lines of text without worrying about formatting.

_`getchar_unlocked` reads characters at high speed. It skips safety checks, making it faster than `getchar`_. It’s best for reading large data sets or custom input parsing of integers and strings. But remember, it’s not safe in multi-threaded environments.

_`getchar` reads one character at a time, faster than `scanf` for simple inputs or when paired with custom input buffers_. It’s thread-safe but still quicker than more complex functions. These options give you raw speed when thread safety isn’t a priority.

Remember, these functions, `putchar`, `puts`, `fputs`, `fgets`, `getchar`, `getchar_unlocked`, `scanf_unlocked`, and `printf_unlocked`, are from C, not C++. They focus on raw speed and skip the safety features found in C++. Most of them, especially the unlocked versions, only work on Linux because they’re part of glibc. You won’t find them in standard Windows setups. Here's the code explained, showing the differences between reading and printing characters and numbers. This will help you understand the speed and use cases of each function.

```cpp
#include <cstdio>  // Include C standard I/O functions

int main() {
    // Use getchar_unlocked to read characters fast
    char ch = getchar_unlocked();  // Reads a single character quickly without thread safety checks, faster than getchar
    putchar(ch);                   // Prints the character without formatting, the fastest way to print characters

    // Read a string safely with fgets, unlike gets, which is unsafe
    char str[100];
    fgets(str, 100, stdin);        // Reads up to 99 characters including spaces, prevents overflow by limiting input size
    puts(str);                     // Prints the string with a newline, faster than printf for simple text output

    // Print formatted output quickly using printf_unlocked
    int n = 42;
    printf_unlocked("Number: %d\n", n); // Prints the integer with formatting, skips thread safety checks unlike printf

    // Use scanf_unlocked for fast input of integers
    int num;
    scanf_unlocked("%d", &num);    // Reads an integer quickly, faster than scanf because it avoids thread safety checks
    printf_unlocked("Read: %d\n", num); // Prints the integer using the fast, unlocked version of printf

    return 0;
}
```

_Code 2.1.K: Fastest I/O functions._{: class="legend"}

`getchar_unlocked` takes no arguments except the call itself. It reads the next character from input, ignoring the checks that slow down `getchar`. You won’t be asked for anything fancy, just the raw input. It’s the tool for fast, unformatted character reads when time is tight.

`putchar` is its printing cousin. One argument: the character. It spits it out without asking questions. No formatting, no newline unless you add one yourself. Perfect when you need repeated character output with zero overhead.

`fgets` reads strings, but unlike `gets`, it won’t let you shoot yourself in the foot. It takes three arguments: the buffer, the size, and the input stream. The buffer catches the string, the size stops overflow, and stdin feeds it. It reads until it hits the size limit or a newline. That’s why it’s safer, faster, and reliable.

> `fgets` is your go-to when you need to read strings safely. It keeps things under control by asking for a buffer, the size of the buffer, and the input stream. It’s safer than `gets`, but you need to set it up right. Let’s break it down with examples for different inputs: arrays, strings, and matrices.
>
> `fgets` reads one line at a time, including spaces and stops at the newline or when it fills the buffer. It’s great for reading a line of text without overflow.
>
> ```cpp
> char str[100]; // Buffer to hold the input
> fgets(str, 100, stdin); // Reads up to 99 characters plus the null terminator
> ```
>
> It reads into `str`, stopping at $99$ characters or a newline. It adds a null terminator, so your string is always safe to use.
>
> When you need multiple strings, set up an array of buffers. Each `fgets` call reads into the next buffer.
>
> ```cpp
> char words[5][20]; // Array of 5 strings, each up to 19 characters plus null terminator
> for (int i = 0; i < 5; i++) {
>     fgets(words[i], 20, stdin); // Reads each line into the array
> }
> ```
>
> Here, each row of `words` holds one string. You read each line separately, and the 20-character limit keeps it safe.
>
> `fgets` can also help when reading a grid or matrix of characters, treating each row as a string.
>
> ```cpp
> char matrix[3][4]; // 3 rows, 4 columns
> for (int i = 0; i < 3; i++) {
>     fgets(matrix[i], 5, stdin); // Reads 4 characters and a newline
> }
> ```
>
> Each `fgets` call reads a row. The buffer size of $5$ includes 4 characters plus the null terminator.
>
> `fgets` doesn’t read numbers directly, but you can use it to grab the line and then convert the text.
>
> ```cpp
> char input[10];
> fgets(input, 10, stdin); // Read the input as a string
> int number = atoi(input); // Convert to integer using atoi
> ```
>
> This lets you handle the input safely as text before converting, reducing the risk of overflow.
>
> `fgets` puts control in your hands. It reads just enough to fill the buffer without spilling over. Use it for strings, arrays, and grids when you need precise control. It’s simple, fast, and doesn’t ask questions—it just gets the job done.

`puts` is simple: one string and it’s printed with a newline. No need to worry about formatting strings or handling variable types. It’s fast because it’s straightforward, great for dumping results to the screen when you don’t need the extra fluff.

`printf_unlocked` handles formatted output like its safer cousin, `printf`. You pass the format string and the values. Each %d, %c, or %f you throw at it gets processed and printed. But unlike `printf`, it skips thread safety, making it quicker in single-thread scenarios where control is yours.

`scanf_unlocked` is the input counterpart. You pass the format string and pointers to where the data goes. Use %d for integers, %c for characters, %s for strings—just like `scanf`. It reads fast but trusts you to handle safety. It won’t pause to double-check.

Each function has its role in competitive programming. Use `getchar_unlocked` when you need every character, no questions asked. Use `putchar` when you need to print those characters right back. `fgets` and `puts` give you quick ways to handle strings without the mess of formatting. And when you need more, `printf_unlocked` and `scanf_unlocked` step in, speeding through input and output without the safety nets. They’re fast because they trust you to manage the risks.

In competitive programming, every millisecond matters. Below is a table showing the fastest input and output functions, their uses, and where they work. Use it to pick the right tool for the job, depending on your platform and need for speed.

| Function             | Speed Order | Use Case                                                                                    | Platform      |
| -------------------- | ----------- | ------------------------------------------------------------------------------------------- | ------------- |
| **Input Functions**  |             |
| `getchar_unlocked`   | 1           | Fastest for reading characters without safety checks; ideal for fast unformatted input.     | Linux         |
| `fgets`              | 2           | Reads strings safely with control over buffer size; good for line input.                    | Linux/Windows |
| `scanf_unlocked`     | 3           | Fast input of formatted data without thread safety; ideal when speed is critical.           | Linux         |
| `getchar`            | 4           | Thread-safe reading of single characters; slower but safer than getchar_unlocked.           | Linux/Windows |
| `scanf`              | 5           | Standard formatted input; safer but slower due to safety checks.                            | Linux/Windows |
| `std::cin`           | 6           | Standard input in C++, slower than C functions but safer and easier to use.                 | Linux/Windows |
|                      |             |
| **Output Functions** |             |
| `putchar`            | 1           | Fastest for printing single characters without formatting.                                  | Linux/Windows |
| `puts`               | 2           | Quick for printing strings with a newline; faster than `printf` for simple strings.           | Linux/Windows |
| `fputs`              | 3           | Similar to puts but without the newline, giving more control over output flow.              | Linux/Windows |
| `printf_unlocked`    | 4           | Formatted output without thread safety; faster in controlled, single-threaded environments. | Linux         |
| `printf`             | 5           | Standard formatted output; slower due to thread safety and formatting checks.               | Linux/Windows |
| `std::cout`          | 6           | Standard output in C++, slower than C functions; handles complex formatting easily.         | Linux/Windows |

{% comment %}

PRECISO REFAZER ESTES TESTES DE PERFORMANCE

### 2.1.4.2 I/O Performance Analysis

The choice of I/O method impacts program performance. Let's analyze the performance differences between the main I/O methods by testing reading and writing $10^6$ integers on different operating systems.

<cpp>
#include <iostream>
#include <chrono>
#include <vector>
#include <cstdio>

// Time measurement utility
template<typename F>
double measure_time(F&& func) {
    auto start = std::chrono::high_resolution_clock::now();
    func();
    auto end = std::chrono::high_resolution_clock::now();
    return std::chrono::duration<double>(end - start).count();
}

const int N = 1000000;
std::vector<int> arr(N);

// Test 1: std::cin/cout with sync
void test_sync() {
    for(int i = 0; i < N; ++i) std::cin >> arr[i];
    for(int i = 0; i < N; ++i) std::cout << arr[i] << '\n';
}

// Test 2: std::cin/cout without sync
void test_no_sync() {
    std::ios::sync_with_stdio(false);
    std::cin.tie(nullptr);
    for(int i = 0; i < N; ++i) std::cin >> arr[i];
    for(int i = 0; i < N; ++i) std::cout << arr[i] << '\n';
}

// Test 3: scanf/printf
void test_c_io() {
    for(int i = 0; i < N; ++i) scanf("%d", &arr[i]);
    for(int i = 0; i < N; ++i) printf("%d\n", arr[i]);
}

// Test 4: Custom buffer implementation
void test_custom() {
    for(int i = 0; i < N; ++i) arr[i] = next_int();
    for(int i = 0; i < N; ++i) {
        write_int(arr[i]);
        write_char('\n');
    }
    flush_out();
}

int main() {
    const int RUNS = 10;
    std::vector<double> times(4, 0.0);
    
    // Run each test multiple times and average
    for(int run = 0; run < RUNS; ++run) {
        times[0] += measure_time(test_sync);
        times[1] += measure_time(test_no_sync);
        times[2] += measure_time(test_c_io);
        times[3] += measure_time(test_custom);
    }
    
    // Calculate and display averages
    for(auto& t : times) t /= RUNS;
    printf("Synchronized C++: %.3f s\n", times[0]);
    printf("Unsynchronized C++: %.3f s\n", times[1]);
    printf("C I/O: %.3f s\n", times[2]);
    printf("Custom Buffer: %.3f s\n", times[3]);
    
    return 0;
}
</cpp>

Tests were performed in two environments:

1. **Linux** (Ubuntu 22.04, Intel i7, g++ 11.3.0 with `-O2`)
   - Synchronized C++: $2.45$ seconds
   - Unsynchronized C++: $0.82$ seconds
   - C I/O: $0.38$ seconds
   - Custom Buffer: $0.12$ seconds

2. **Windows** (Windows 11, Intel i7, MinGW-w64 g++ 11.3.0 with `-O2`)
   - Synchronized C++: $1.95$ seconds
   - Unsynchronized C++: $0.75$ seconds
   - C I/O: $0.42$ seconds
   - Custom Buffer: $0.15$ seconds

#### Results Analysis

1. **Synchronization Impact**:
   - On Linux, disabling synchronization results in a $3\times$ performance improvement
   - On Windows, the improvement is approximately $2.6\times$
   - The larger difference in Linux is due to Unix synchronization implementation

2. **C vs C++ I/O**:
   - `scanf`/`printf` are faster than `cin`/`cout` even without synchronization
   - On Linux, C-style I/O is $2.16\times$ faster than unsynchronized C++
   - On Windows, the difference is $1.79\times$

3. **Custom Buffer**:
   - Custom buffer implementation shows performance improvements on both systems
   - Linux: $3.17\times$ faster than C I/O, $20.4\times$ faster than synchronized C++
   - Windows: $2.8\times$ faster than C I/O, $13\times$ faster than synchronized C++

4. **System Differences**:
   - Linux shows larger differences between methods
   - Windows presents more consistent performance across methods
   - Custom buffer maintains performance improvements on both systems

#### I/O Method Selection Guidelines

1. **Small Inputs** (input < $10^4$):
   - Unsynchronized C++ (`std::ios::sync_with_stdio(false)`)
   - Performance differences are minimal
   - Code remains readable

2. **Medium Inputs** ($10^4 \leq$ input < $10^6$):
   - C-style I/O (`scanf`/`printf`)
   - Standard performance level
   - Common implementation method

3. **Large Inputs** (input $\geq 10^6$):
   - Custom buffer implementation
   - Performance gains increase with input size
   - Required for time-sensitive scenarios

4. **System Considerations**:
   - Windows shows smaller performance variations between methods
   - Linux shows larger performance variations
   - Custom buffer provides consistent performance improvements

These measurements quantify the performance impact of different I/O methods. In competitive programming, I/O method selection affects execution time and can determine whether a solution meets time constraints.
{% endcomment %}

## 2.3. The Sad Trick: Namespaces

In C++, **namespaces** help organize your code and keep names from clashing. They are essential in big projects or when using multiple libraries that might have functions, classes, or variables with the same name. A namespace sets up a scope, letting you define functions, classes, and variables without fear of conflicts.

A **namespace** is a space where identifiers (names of types, functions, variables, etc.) live. It allows you to use the same names in different parts of your program or across libraries without mixing things up.

```cpp
namespace MyNamespace {
    void myFunction() {
        // Implementation
    }

    class MyClass {
    public:
        void method();
    };
}
```

In this example, `MyNamespace` wraps `myFunction` and `MyClass`, keeping them separate from names in other namespaces. This prevents collisions and keeps your code clean and clear.

To access elements inside a namespace, use the _scope resolution operator_ `::`.

The _scope resolution operator_ (`::`) in C++ tells the compiler exactly where to find an element. It cuts through the noise when names are the same but live in different places. Whether it’s a function, variable, or class, `::` points to the right spot. If a function is inside a namespace, `::` pulls it out from the right one. Inside a class, it defines functions outside the declaration or accesses static members.

In competitive programming, you see `::` all the time with `std::cout` or `std::vector`. It makes sure you’re using the standard library, keeping things clear and avoiding mix-ups with your own code or other libraries. Even though it’s not always needed in small, quick code, in bigger projects, `::` keeps references straight, especially when names overlap in different parts of the program.

```cpp
int main() {
    // Calling the function inside MyNamespace
    MyNamespace::myFunction();

    // Creating an object of the class inside the namespace
    MyNamespace::MyClass obj;
    obj.method();

    return 0;
}
```

### 2.3.1 `using namespace std;`

The **std** namespace is the core of the C++ Standard Library. It holds everything you use daily, like `std::vector`, `std::cout`, `std::string`, and much more.

When you write `using namespace std;`, you’re telling the compiler to pull everything from `std` into your code. It saves you from typing `std::` every time. This makes the code shorter and easier to read, especially in small programs or quick examples. It’s a important time-saver when you’re in a rush, like during competitions.

Let's see a simple example without `using namespace std;`:

```cpp
#include <iostream>
#include <vector>

int main() {
    std::vector<int> numbers = {1, 2, 3, 4, 5};
    for (const int& num : numbers) {
        std::cout << num << " ";
    }
    std::cout << std::endl;
    return 0;
}
```

Now compare the earlier code with an example with `using namespace std;`\*\*:

```cpp
#include <iostream>
#include <vector>

using namespace std;

int main() {
    vector<int> numbers = {1, 2, 3, 4, 5};
    for (const int& num : numbers) {
        cout << num << " ";
    }
    cout << endl;
    return 0;
}
```

The first version, with `using namespace std;`, has $24$ caracteres more than the version without `using namespace std;`. This in only $10$ lines. Think about a code complex enough to build a graph and search it for a value.

`using namespace std;` makes your code shorter and easier to read, but it has its downsides. In bigger projects or when using multiple libraries, it raises the risk of name conflicts. Different namespaces might have elements with the same name, and that leads to confusion. It can make your code harder to maintain and understand because you lose track of where things come from. That’s why it’s best to avoid `using namespace std;` in production code, especially in large or shared projects.

To avoid the risks of `using namespace std;`, import only what you need from the `std` namespace. Instead of pulling in everything, bring in just the functions and types you use, like `std::cout` and `std::vector`. This keeps your code clear and reduces the chance of name conflicts, while still making it concise.

```cpp
#include <iostream>
#include <vector>

using std::cout;
using std::endl;
using std::vector;

int main() {
    vector<int> numbers = {1, 2, 3, 4, 5};
    for (const int& num : numbers) {
        cout << num << " ";
    }
    cout << endl;
    return 0;
}
```

Keep your code clean and easy to manage. Don’t use `using namespace std;` in header files. It forces every file that includes the header to pull in the `std` namespace, raising the risk of conflicts. If you must use `using`, limit it to a small scope, like inside a function. This keeps the impact small. Stay consistent with how you handle namespaces in your project. It makes the code easier to read and work with. In competitive programming, headers are rare, but in bigger projects, this discipline keeps things in order.

_In competitive programming, you don’t need custom namespaces beyond `std`. The code is small, fast, and used once. Custom namespaces add complexity with no real benefit. They’re made to avoid conflicts in big projects with many libraries, but in competitions, you rarely have that problem. The focus is on speed and simplicity, not on managing names. The same goes for object-oriented programming, it adds overhead that slows you down. Stick to the basics. Leave namespaces and OOP for large projects where they make sense. In competitions, keep it simple and keep it fast_.

In competitive programming, mastering the basics of C++20 is essential for writing efficient and optimized code. This section focuses on fundamental control structures like loops and essential data structures such as vectors and matrices. Both elements play a important role in solving problems under time constraints.

C++20 introduces several features that enhance the flexibility and performance of loops. Techniques like range views and parallel execution allow programmers to process data with greater efficiency. Whether you are dealing with small arrays or large datasets, choosing the right loop can significantly impact the runtime of your solution.

Alongside loops, vectors and matrices serve as the foundation for storing and manipulating data. Understanding how to effectively use these data structures, combined with modern C++ features, allows you to handle complex computations with ease.

In the following sections, we will explore these elements in-depth, providing examples and performance considerations to help you develop competitive programming skills using C++20.

## 2.4. Data Manipulation in C++20

Modern C++20 provides powerful tools and abstractions for handling structured data efficiently. This section explores four fundamental approaches to managing and manipulating data collections: vectors for one-dimensional data structures, matrices for two-dimensional data arrangements, and spans and ranges for flexible data views and iterations. These mechanisms form the backbone of efficient data handling in competitive programming and general-purpose applications.

Vectors are flexible. They change size and are easy to use. You can insert, remove, and resize them with little effort. They work well for many tasks in competitive programming. Vectors hold one-dimensional data, but can also represent matrices. These two-dimensional vectors are often used for grids, tables, or simulations.

Matrices, built from vectors, handle multi-dimensional problems. They are good for game boards, adjacency matrices, and dynamic programming. You can change rows and columns, transpose the matrix, or access submatrices. Vectors and matrices give you control over how you store and process data. Starting with vectors.

### 2.4.1. Working with Vectors

In C++20, vectors have several important features that make them a powerful tool for managing collections of elements. First, vectors dynamically resize. This means they grow automatically when you add elements beyond their current capacity. You don’t need to manually manage memory like you would with arrays.

Vectors also provide random access in constant time, $O(1)$. You can access any element by its index using `[]` notation, just as you would with a regular array. This makes it easy to work with elements directly without needing to traverse the vector.

>C++ also has the `std::array`. While `std::array` offers better performance due to its fixed size and stack allocation, making it more efficient in terms of memory access and iteration speed, it's practically unsuitable for competitive programming scenarios. The core reason is that competitive programming problems typically deal with dynamic, runtime-determined input sizes. Since std::array requires the size to be known at compile time, it becomes essentially useless when you don't know beforehand how many elements you'll need to store, which is the case for the vast majority of competitive programming challenges. _In contrast, `std::vector`'s ability to dynamically resize and handle arbitrary input sizes makes it the go-to container for competitive programming_, despite its slightly higher overhead. The minimal performance advantage of `std::array` becomes irrelevant when weighed against the fundamental need for runtime size flexibility in competitive programming contexts.

In C++, the `std::vector` class is part of the Standard Template Library (STL). It is a dynamic array that manages collections of elements. Unlike arrays, vectors resize when elements are added or removed. This makes them useful in competitive programming when data sizes change during execution.

Vectors offer random access to elements. They support iteration with iterators and allow dynamic resizing. They provide functions like `push_back`, `pop_back`, `insert`, `erase`, and `resize`. These make managing data easier without manual memory handling.

The following code fragment shows how to create a vector in C++20, reserve memory, and initialize elements. We start by creating a vector, reserving space for $10$ elements, and then resizing it to hold $10$ elements initialized to $0$.

```cpp
std::vector<int> vec;
vec.reserve(10); // Reserves memory for 10 elements without changing size
vec.resize(10, 5); // Resizes the vector to 10 elements, all initialized to 0
```

`vec.reserve(10);` reserves memory for $10$ elements but doesn’t affect the vector’s size. This means no elements are created yet, but space is allocated in advance to avoid future reallocations. Then, `vec.resize(10, 0);` creates $10$ elements, all initialized to $5$, using the reserved memory.

The class template `std::vector` is part of the Standard Template Library (STL) and is a dynamic array. It allows for efficient management of collections of elements. When you write `std::vector<int>`, you are creating a vector where each element is of type `int`.

`std::vector` is a _generic_ class. This means it can store elements of any type, not just integers. For example, `std::vector<double>` stores `double` values, and `std::vector<std::string>` stores strings. The class is defined with a template parameter that specifies the type of the elements.

Here’s an example of creating vectors with different types:

```cpp
std::vector<int> intVec; // Vector of integers
std::vector<double> doubleVec; // Vector of doubles
std::vector<std::string> stringVec; // Vector of strings
```

When you create a `std::vector<int>`, the compiler generates a specialized version of the `std::vector` class for integers. The same applies to any other type you use with `std::vector`. This is the power of _generic programming_, the ability to write code that works with any type while maintaining type safety.

One important feature of `std::vector` is efficient memory management. By using methods like `reserve` and `shrink_to_fit`, you can control the vector’s capacity. Reserving memory early ensures that the vector has enough space for future elements. _This avoids multiple reallocations, which can be expensive because each reallocation involves copying the entire vector to a new memory location_. When you know in advance how many elements the vector will need, calling `reserve` improves performance by minimizing these costly reallocations. We saw `reserve` before so let's take a look on `shrink_to_fit`.

`shrink_to_fit` requests the vector to reduce its capacity to match its size. This helps free unused memory after adding or removing elements. It’s not guaranteed, but it allows the system to optimize memory usage. Here’s a simple example:

```cpp
std::vector<int> vec;
vec.reserve(100);  // Reserve space for 100 elements
vec.resize(10);    // Resize to hold 10 elements
vec.shrink_to_fit(); // Reduce capacity to fit size
```

In this code fragment, we reserve space for $100$ elements, resize it to $10$, and then call `shrink_to_fit` to match capacity to the actual number of elements. It ensures memory is not wasted on unused space.

Vectors classe, `std::vector`, also come with several built-in functions that make them easy to use. For example, `push_back` allows you to add an element to the end of the vector, while `pop_back` removes the last element. The `insert` function lets you add elements at specific positions within the vector. For example, inserting a value into a vector' end:

```cpp
intVec.push_back(5); // Adds the value 5 to the end of the vector
```

`intVec.push_back(5);` _appends the value $5$ to the end of the vectorWhen the vector's capacity is reached, this operation triggers a reallocation of memory, typically doubling the vector's capacity, which incurs an $O(n)$ time complexity for copying all elements to the new memory location_. The following code fragment shows how to inserts a value into a vector at position $5$, provided that the vector has at least $6$ elements:

```cpp
if (vec.size() > 5) {
    vec.insert(vec.begin() + 5, 32);
}
```

`vec.insert(vec.begin() + 5, 42);` inserts the value $42$ at position $5$ in the vector `vec`. The condition `vec.size() > 5` ensures the vector has enough elements to avoid out-of-bounds errors. This operation has a time complexity of $O(n)$ since all elements after position $5$ need to be shifted one position to the right to make room for the new value. Now, let's see another code fragment.

```cpp
if (vec.size() > 5) vec.insert(vec.begin() + 5, 42);
```

By removing the block braces `{}`, the code becomes more concise while keeping the logic intact. This is useful when clarity is maintained without additional syntax.

As we are studying competitive programming, we must try to type less and faster. This is where `using` comes in:

```cpp
using VI = std::vector<int>; //defining an alias to std::vector<int>
VI vec;
if (vec.size() > 5) vec.insert(vec.begin() + 5, 42);
```

The `using` statement creates a shorthand for `std::vector<int>`, reducing typing. `VI vec;` now declares the vector `vec` as a vector of integers. The rest of the logic remains unchanged, making the code easier to write without losing clarity.

When working with data, insert is not enough. The following code fragment removes the last element from the vector, followed by the removal of the element at position $3$, assuming the vector has at least $4$ elements:

```cpp
if (!vec.empty()) { //vector is not empty so we can remove the last element
    vec.pop_back();
}

if (vec.size() > 3) { //as vec size is bigger than 3 we can erase elements at position 3
    vec.erase(vec.begin() + 3);
}
```

`vec.pop_back();` removes the last element from the vector while `vec.erase(vec.begin() + 3);` removes the element at position $3$. Using predefined macros, we can also reduce typing for common operations:

```cpp
#define ERASE_AT(vec, pos) vec.erase(vec.begin() + pos)
if (!vec.empty()) vec.pop_back();
if (vec.size() > 3) ERASE_AT(vec, 3);
```

In the previous code fragment, we must use the `#define` macro since the alternatives won't bring any advantages in a competitive programming environment. _Creating a template function would require more typing during the competition and could potentially introduce function call overhead, while using a lambda would not only require more typing but also make the code less readable_. The `#define` macro simply tells the preprocessor to perform a text substitution, which is both concise to write and efficiently executed, making it the most practical choice for competitive programming where typing speed and code performance are indispensable factors.

We also can create vectors with a default value in all positions. The following code fragment shows hot to creates a new integer vector with $5$ elements, all initialized to the value $7$:

```cpp
std::vector<int> vec2(5, 7);
```

No significant reduction can be achieved here without compromising clarity.

In the next code fragment, a more complex example, the vector `vec2` is resized to $10$ elements, and each element is filled with a random value between $1$ and $100$:

```cpp
vec2.resize(10);

auto seed = std::chrono::high_resolution_clock::now().time_since_epoch().count();

std::xoshiro256** gen(seed);
std::uniform_int_distribution<int> distribution(1, 100);

for (size_t i = 0; i < vec2.size(); ++i) {
    vec2[i] = distribution(gen);
}
```

Let's examine this code fragment thoroughly. The line `vec2.resize(10);` changes the size of the vector to hold $10$ elements. If the vector had fewer than $10$ elements, new ones are added. If it had more, extra elements are removed.

Next, the line `auto seed = std::chrono::high_resolution_clock::now().time_since_epoch().count();` creates a seed for the random number generator. It uses the current time, converts it to a count of time units. Since `Xoshiro256**`[^note1] works with 64-bit integers directly, we don't need type casting. This ensures the random numbers change each time the program runs.

The code then defines the generator `std::xoshiro256** gen(seed);` using the seed. This creates a Xoshiro256** random number generator, which is notably faster than Mersenne Twister while maintaining high-quality randomization. The next line, `std::uniform_int_distribution<int> distribution(1, 100);`, sets up the distribution. It ensures random numbers between 1 and 100 are generated evenly.

Finally, the `for` loop runs through each element in the vector. It assigns a random number to each position, filling the vector with random values between $1$ and $100$. We can rewrite this same code with less typing.

```cpp
vec2.resize(10);

std::xoshiro256** gen(std::random_device{}());
std::uniform_int_distribution<int> dist(1, 100);

for (auto& v : vec2) v = dist(gen);
```

In this shorter version, we use `std::random_device{}()` directly as the seed source, which provides a non-deterministic seed when available. The range-based for loop makes the code more concise and readable. Both versions produce the same result: a vector of $10$ random integers between $1$ and $100$.

> In C++20, we use the `<random>` library for generating random numbers. This library gives us flexible and efficient ways to create random data. It includes generators and distributions to produce random numbers in various forms. Generators are engines that produce random raw numbers, like `std::xoshiro256**`, which is one of the newest and most efficient generators in C++20; Distributions are objects that transform the raw numbers from generators into specific ranges or patterns, like `uniform_int_distribution` for integers in a range, or `normal_distribution` for normally distributed values. The Table 2.4.A presents a summary of the generators available in C++20.
>
> | Name                 | Availability in C++     | Purpose                 | Algorithm                                  | Performance                                               |
|----------------------|-------------------------|--------------------------|--------------------------------------------|-----------------------------------------------------------|
> | `std::mt19937`       | C++11 and later         | General purpose          | Mersenne Twister with period $2^{19937}-1$ | Good overall performance, but requires 2.5 KB of state    |
> | `std::mt19937_64`    | C++11 and later         | General purpose (64-bit) | Mersenne Twister optimized for 64 bits     | Similar to `mt19937`, with better performance on 64-bit systems |
> | `std::xoshiro256**`  | C++20                   | High performance         | Xoshiro256** (xor/shift/rotate)            | Excellent performance, small state (256 bits), period $2^{256}-1$ |
> | `std::ranlux24`      | C++11 and later         | High statistical quality | Subtract-with-borrow + discarding         | Lower performance due to number discarding                |
> | `std::ranlux48`      | C++11 and later         | Cryptographic quality    | Subtract-with-borrow + intensive discarding | Lower performance, higher statistical quality             |
> | `std::minstd_rand`   | C++11 and later         | Minimalistic             | Linear Congruential Generator (LCG)        | Very fast, but lower statistical quality                  |
> | `std::default_random_engine` | C++11 and later | Implementation-specific  | Depends on the compiler                    | Varies depending on implementation                        |
>
>_Table 2.4.A: This table provides an overview of the random number generators available in C++20, including their purpose, algorithms used, and performance characteristics. It highlights the differences in performance, statistical quality, and state size among various generators._{: class="legend"}
>
> Now, we'll take a closer look at `std::xoshiro256**`, which is a modern random number generator. This generator is known for being significantly faster than Mersenne Twister while maintaining high-quality randomization. The generator works by taking a seed, typically a 64-bit integer, to initialize its random sequence. In the previous code fragment, we used:
>
> ```cpp
> std::xoshiro256** gen(seed);
> ```
>
> Here, `seed` is a 64-bit integer. It ensures that every run of the program generates different numbers. We seed the generator using the current time from `std::chrono::high_resolution_clock::now()`. Since `Xoshiro256**` works directly with 64-bit values, we don't need additional type casting.
>
> The generator itself only produces random bits. _To convert those bits into a useful range, we use a distribution_. C++20 offers several kinds of distributions. For example, we use `std::uniform_int_distribution<int>`, which produces integers evenly spread across a given range:
>
> ```cpp
> std::uniform_int_distribution<int> distribution(1, 100);
> ```
>
> This tells the program to create numbers between $1$ and $100$, all with equal probability. When we call:
>
> ```cpp
> distribution(gen);
> ```
>
> The generator provides the random bits, and the distribution maps those bits to numbers between $1$ and $100$:
>
> | Name                      | Availability in C++     | Purpose                  | Description                                      | Characteristics                                       |
> |---------------------------|-------------------------|---------------------------|--------------------------------------------------|-------------------------------------------------------|
> | `std::uniform_int_distribution` | C++11 and later | Uniform distribution       | Generates integers uniformly within a range     | Constant time performance, unbiased results          |
> | `std::uniform_real_distribution`| C++11 and later | Uniform distribution       | Generates real numbers uniformly within a range | High precision, constant time performance            |
> | `std::normal_distribution`     | C++11 and later | Gaussian distribution      | Generates values with a normal distribution     | Good for simulations, may have performance overhead   |
> | `std::bernoulli_distribution`  | C++11 and later | Bernoulli trial            | Generates true/false with a given probability   | Fast, suitable for binary outcomes                   |
> | `std::binomial_distribution`   | C++11 and later | Binomial distribution      | Number of successes in a sequence of trials     | Effective for modeling discrete probability events   |
> | `std::geometric_distribution`  | C++11 and later | Geometric distribution     | Generates number of failures before success     | Useful for waiting-time scenarios, fast computation  |
> | `std::poisson_distribution`    | C++11 and later | Poisson distribution       | Models number of events in fixed interval       | Efficient for modeling rare events over time         |
> | `std::exponential_distribution`| C++11 and later | Exponential distribution   | Time between events in Poisson process          | Suitable for modeling interarrival times             |
> | `std::gamma_distribution`      | C++11 and later | Gamma distribution         | Models waiting times with shape and scale       | Flexible, used in various statistical applications   |
> | `std::weibull_distribution`    | C++11 and later | Weibull distribution       | Models failure times in reliability analysis    | Good for reliability modeling, shape-adjustable      |
> | `std::chi_squared_distribution`| C++11 and later | Chi-squared distribution   | Statistical measure of goodness-of-fit          | Common in hypothesis testing, moderate performance   |
> | `std::student_t_distribution`  | C++11 and later | Student's t-distribution   | Models differences between sample means         | Useful in statistical testing, heavy-tailed behavior |
> | `std::cauchy_distribution`     | C++11 and later | Cauchy distribution        | Heavy-tailed distribution, undefined variance   | Models outcomes with extreme values                  |
> | `std::lognormal_distribution`  | C++11 and later | Log-normal distribution    | Models growth rates of processes                | Skewed distribution, good for financial modeling     |
> | `std::discrete_distribution`   | C++11 and later | Discrete distribution      | Generates integers based on a set of probabilities | Useful for weighted random selection               |
> | `std::piecewise_constant_distribution` | C++11 and later | Piecewise constant distribution | Generates values with constant probability density within subranges | Good for custom-defined distributions |
> | `std::piecewise_linear_distribution`   | C++11 and later | Piecewise linear distribution | Generates values with linear probability density within subranges | Useful for modeling linear trends                   |
>
>_Table 2.4.B: This table outlines the distributions available in C++20, describing their purpose, characteristics, and usage. It covers a range of statistical distributions, highlighting their computational performance, suitability for different scenarios, and potential applications._
>
> C++20 keeps these ideas separate: generators produce bits, and distributions map those bits to useful values. You can also use other distributions like `std::normal_distribution` for normal (Gaussian) distributions or `std::bernoulli_distribution` for true/false outcomes.

Now that you have a understanding of the basics of `std::vector`, let’s move forward to one of its most common uses: sorting vectors. Sorting is a fundamental operation in computer science, and C++ provides efficient algorithms to handle this task directly. The `std::vector` allows seamless integration with sorting functions from the Standard Library, making it easy to sort elements in ascending, descending, or custom-defined order.

#### Sorting Vectors

In C++, sorting a vector is typically achieved using the `std::sort` algorithm, which operates with a time complexity of $O(n log n)$. This algorithm leverages highly optimized techniques, ensuring fast sorting even for large datasets. Next, let’s explore how to implement sorting operations on vectors, covering various sorting criteria and practical examples.

In C++20, `std::sort` is part of the `<algorithm>` header, retaining a similar interface to previous versions but with performance improvements and support for new C++20 features like ranges.

The sorting function uses the Introsort algorithm (a combination of QuickSort, HeapSort, and InsertionSort) to ensure an average time complexity of $O(n \log n)$ and is highly optimized for various data types.

>`Introsort`, short for _Introspective Sort_[^article1], is the underlying algorithm used by `std::sort` in the C++ Standard Library. It is designed to be a efficient hybrid sorting algorithm that adapts its behavior based on the characteristics of the input data. Introsort was invented by [David Musser](https://en.wikipedia.org/wiki/David_Musser) in 1997 and is chosen for its combination of speed, worst-case performance guarantees, and memory efficiency.
>
>Introsort starts by using _QuickSort_, a fast divide-and-conquer sorting algorithm. However, if the recursion depth becomes too large, indicating the possibility of poor performance (close to $O(n^2)$), it switches to _HeapSort_, which guarantees $O(n \log n)$ complexity. Finally, when the remaining partitions are small (typically fewer than 16 elements), it switches to _InsertionSort_, which is efficient for small arrays. Going deeper:
>
>1. **QuickSort Phase**: Initially, Introsort uses QuickSort, partitioning the array around a pivot and recursively sorting the subarrays. QuickSort is chosen due to its average-case complexity of $O(n \log n)$ and excellent performance in practice. The pivot selection in modern implementations of Introsort often uses the _median-of-three_ method, which improves partitioning stability. The median-of-three deserve a bit of attention:
>
>The *median-of-three* method is a technique used in sorting algorithms, particularly in _QuickSort_ and _Introsort_, to select a better pivot element. The pivot selection in QuickSort is crucial for its efficiency, as it determines how well the array is partitioned at each step. Poor pivot selection can lead to imbalanced partitions and degraded performance, potentially reaching $O(n^2)$ time complexity. The median-of-three approach helps mitigate this issue by choosing the pivot as the median of three specific elements in the array:
>
>1. **First element**
>2. **Middle element**
>3. **Last element**
>
>The median of these three values is then used as the pivot, rather than just using the first or last element, which could be problematic for sorted or nearly sorted arrays. Let's work an example:
>
>Consider an array $[5, 1, 9, 4, 6, 7, 3, 8, 2]$.
>
>1. **First element**: $5$
>2. **Middle element**: $6$ (index 4)
>3. **Last element**: $2$
>
>Now, we compare these three values: $5$, $6$, and $2$. The median of $5$, $6$, and $2$ is $5$. So, $5$ becomes the pivot. Or, using C++:
>
>
>```cpp
>int medianOfThree(int a, int b, int c) {
>    if ((a > b) == (a < c)) return a; // a é a mediana
>    else if ((b > a) == (b < c)) return b; // b é a mediana
>    else return c; // c é a mediana
>}
>```
>
>The median-of-three technique improves QuickSort’s performance by avoiding Worst-Case Partitions. In basic QuickSort, using the first or last element as the pivot can lead to worst-case scenarios, especially for already sorted or nearly sorted arrays. The median-of-three minimizes the chance of selecting a very poor pivot by making a more balanced choice. Also, the median-of-three improves partitioning quality. By choosing the median of three, the partitioning step becomes more likely to divide the array into relatively equal-sized subarrays, which is essential for achieving the $O(n \log n)$ average-case complexity. Finally, the median-of-three technique requires only a few additional comparisons, making it a low-cost improvement in most cases.
>
>In C++, the median-of-three is often used as part of the partitioning logic in QuickSort and Introsort implementations:
>
> ```cpp
>    #include <iostream>
>    #include <vector>
>
>    // Helper function to find the median of three
>    int medianOfThree(int a, int b, int c) {
>        if ((a > b) == (a < c)) return a; // a is the median
>        else if ((b > a) == (b < c)) return b; // b is the median
>        else return c; // c is the median
>    }
>
>    int main() {
>        std::vector<int> arr = {5, 1, 9, 4, 6, 7, 3, 8, 2};
>        int first = arr[0];
>        int middle = arr[arr.size() / 2];
>        int last = arr[arr.size() - 1];
>
>        int pivot = medianOfThree(first, middle, last);
>
>        std::cout << "The median-of-three pivot is: " << pivot << std::endl;
>        return 0;
>    }
> ```
>
>_Code XXXX:the function `medianOfThree` determines the median value among the three candidates, which is then used as the pivot for sorting_{: class="legend"}
>
>2. **HeapSort Phase**: If the recursion depth exceeds a certain limit (usually set to $2 \log n$), Introsort switches to HeapSort. This switch ensures a worst-case time complexity of $O(n \log n)$, as HeapSort is not sensitive to bad pivot choices like QuickSort. HeapSort is used to prevent QuickSort’s performance degradation on certain pathological cases, such as sorted or nearly sorted arrays.
>
>3. **InsertionSort Phase**: When partitions become small (typically fewer than 16 elements), Introsort switches to InsertionSort. InsertionSort is faster for small arrays due to its lower overhead, despite having a $O(n^2)$ worst-case complexity. This phase takes advantage of the partially sorted state left by previous steps, making InsertionSort very efficient for these cases. Table XXXX has a summary of Introsort characteristics.
>
>| **Property**                | **Description**                                                                                          |
|-----------------------------|----------------------------------------------------------------------------------------------------------|
>| **Average-case time complexity** | $O(n \log n)$                                                                                       |
>| **Worst-case time complexity**   | $O(n \log n)$, due to the switch to HeapSort when necessary                                          |
>| **Space complexity**        | $O(\log n)$ for the recursion stack                                                                      |
>| **Stable vs. unstable sorting** | Introsort is an unstable sort, meaning that equal elements might not retain their original order after sorting |
>| **In-place sorting**        | Introsort is an in-place sort, meaning it requires a constant amount of additional memory beyond the input array |
>
>_Table XXXX: Introsort characteristics_{: class="legend"}

Introsort is chosen for `std::sort` and for `std::ranges::sort` due to its: Adaptive behavior: It adjusts based on input data characteristics, ensuring fast and consistent sorting; Guaranteed performance: It avoids the potential pitfalls of QuickSort’s $O(n^2)$ worst-case time complexity; And Efficiency: Its combination of sorting algorithms offers both speed and efficiency for various types of data and distributions.

Using Introsort in `std::ranges::sort`, the following code sorts the vector `vec2` in ascending order. While the traditional approach using `std::sort` is still valid, C++20 offers a more concise syntax:

```cpp
// Traditional C++17 way - still perfectly valid
std::sort(vec2.begin(), vec2.end());

// C++20 way - shorter and cleaner
std::ranges::sort(vec2);
```

For competitive programming, we might want a shorter syntax. While macros are one option:

```cpp
#define SORT(v) std::ranges::sort(v)
SORT(vec2);
```

A type-safe alternative using C++20 features would be a simple `constexpr lambda`:

```cpp
constexpr auto sort = [](auto& v) { 
   std::ranges::sort(v); 
};
sort(vec2);
```

For cases where custom comparators are needed (like sorting in descending order), both approaches work:

```cpp
// Traditional way
std::sort(vec2.begin(), vec2.end(), std::greater<>());

// C++20 way
std::ranges::sort(vec2, std::greater<>());

// Or using our lambda
constexpr auto rsort = [](auto& v) { 
   std::ranges::sort(v, std::greater<>()); 
};

rsort(vec2);
```

The time complexity remains $O(n \log n)$ where $n$ is the number of elements in the vector. For competitive programming, both traditional and C++20 approaches are equally efficient, but the C++20 syntax can save a few keystrokes while maintaining type safety.

_Note: While C++20 offers more advanced features like concepts and complex constraints, in competitive programming scenarios, the simpler approaches shown above are usually sufficient and more practical under time pressure._

We can use `std::ranges::sort` with `std::greater<>()` comparator to sort elements in descending order. The implementation requires the `ranges` header and has a time complexity of $O(n \log n)$ where $n$ is the number of elements.

```cpp
#include <ranges>
#include <vector>

std::vector<int> vec = {5, 2, 9, 1, 5, 6};
std::ranges::sort(vec, std::greater<>());
```

This code fragment shows how to create a sequence where each element $a_i$ and $a_{i+1}$ satisfy:

$$a_i \geq a_{i+1} \text{ for } i \in [0, n-1]$$

`std::ranges::sort` allows the creation of custom projections and comparators (e.g. Odd Numbers First). The following code fragment implements this using C++20 features:

```cpp
constexpr auto odd_even_sort = [](std::ranges::input_range auto&& range) {
   std::ranges::sort(range, {}, [](int x) { 
       return std::pair{x % 2 == 0, x}; 
   });
};

std::vector<int> vec = {5, 2, 9, 1, 5, 6};
odd_even_sort(vec);
```

In this case, for elements $a$ and $b$, the ordering follows:

$$
\begin{cases}
\text{true} & \text{if } a \bmod 2 > b \bmod 2 \\
a < b & \text{if } a \bmod 2 = 1 \text{ and } b \bmod 2 = 1 \\
a > b & \text{if } a \bmod 2 = 0 \text{ and } b \bmod 2 = 0
\end{cases}
$$

The next example uses a projection to sort elements based on their remainder when divided by 3. The operation has time complexity $O(n \log n)$.

```cpp
std::vector<int> vec = {5, 2, 9, 1, 5, 6};
std::ranges::sort(vec, {}, [](int x) { return x % 3; });
```

For elements $a$ and $b$, the ordering is determined by:

$$
a \prec b \iff a \bmod 3 < b \bmod 3
$$

In addition to basic types, `std::ranges::sort` efficiently handles custom data types through projections and comparators. The following code fragment demonstrates sorting a vector of student records based on multiple criteria: GPA (descending) and age (ascending when GPAs are equal).

```cpp
struct Student {
   std::string name;
   double gpa;
   int age;
   
   Student(std::string n, double g, int a) 
       : name(n), gpa(g), age(a) {}
};

std::vector<Student> students = {
   {"Alice", 3.8, 20},
   {"Bob", 3.8, 19},
   {"Charlie", 3.9, 22},
   {"David", 3.7, 21}
};

constexpr auto float_eq = [](double a, double b) {
   return std::abs(a - b) < 
          std::numeric_limits<double>::epsilon() * 
          std::max(std::abs(a), std::abs(b));
};

std::ranges::sort(students, {}, [&](const Student& s) {
   return std::tuple{-s.gpa, s.age};  // negative gpa for descending order
});
```

In this case, the time complexity remains $O(n \log n)$ where $n$ is the number of students. The comparator performs constant time operations:

$$
\begin{cases}
\text{Compare GPAs} & O(1) \\
\text{Compare ages if GPAs equal} & O(1)
\end{cases}
$$

When dealing with floating-point comparisons, the code uses $\epsilon$-comparison ($1e-9$) to handle potential floating-point precision issues:

$$|a - b| < \epsilon \implies a \approx b$$

The space complexity is $O(1)$ as the comparison operations require only a constant amount of additional memory, independent of the input size.

#### Stable Sorting of Vectors

In C++, sorting a vector while preserving the relative order of equal elements is achieved using `std::stable_sort` from the `<algorithm>` header. This function ensures that elements considered equal retain their original order after sorting[^book2], which is essential in applications requiring stable sorting, such as when sorting records based on multiple criteria.

Unlike `std::sort`, which may not maintain the original order of equal elements due to its underlying algorithm, `std::stable_sort` guarantees stability by using a variation of the _Merge Sort algorithm_[^book2]. Merge Sort has a time complexity of $O(n \log n)$ and is inherently stable because it preserves the order of equal elements during the merge steps.

For example, consider a vector of `Person` structures:

```cpp
struct Person {
    std::string name;
    int age;
};

std::vector&lt;Person&gt; people = {
    {"Alice", 30},
    {"Bob", 25},
    {"Charlie", 25},
    {"David", 35}
};
```

If we want to sort `people` by age while maintaining the original order among people with the same age, we can use `std::stable_sort`:

```cpp
std::stable_sort(people.begin(), people.end(),
    [](const Person& a, const Person& b) {
        return a.age &lt; b.age;
    });
```

After sorting, "Bob" and "Charlie", both aged 25, will remain in their original order (Bob before Charlie) in the sorted vector.

The key difference between `std::sort` and `std::stable_sort` lies in their stability and underlying algorithms. `std::sort` uses Introsort, which is a hybrid of _QuickSort_, _HeapSort_, and _InsertionSort_, and is not guaranteed to be stable. In contrast, `std::stable_sort` uses a stable sorting algorithm, typically a hybrid of _Merge Sort_ and _InsertionSort_, to ensure stability.

_In competitive programming, using `std::stable_sort` can be advantageous when sorting data based on multiple criteria. Instead of writing complex comparison functions to handle all sorting criteria at once, one can perform multiple stable sorts in succession_. By sorting first on the least significant criterion and last on the most significant one, each stable sort preserves the ordering of the previous sorts for elements considered equal. For instance, suppose we have a list of students with `name`, `grade`, and `age`, and we want to sort them by `grade` in descending order, then by `age` in ascending order, and finally by `name` alphabetically. We can achieve this by performing multiple stable sorts:

```cpp
std::stable_sort(students.begin(), students.end(),
    [](const Student& a, const Student& b) {
        return a.name &lt; b.name;
    });

std::stable_sort(students.begin(), students.end(),
    [](const Student& a, const Student& b) {
        return a.age &lt; b.age;
    });

std::stable_sort(students.begin(), students.end(),
    [](const Student& a, const Student& b) {
        return a.grade &gt; b.grade;
    });
```

This sequence of stable sorts ensures that the final ordering reflects all the sorting criteria, with stability preserving the relative order from previous sorts.

Regarding the time and space complexity of `std::stable_sort`, its time complexity is $O(n \log n)$, similar to `std::sort`. This efficiency arises from its use of a divide-and-conquer algorithm, typically a variation of _Merge Sort_, which consistently performs well regardless of the initial order of the elements.

However, the space complexity of `std::stable_sort` can be higher than that of `std::sort`. Specifically, `std::stable_sort` may require additional memory proportional to $O(n)$ in the worst case. This extra space is needed because the merging process in Merge Sort requires temporary storage to combine the sorted subarrays. During the merge step, elements from the divided subarrays are copied into a temporary array to ensure that the stability of the sort is maintained—that is, equal elements retain their original relative positions.

In contrast, `std::sort` often uses in-place sorting algorithms like Introsort, which require only $O(\log n)$ additional space for the recursion stack. This difference means that while `std::stable_sort` provides the benefit of stability, it does so at the potential cost of increased memory usage. When working with large datasets or in environments with limited memory resources, this additional space requirement can be a significant consideration.

#### Vectors as Inputs and Outputs

In competitive programming, a common input format involves receiving the size of a vector as the first integer, followed by the elements of the vector separated by spaces, with a newline at the end. Below is an optimized version using `fread` for input and `putchar` for output, ensuring minimal system calls and fast execution.

This version reads the input, processes it, and then outputs the vector’s elements using the fastest possible I/O methods in C++.

```cpp
#include <cstdio>
#include <vector>

int main() {
    // Buffer for reading input
    char buffer[1 << 16]; // 64 KB buffer size
    int idx = 0;

    // Read the entire input at once
    size_t bytesRead = fread(buffer, 1, sizeof(buffer), stdin);

    // Parse the size of the vector from the input
    int n = 0;
    while (buffer[idx] >= '0' && buffer[idx] <= '9') {
        n = n * 10 + (buffer[idx++] - '0');
    }
    ++idx; // Skip the space or newline after the number

    // Create the vector and fill it with elements
    std::vector<int> vec(n);
    for (int i = 0; i < n; ++i) {
        int num = 0;
        while (buffer[idx] >= '0' && buffer[idx] <= '9') {
            num = num * 10 + (buffer[idx++] - '0');
        }
        vec[i] = num;
        ++idx; // Skip the space or newline after each number
    }

    // Output the vector elements using putchar
    for (int i = 0; i < n; ++i) {
        if (vec[i] == 0) putchar('0');
        else {
            int num = vec[i], digits[10], digitIdx = 0;
            while (num) {
                digits[digitIdx++] = num % 10;
                num /= 10;
            }
            // Print digits in reverse order
            while (digitIdx--) putchar('0' + digits[digitIdx]);
        }
        putchar(' '); // Space after each number
    }
    putchar('\n'); // End the output with a newline

    return 0;
}
```

In the previous code, we have the following functions:

1. **Input with `fread`**: `fread` is used to read the entire input into a large buffer at once. This avoids multiple system calls, which are slower than reading in bulk.

2. **Parsing the Input**: The input is parsed from the buffer using simple character arithmetic to convert the string of numbers into integers.

3. **Output with `putchar`**: `putchar` is used to print the numbers, which is faster than `std::cout` for individual characters. The digits of each number are processed and printed in reverse order.

The previous code method minimizes system calls and avoids using slower I/O mechanisms like `std::cin` and `std::cout`, making it highly optimized for competitive programming scenarios where speed is the success key.

In competitive programming, it's also common to handle input from a file provided via the command line. This scenario requires efficient reading and processing, especially when dealing with large datasets. Below is the optimized version using `fread` to read from a file specified in the command line argument and `putchar` for output.

#### Optimized Version Using `fread` and `putchar` with Command-Line File Input

This version reads the input file, processes it, and outputs the vector’s elements, ensuring fast I/O performance.

```cpp
#include <cstdio>
#include <vector>

int main(int argc, char* argv[]) {
    // Check if the filename was provided
    if (argc != 2) {
        return 1;
    }

    // Open the file from the command line argument
    FILE* file = fopen(argv[1], "r");
    if (!file) {
        return 1;
    }

    // Buffer for reading input
    char buffer[1 << 16]; // 64 KB buffer size
    int idx = 0;

    // Read the entire input file at once
    size_t bytesRead = fread(buffer, 1, sizeof(buffer), file);
    fclose(file); // Close the file after reading

    // Parse the size of the vector from the input
    int n = 0;
    while (buffer[idx] >= '0' && buffer[idx] <= '9') {
        n = n * 10 + (buffer[idx++] - '0');
    }
    ++idx; // Skip the space or newline after the number

    // Create the vector and fill it with elements
    std::vector<int> vec(n);
    for (int i = 0; i < n; ++i) {
        int num = 0;
        while (buffer[idx] >= '0' && buffer[idx] <= '9') {
            num = num * 10 + (buffer[idx++] - '0');
        }
        vec[i] = num;
        ++idx; // Skip the space or newline after each number
    }

    // Output the vector elements using putchar
    for (int i = 0; i < n; ++i) {
        if (vec[i] == 0) putchar('0');
        else {
            int num = vec[i], digits[10], digitIdx = 0;
            while (num) {
                digits[digitIdx++] = num % 10;
                num /= 10;
            }
            // Print digits in reverse order
            while (digitIdx--) putchar('0' + digits[digitIdx]);
        }
        putchar(' '); // Space after each number
    }
    putchar('\n'); // End the output with a newline

    return 0;
}
```

In the previous code we have:

1. **File Input with `fread`**: The input is read from a file specified in the command line argument using `fread`. This reads the entire file into a buffer in one go, improving efficiency by reducing system calls.

2. **File Handling**: The file is opened using `fopen` and closed immediately after reading the data. This ensures that system resources are released as soon as the file reading is complete.

3. **Parsing and Output**: The rest of the program processes the input similarly to the previous version, parsing the numbers from the buffer and outputting them efficiently using `putchar`.

This approach remains highly optimized for competitive programming environments where fast I/O handling is critical. But, in Linux we can use `mmap`. As we can see in Code 2.4.A.

```cpp
#include <sys/mman.h>
#include <fcntl.h>
#include <unistd.h>
#include <sys/stat.h>
#include <vector>
#include <iostream>

int main(int argc, char* argv[]) {
    if (argc != 2) {
        return 1;
    }

    // Open the file
    int fd = open(argv[1], O_RDONLY);
    if (fd == -1) {
        return 1;
    }

    // Get the file size
    struct stat sb;
    if (fstat(fd, &sb) == -1) {
        close(fd);
        return 1;
    }
    size_t fileSize = sb.st_size;

    // Memory-map the file
    char* fileData = static_cast<char*>(mmap(nullptr, fileSize, PROT_READ, MAP_PRIVATE, fd, 0));
    if (fileData == MAP_FAILED) {
        close(fd);
        return 1;
    }

    close(fd); // The file descriptor can be closed after mapping

    // Parse the vector size
    int idx = 0;
    int n = 0;
    while (fileData[idx] >= '0' && fileData[idx] <= '9') {
        n = n * 10 + (fileData[idx++] - '0');
    }
    ++idx; // Skip the space or newline

    // Create the vector and fill it with values from the memory-mapped file
    std::vector<int> vec(n);
    for (int i = 0; i < n; ++i) {
        int num = 0;
        while (fileData[idx] >= '0' && fileData[idx] <= '9') {
            num = num * 10 + (fileData[idx++] - '0');
        }
        vec[i] = num;
        ++idx; // Skip the space or newline
    }

    // Output the vector
    for (const int& num : vec) {
        std::cout << num << " ";
    }
    std::cout << std::endl;

    // Unmap the file from memory
    munmap(fileData, fileSize);

    return 0;
}
```

_Code 2.4.A: Using `mmap` in linux._{: class="legend"}

### 2.4.2. Using Matrices

In C++20, matrices are typically represented as vectors of vectors (`std::vector<std::vector<T>>`), where each inner vector represents a row of the matrix. This approach allows for dynamic sizing and easy manipulation of multi-dimensional data, making matrices ideal for problems involving grids, tables, or any 2D structure.

Matrices in C++ offer flexibility in managing data: you can resize rows and columns independently, access elements using intuitive indexing, and leverage standard vector operations for rows. Additionally, the use of `ranges` and `views` introduced in C++20 boosts the ability to iterate and transform matrix data more expressively and efficiently.

_The use of matrices is common in competitive programming for tasks such as implementing dynamic programming tables, graph adjacency matrices, or performing transformations on 2D data. With the powerful capabilities of C++20's STL, matrices become a highly adaptable and efficient way to handle complex, multi-dimensional computations in a structured manner_.

#### Creating and Filling a Matrix

The code creates a 2x2 matrix (a vector of vectors) and fills each element with the value 1:

**Standard Version:**

```cpp
int rows = 2, cols = 2;
std::vector<std::vector<int>> matrix(rows, std::vector<int>(cols));

for (int i = 0; i < rows; ++i) {
    for (int j = 0; j < cols; ++j) {
        matrix[i][j] = 1;
    }
}
```

In this fragment, $\text{std::vector<std::vector<int>> matrix(rows, std::vector<int>(cols));}$ creates a matrix of size $2\times 2$. The nested `for` loop fills each element of the matrix with $1$.

**Optimized for Minimal Typing:**

```cpp
std::vector<std::vector<int>> matrix(2, std::vector<int>(2, 1));
```

This version eliminates the need for the explicit loop by using the constructor to initialize the matrix with 1s directly.

#### Displaying the Matrix

Finally, the matrix is printed in the standard format:

**Standard Version:**

```cpp
for (const auto& row : matrix) {
    for (const auto& element : row) {
        std::cout << element << " ";
    }
    std::cout << std::endl;
}
```

The loop iterates over each row and prints all elements in the row, followed by a newline.

**Optimized for Minimal Typing:**

```cpp
for (const auto& row : matrix) {
    for (int el : row) std::cout << el << " ";
    std::cout << "\n";
}
```

Here, we replaced `std::endl` with `"\n"` to improve performance by avoiding the unnecessary flushing of the output buffer.

#### Inserting Elements at a Specific Position

To insert an element at a specific position in a matrix (vector of vectors) in C++ 20, we use the `insert` function. This function can insert rows or columns in a specific location, modifying the structure of the matrix.

```cpp
#include <iostream>
#include <vector>

int main() {
    std::vector<std::vector<int>> matrix = { {1, 2}, {3, 4} };

    // Insert a row at position 1
    matrix.insert(matrix.begin() + 1, std::vector<int>{5, 6});

    // Insert a column value at position 0 in the first row
    matrix[0].insert(matrix[0].begin(), 0);

    // Display the modified matrix
    for (const auto& row : matrix) {
        for (int el : row) std::cout << el << " ";
        std::cout << "\n";
    }

    return 0;
}
```

_Code 2.4.B: Example to show how to insert a new row at position 1 and a new column value at position 0 in the first row. The result is a modified matrix_.{: class="legend"}

#### Removing the Last Element and a Specific Element

To remove the last element of a matrix or a specific element, you can use the `pop_back` function for removing the last row and the `erase` function for removing specific rows or columns.

```cpp
#include <iostream>
#include <vector>

int main() {
    std::vector<std::vector<int>> matrix = { {1, 2}, {3, 4}, {5, 6} };

    // Remove the last row
    matrix.pop_back();

    // Remove the first element of the first row
    matrix[0].erase(matrix[0].begin());

    // Display the modified matrix
    for (const auto& row : matrix) {
        for (int el : row) std::cout << el << " ";
        std::cout << "\n";
    }

    return 0;
}
```

_Code 2.4.C: Example to show how to removes the last row from the matrix and removes the first element of the first row_.{: class="legend"}

#### Creating a New Matrix with a Default Value

To create a new matrix filled with a default value, you can specify this value in the constructor of the vector.

```cpp
#include <iostream>
#include <vector>

int main() {
    // Create a 3x3 matrix filled with the default value 7
    std::vector<std::vector<int>> matrix(3, std::vector<int>(3, 7));

    // Display the matrix
    for (const auto& row : matrix) {
        for (int el : row) std::cout << el << " ";
        std::cout << "\n";
    }

    return 0;
}
```

_Code 2.4.C: Example to show how to initializes a 3x3 matrix with all elements set to $7$_.{: class="legend"}

#### Resizing and Filling with Random Values

To resize a matrix and fill it with random values, you can use the `resize` function along with the `<random>` library.

```cpp
#include <iostream>
#include <vector>
#include <random>

int main() {
    std::vector<std::vector<int>> matrix;
    int rows = 3, cols = 3;

    // Resize the matrix
    matrix.resize(rows, std::vector<int>(cols));

    // Fill the matrix with random values
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_int_distribution<> dis(1, 10);

    for (auto& row : matrix) {
        for (auto& el : row) {
            el = dis(gen);
        }
    }

    // Display the matrix
    for (const auto& row : matrix) {
        for (int el : row) std::cout << el << " ";
        std::cout << "\n";
    }

    return 0;
}
```

_Code 2.4.E: Example to show how resizes the matrix to 3x3 and fills it with random values between $1$ and $2.8$_.{: class="legend"}

#### Sorting Matrices by Rows and Columns

In C++20, we can sort matrices (represented as vectors of vectors) both by rows and by columns. Here are examples of how to do both:

##### 2.5.7.1 Sorting by Rows

Sorting by rows is straightforward, as we can use the `std::sort` function directly on each row of the matrix.

```cpp
#include <iostream>
#include <vector>
#include <algorithm>

int main() {
   std::vector<std::vector<int>> matrix = {
        {3, 1, 4}, {1, 5, 9}, {2, 6, 5}
    };

   // Sort each row of the matrix
   for (auto& row : matrix) {
       std::sort(row.begin(), row.end());
   }

   // Display the sorted matrix
   for (const auto& row : matrix) {
       for (int el : row) std::cout << el << " ";
       std::cout << "\n";
   }

   return 0;
}
```

This code sorts each row of the matrix independently. The time complexity for sorting by rows is $O(m \cdot n \log n)$, where $m$ is the number of rows and $n$ is the number of columns.

##### 2.5.7.2 Sorting by Columns

Sorting by columns is more complex because the elements in a column are not contiguous in memory. We need to extract each column, sort it, and then put the sorted elements back into the matrix.

```cpp
#include <iostream>
#include <vector>
#include <algorithm>

int main() {
   std::vector<std::vector<int>> matrix = { {3, 1, 4}, {1, 5, 9}, {2, 6, 5} };
   int rows = matrix.size();
   int cols = matrix[0].size();

   // Sort each column of the matrix
   for (int j = 0; j < cols; ++j) {
       std::vector<int> column;
       for (int i = 0; i < rows; ++i) {
           column.push_back(matrix[i][j]);
       }
       std::sort(column.begin(), column.end());
       for (int i = 0; i < rows; ++i) {
           matrix[i][j] = column[i];
       }
   }

   // Display the sorted matrix
   for (const auto& row : matrix) {
       for (int el : row) std::cout << el << " ";
       std::cout << "\n";
   }

   return 0;
}
```

This code sorts each column of the matrix independently. The time complexity for sorting by columns is $O(n \cdot m \log m)$, where $n$ is the number of columns and $m$ is the number of rows.

Note that this method of sorting by columns is not the most efficient for very large matrices, as it involves many data copies. For large matrices, it might be more efficient to use an approach that sorts the row indices based on the values in a specific column.

#### Optimizing Matrix Input and Output in Competitive Programming

Let's explore optimized techniques in C++ that minimize system calls and maximize execution speed.

Typically, the input for a matrix consists of:

1. Two integers $n$ and $m$, representing the number of rows and columns, respectively.
2. $n \times m$ elements of the matrix, separated by spaces and newlines.

For example:

```txt
3 4
1 2 3 4
5 6 7 8
9 10 11 12
```

#### Optimized Reading with `fread`

To optimize reading, we can use `fread` to load the entire input at once into a buffer, then parse the numbers from the buffer. This approach reduces the number of system calls compared to reading the input one character or one line at a time.

```cpp
#include <cstdio>
#include <vector>

int main() {
    char buffer[1 << 16];
    size_t bytesRead = fread(buffer, 1, sizeof(buffer), stdin);
    size_t idx = 0;

    auto readInt = [&](int& num) {
        while (idx < bytesRead && (buffer[idx] < '0' || buffer[idx] > '9') && buffer[idx] != '-') ++idx;
        bool neg = false;
        if (buffer[idx] == '-') {
            neg = true;
            ++idx;
        }
        num = 0;
        while (idx < bytesRead && buffer[idx] >= '0' && buffer[idx] <= '9') {
            num = num * 10 + (buffer[idx++] - '0');
        }
        if (neg) num = -num;
    };

    int n, m;
    readInt(n);
    readInt(m);

    std::vector<std::vector<int>> matrix(n, std::vector<int>(m));
    for (int i = 0; i < n; ++i) {
        for (int j = 0; j < m; ++j) {
            readInt(matrix[i][j]);
        }
    }

    // Matrix processing...

    return 0;
}
```

In this code: We define a lambda function `readInt` to read integers from the buffer, handling possible whitespace and negative numbers. The `readInt` function skips over any non-digit characters and captures negative signs. This ensures robust parsing of the input data.

##### Optimized Output with `putchar_unlocked`

For output, using `putchar_unlocked` offers better performance than `std::cout` or even `putchar`, as it is not thread-safe and thus faster.

```cpp
#include <cstdio>
#include <vector>

void writeInt(int num) {
    if (num == 0) {
        putchar_unlocked('0');
        return;
    }
    if (num < 0) {
        putchar_unlocked('-');
        num = -num;
    }
    char digits[10];
    int idx = 0;
    while (num) {
        digits[idx++] = '0' + num % 10;
        num /= 10;
    }
    while (idx--) {
        putchar_unlocked(digits[idx]);
    }
}

int main() {
    // Assume matrix is already populated
    int n = /* number of rows */;
    int m = /* number of columns */;
    std::vector<std::vector<int>> matrix = /* your matrix */;

    for (int i = 0; i < n; ++i) {
        for (int j = 0; j < m; ++j) {
            writeInt(matrix[i][j]);
            putchar_unlocked(j == m - 1 ? '\n' : ' ');
        }
    }

    return 0;
}
```

In this code: We define a function `writeInt` to output integers efficiently. It handles zero and negative numbers correctly, and we use `putchar_unlocked` for faster character output.

> `putchar_unlocked` is a non-thread-safe version of `putchar`. It writes a character to `stdout` without locking the output stream, eliminating the overhead associated with ensuring thread safety. This makes `putchar_unlocked` faster than `putchar`, which locks the output stream to prevent concurrent access from multiple threads.
>
> When comparing `putchar` and `putchar_unlocked`, we find that `putchar` is thread-safe and locks `stdout` to prevent data races, but incurs overhead due to locking. On the other hand, `putchar_unlocked` is not thread-safe and does not lock `stdout`, making it faster due to the absence of locking overhead.
>
> Here's an example of using `putchar_unlocked` to output an integer efficiently:
>
> ```cpp
> #include <cstdio>
>
> void writeInt(int num) {
>    if (num == 0) {
>        putchar_unlocked('0');
>        return;
>    }
>    if (num < 0) {
>        putchar_unlocked('-');
>        num = -num;
>    }
>    char digits[10];
>    int idx = 0;
>    while (num) {
>        digits[idx++] = '0' + (num % 10);
>        num /= 10;
>    }
>    while (idx--) {
>        putchar_unlocked(digits[idx]);
>    }
> }
>
> int main() {
>    int number = 12345;
>    writeInt(number);
>    putchar_unlocked('\n');
>    return 0;
> }
> ```
>
> In contrast, using `putchar` would involve replacing `putchar_unlocked` with `putchar`:
>
> ```cpp
> #include <cstdio>
>
> void writeInt(int num) {
>    if (num == 0) {
>        putchar('0');
>        return;
>    }
>    if (num < 0) {
>        putchar('-');
>        num = -num;
>    }
>    char digits[10];
>    int idx = 0;
>    while (num) {
>        digits[idx++] = '0' + (num % 10);
>        num /= 10;
>    }
>    while (idx--) {
>        putchar(digits[idx]);
>    }
> }
>
> int main() {
>    int number = 12345;
>    writeInt(number);
>    putchar('\n');
>    return 0;
> }
> ```
>
> `putchar_unlocked` is best used in single-threaded programs where maximum output performance is required. It's particularly >useful in competitive programming scenarios where execution time is critical and the program is guaranteed to be >single-threaded.
>
> However, caution must be exercised when using `putchar_unlocked`. It is not thread-safe, and in multi-threaded applications, >using it can lead to data races and undefined behavior. Additionally, it is a POSIX function and may not be available or >behave differently on non-POSIX systems.
>
> _Both `putchar` and `putchar_unlocked` are functions from the C standard library `<cstdio>`, which is included in C++ for >compatibility purposes. The prototype for `putchar` is `int putchar(int character);`, which writes the character to `stdout` >and returns the character written, or `EOF` on error. It is thread-safe due to internal locking mechanisms_.
>
> The prototype for `putchar_unlocked` is `int putchar_unlocked(int character);`. It's a faster version of `putchar` without >internal locking, but it's not thread-safe and may not be part of the C++ standard in all environments.
>
> If both performance and thread safety are needed, consider using buffered output or high-performance C++ I/O techniques. For >example:
>
> ```cpp
> #include <iostream>
> #include <vector>
>
> int main() {
>    std::ios::sync_with_stdio(false);
>    std::cin.tie(nullptr);
>
>    std::vector<int> numbers = {1, 2, 3, 4, 5};
>    for (int num : numbers) {
>        std::cout << num << ' ';
>    }
>    std::cout << '\n';
>
>    return 0;
> }
> ```
>
> By untethering C++ streams from C streams using `std::ios::sync_with_stdio(false);` and untangling `cin` from `cout` with >`std::cin.tie(nullptr);`, you can achieve faster I/O while maintaining thread safety and standard compliance.

The time complexity for reading and writing matrices is $O(nm)$, where $n$ and $m$ are the dimensions of the matrix. The space complexity is also $O(nm)$, as we store the entire matrix in memory. However, the constant factors are significantly reduced compared to standard I/O methods, leading to faster execution times in practice.

##### Using `mmap` on Unix Systems for Matrices

On Unix systems, we can use `mmap` to map a file (or standard input) directly into memory, potentially improving I/O performance even further.

```cpp
#include <sys/mman.h>
#include <fcntl.h>
#include <unistd.h>
#include <sys/stat.h>
#include <vector>
#include <cstdio>

int main() {
    struct stat sb;
    fstat(0, &sb); // File descriptor 0 is stdin
    size_t fileSize = sb.st_size;
    char* data = static_cast<char*>(mmap(nullptr, fileSize, PROT_READ, MAP_PRIVATE, 0, 0));

    size_t idx = 0;

    auto readInt = [&](int& num) {
        while (idx < fileSize && (data[idx] < '0' || data[idx] > '9') && data[idx] != '-') ++idx;
        bool neg = false;
        if (data[idx] == '-') {
            neg = true;
            ++idx;
        }
        num = 0;
        while (idx < fileSize && data[idx] >= '0' && data[idx] <= '9') {
            num = num * 10 + (data[idx++] - '0');
        }
        if (neg) num = -num;
    };

    int n, m;
    readInt(n);
    readInt(m);

    std::vector<std::vector<int>> matrix(n, std::vector<int>(m));
    for (int i = 0; i < n; ++i) {
        for (int j = 0; j < m; ++j) {
            readInt(matrix[i][j]);
        }
    }

    munmap(data, fileSize);

    // Matrix processing...

    return 0;
}
```

_**Note:** Using `mmap` can be risky, as it relies on the entire input being available and may not be portable across different systems or handle input streams properly. Use it only when you are certain of the input's nature and when maximum performance is essential._

_**Remember:** The efficiency of these approaches comes at the cost of increased code complexity and reduced readability. In scenarios where performance is not critical, standard I/O methods are preferable for their simplicity and maintainability._

### 2.4.3. Using Span and Ranges

In the fast-paced world of competitive programming and high-performance computing, efficient data manipulation is paramount. C++20 introduces two powerful features - `std::span` and `std::ranges` for that.

These features are particularly important because they address common performance bottlenecks in data-intensive applications. `std::span` provides a lightweight, non-owning view into contiguous data, reducing unnecessary copying and allowing for flexible, efficient data access. `std::ranges`, on the other hand, offers a unified, composable interface for working with sequences of data, enabling more intuitive and often more performant algorithm implementations. Together, they form a potent toolkit for developers seeking to push the boundaries of what's possible in terms of code efficiency and elegance in C++.

#### Using `std::span`

The `std::span` is a new feature introduced in C++20 that allows you to create lightweight, non-owning views of arrays and containers, such as `std::vector`. This avoids unnecessary copying of data and provides a flexible and efficient way to access and manipulate large blocks of data. `std::span` can be particularly useful when working with large datasets, file I/O, or when optimizing memory usage in competitive programming.

Unlike containers such as `std::vector`, `std::span` doesn't own the data it references. This means it doesn't allocate new memory and works directly with existing data, leading to lower memory overhead. Additionally, `std::span` can work with both static arrays and dynamic containers (like `std::vector`) without requiring copies. It provides safer array handling compared to raw pointers, as it encapsulates size information. Since `std::span` eliminates the need for memory copies, it can speed up operations where large datasets need to be processed in-place, or only certain views of data are required.

**Example of `std::span` for Efficient Data Access**:

In this example, we create a `std::span` from a `std::vector` of integers, allowing us to iterate over the vector’s elements without copying the data:

```cpp
#include <iostream>
#include <span>
#include <vector>

int main() {
    // Create a vector of integers
    std::vector<int> numbers = {1, 2, 3, 4, 5};

    // Create a span view of the vector
    std::span<int> view(numbers);

    // Iterate over the span and print the values
    for (int num : view) {
        std::cout << num << " ";
    }
    std::cout << std::endl;

    return 0;
}
```

`std::span<int> view(numbers);` creates a non-owning view of the `std::vector<int>` `numbers`. This allows access to the elements of the vector without copying them. The loop `for (int num : view)` iterates over the elements in the `std::span`, just like it would with the original `std::vector`, but with no additional overhead from copying the data.

##### Efficient Use Cases for `std::span`

`std::span` is especially useful when you want to work with sub-ranges of arrays or vectors. For example, when working with just part of a large dataset, you can use `std::span` to reference a subset without slicing or creating new containers:

```cpp
std::span<int> subrange = view.subspan(1, 3); // Access elements 1, 2, and 3
for (int num : subrange) {
    std::cout << num << " "; // Outputs: 2 3 4
}
```

When passing data to functions, `std::span` provides an efficient alternative to passing large vectors or arrays by reference. You can pass a span instead, ensuring that no copies are made, while maintaining full access to the original data:

```cpp
void process_data(std::span<int> data) {
    for (int num : data) {
        std::cout << num << " ";
    }
    std::cout << std::endl;
}

int main() {
    std::vector<int> numbers = {10, 20, 30, 40, 50};
    process_data(numbers); // Pass the vector as a span
    return 0;
}
```

In the early example, the function `process_data` accepts a `std::span`, avoiding unnecessary copies and keeping the original data structure intact.

##### Comparing `std::span` to Traditional Methods

| Feature          | `std::vector`           | Raw Pointers          | `std::span`     |
| ---------------- | ----------------------- | --------------------- | --------------- |
| Memory Ownership | Yes                     | No                    | No              |
| Memory Overhead  | High (allocates memory) | Low                   | Low             |
| Bounds Safety    | High                    | Low                   | High            |
| Compatibility    | Works with STL          | Works with raw arrays | Works with both |

Unlike `std::vector`, which manages its own memory, `std::span` does not allocate or own memory. This is similar to raw pointers but with added safety since `std::span` knows its size. `std::span` is safer than raw pointers because it carries bounds information, helping avoid out-of-bounds errors. While raw pointers offer flexibility, they lack the safety features provided by modern C++.

##### Practical Application: Using `std::span` in Competitive Programming

When working with large datasets in competitive programming, using `std::span` avoids unnecessary memory copies, making operations faster and more efficient. You can easily pass sub-ranges of data to functions without creating temporary vectors or arrays. Additionally, it allows you to maintain full control over memory without introducing complex ownership semantics, as with `std::unique_ptr` or `std::shared_ptr`.

**Example: Efficiently Passing Data in a Competitive Programming Scenario**:

```cpp
#include <iostream>
#include <span>
#include <vector>

void solve(std::span<int> data) {
    for (int num : data) {
        std::cout << num * 2 << " "; // Example: print double each value
    }
    std::cout << std::endl;
}

int main() {
    std::vector<int> input = {100, 200, 300, 400, 500};

    // Use std::span to pass the entire vector without copying
    solve(input);

    // Use a subspan to pass only a portion of the vector
    solve(std::span<int>(input).subspan(1, 3)); // Pass elements 200, 300, 400

    return 0;
}
```

### 2.4.4. Data Manipulation with `std::ranges`

C++20 brought the `<ranges>` library—a tool for handling data sequences with power and ease. It works through lazy views and composable transformations. `std::ranges` lets you create views over containers or arrays, avoiding changes and extra copies. In competitive programming and high-performance tasks, cutting down on memory and computation is key.

With `std::vector` and other containers, you often need extra storage or loops for things like filtering, transforming, or slicing data. `std::ranges` changes that. It lets you chain operations in a simple, expressive way without losing speed. It uses lazy evaluation, meaning transformations only happen when needed, not upfront.

`std::ranges` revolves around "views" of data, a windows that let you look at and manipulate sequences without owning them. A view acts like a container, but it doesn't hold the data itself. It just provides a way to interact with it, making operations light and efficient.

The advantage? `std::ranges` stacks operations without creating new containers, saving memory. Traditional methods create copies with every action (filter, transform, slice) adding overhead. Ranges avoid this, evaluating only when the data is accessed. Memory stays low, performance stays high, especially with big data.

Performance gains also come from optimized operations. By working lazily and directly on the data, `std::ranges` avoids unnecessary copies and allocations. The result is better cache usage and fewer CPU cycles wasted on managing temporary structures.

**Example Filtering and Transforming Data with `std::ranges`**:

Suppose we have a vector of integers and we want to filter out the odd numbers and then multiply the remaining even numbers by two. Using traditional methods, we would need to loop through the vector, apply conditions, and store the results in a new container. With `std::ranges`, this can be done in a more expressive and efficient way:

```cpp
#include <iostream>
#include <vector>
#include <ranges>
#include <span>

int main() {
    // Sample data
    std::vector<int> data = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};

    // Using std::span to create a view over the existing data without copying
    std::span<int> data_span(data);

    // Using std::ranges to filter and transform data lazily
    auto processed_view = data_span
        | std::views::filter([](int x) { return x % 2 == 0; }) // Filter even numbers
        | std::views::transform([](int x) { return x * x; });  // Square each number

    // Iterating over the processed view
    for (int value : processed_view) {
        std::cout << value << " ";
    }

    return 0;
}

```

The line that creates `processed_view` does the heavy lifting. It uses `std::span` and `std::ranges` to work smart, not hard. Here's what happens, step by step:

```cpp
auto processed_view = data_span
        | std::views::filter([](int x) { return x % 2 == 0; })
        | std::views::transform([](int x) { return x * x; });
```

First, `data_span` is a direct window into the data. No copies, no waste. Then comes `std::views::filter`. It uses a lambda function, which is just a fancy name for a tiny, anonymous function that you write right there. The filter is simple—it checks each number, `[] (int x) { return x % 2 == 0; }`. It says, "If the number is even, keep it; if not, toss it." No fuss.

Next is `std::views::transform`. It’s another lambda, `[] (int x) { return x * x; }`. It takes what’s left from the filter and squares each number. The job is done on the fly, no waiting. The power here is that everything happens only when needed. No intermediate results, no unnecessary containers. Just efficient, on-demand calculation. The functions do their work with precision—like a scalpel, not a sledgehammer.

> The `|` operator in C++20 is called the pipe operator. It chains ranges together, like pieces of a machine, one feeding into the next, just like a Unix pipeline. In the `processed_view` line, it links `std::views::filter` first, then `std::views::transform`. Data moves step by step, each part doing its job without extra fuss. No need for temporary variables or extra code. It’s clean, efficient. Each transformation builds on the last, clear as a straight line.
>
> But the pipe doesn’t stop with ranges. You can use it with custom classes or user types too. Overload the operator, and you’ve got yourself a clear chain of actions, each link precise and sharp. It can take complex operations and make them simple, one step feeding the next, easy to read and hard to get wrong.
>
> The pipe works with I/O too. It lets you stack stream manipulators like a craftsman arranging his tools,`std::cout | std::hex | std::uppercase`. It’s smooth, no clutter. In functional code, pipes connect functions, turning data flow into a straight path. They make the code tell a story—one step at a time, each part pulling its weight.
>
> The `|` operator isn’t just a trick for ranges; it’s a way to keep the code honest. It turns complex work into a direct line, clear, readable, and true to the task.

One of the main strengths of `std::ranges` is how you can stack operations, one on top of the other. You filter, you transform, you slice—and it all stays as a view. No extra containers, no wasted steps. You build a pipeline that works only when you call on it, no sooner. It’s efficient and lean, cutting through the data like a sharp knife. You get what you need when you need it, nothing more. The code is clean, each piece doing its job, each step feeding the next without clutter or delay.

Consider another example, where we filter, transform, and take only a part of the data:

```cpp
#include <iostream>
#include <vector>
#include <ranges>
#include <span>

int main() {
    // Sample data
    std::vector<int> data = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};

    // Using std::span to create a direct, non-owning view of the data
    std::span<int> data_span(data);

    // Using std::ranges with std::span to filter, transform, and limit the data efficiently
    auto processed_view = data_span
        | std::views::filter([](int x) { return x % 2 == 0; })  // Filter even numbers
        | std::views::transform([](int x) { return x * x; })   // Square each number
        | std::views::take(3);                                // Take the first 3 elements

    // Iterate over the processed view
    for (int value : processed_view) {
        std::cout << value << " ";
    }

    return 0;
}
```

In this example, we stack three operations. First, we filter the numbers, keeping those $20$ or higher. Then, we double them. Finally, we take the first three. It all happens lazily, nothing done until you need it. When you loop through the final view, `result`, that's when the work gets done. No extra containers, no wasted steps. Each transformation hits just once, right where it counts. The code stays lean, the processing sharp and efficient, doing just enough—no more, no less.

2.8. Loops the Heart of All Competitive Programming

Loops are, without a doubt, the most important part of any code, whether for competitive programming, high-performance applications, or even solving academic problems. Most programming languages offer more than one way to implement loops. In this text, since Python is only our pseudocode language, we will focus on studying loops in C++.

## 2.8. Understand `for` Loops

C++ provides several ways to iterate over elements in a vector, using different types of `for` loops. In this section, we will explore the various `for` loop options available in C++20, discussing their performance and code-writing efficiency. We will also analyze which loops are best suited for competitive programming based on input size—whether dealing with small or large datasets.

### 2.8.1 `for` Loop with Iterator

The `for` loop using iterators is one of the most efficient ways to iterate over a vector, especially for complex operations where you need to manipulate the elements or the iterator’s position directly.

```cpp
for (auto it = vec.begin(); it != vec.end(); ++it) {
    std::cout << *it << " ";
}
```

Utilizing iterators directly avoids unnecessary function calls such as `operator[]` and allows fine-grained control over the iteration. Ideal when detailed control over the iterator is necessary or when iterating over containers that do not support direct index access (e.g., `std::list`).

**Input Size Consideration**:

- **For Small Inputs**: This is a solid option as it allows precise control over the iteration with negligible overhead.
- **For Large Inputs**: Highly efficient due to minimal overhead and memory usage. However, ensure that the iterator’s operations do not induce cache misses, which can slow down performance for large datasets.

### 2.8.2. Classic `for` Loop with Index

The classic `for` loop using an index is efficient and provides precise control over the iteration process.

```cpp
for (size_t i = 0; i < vec.size(); ++i) {
    std::cout << vec[i] << " ";
}
```

Accessing elements via index is fast, but re-evaluating `vec.size()` in each iteration can introduce a small overhead. Useful when you need to access or modify elements by their index or when you may need to adjust the index inside the loop.

**Input Size Consideration**:

- **For Small Inputs**: Efficient and straightforward, especially when the overhead of re-evaluating `vec.size()` is negligible.
- **For Large Inputs**: If performance is critical, store `vec.size()` in a separate variable before the loop to avoid repeated function calls, which can become significant for larger datasets.

### 2.8.3. Range-Based `for-each` with Constant Reference

Range-based `for-each` with constant reference is highly efficient for reading elements since it avoids unnecessary copies.

```cpp
for (const auto& elem : vec) {
    std::cout << elem << " ";
}
```

Using constant references avoids copying, making it very efficient for both memory and execution time. Recommended for reading elements when you don’t need to modify values or access their indices.

**Input Size Consideration**:

- **For Small Inputs**: Ideal for minimal syntax and efficient execution.
- **For Large Inputs**: Excellent choice due to the avoidance of element copies, ensuring optimal memory usage and performance.

### 2.8.4. Range-Based `for-each` by Value

The `for-each` loop can also iterate over elements by value, which is useful when you want to work with copies of the elements.

```cpp
for (auto elem : vec) {
    std::cout << elem << " ";
}
```

Elements are copied, which can reduce performance, especially for large data types. Useful when you need to modify a copy of the elements without affecting the original vector.

**Input Size Consideration**:

- **For Small Inputs**: Suitable when the overhead of copying is negligible, especially if you need to modify copies of elements.
- **For Large Inputs**: Avoid for large datasets or large element types, as the copying can lead to significant performance degradation.

### 2.8.5. `for` Loop with Range Views (C++20)

C++20 introduced `range views`, which allow iteration over subsets or transformations of elements in a container without creating copies.

```cpp
for (auto elem : vec | std::views::reverse) {
    std::cout << elem << " ";
}
```

Range views allow high-performance operations, processing only the necessary elements. Ideal for operations involving transformations, filtering, or iterating over subsets of elements.

**Input Size Consideration**:

- **For Small Inputs**: Works well, especially when applying transformations like reversing or filtering, while maintaining code readability.
- **For Large Inputs**: Very efficient as no extra memory is allocated, and the processing is done lazily, meaning only the required elements are accessed.

### 2.8.6. Parallel `for` Loop (C++17/C++20)

While not a traditional `for` loop, using parallelism in loops is a powerful feature introduced in C++17 and further improved in C++20.

```cpp
#include <execution>

std::for_each(std::execution::par, vec.begin(), vec.end(), [](int& elem) {
elem \*= 2; // Parallelized operation
});
```

Uses multiple threads to process elements in parallel, offering substantial performance gains for intensive operations that can be performed independently on large datasets. It requires more setup and understanding of parallelism concepts but can provide significant performance boosts for operations on large datasets.

**Input Size Consideration**:

- **For Small Inputs**: Overkill. The overhead of managing threads and synchronization outweighs the benefits for small datasets.
- **For Large Inputs**: Extremely efficient. When dealing with large datasets, parallel processing can drastically reduce runtime, especially for computationally expensive operations.

### 2.8.7. Optimal `for` Loops for Competitive Programming

Choosing the right type of `for` loop in competitive programming depends largely on input size and the specific use case. The following table summarizes the best choices for different scenarios:

| Input Size      | Best `for` Loop Option                                             | Reasoning                                                                                            |
| --------------- | ------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------- |
| Small           | Range-Based `for-each` with Constant Reference                     | Offers minimal syntax, high readability, and avoids copies, making it fast and efficient.            |
| Small           | Classic `for` Loop with Index                                      | Provides precise control over the index, useful when index manipulation or modification is required. |
| Large           | Iterator-Based `for` Loop                                          | Highly efficient for large datasets due to minimal memory overhead and optimized performance.        |
| Large           | Parallel `for` Loop with `std::for_each` and `std::execution::par` | Ideal for computationally heavy tasks on large datasets, leveraging multiple threads to parallelize. |
| Transformations | `for` Loop with Range Views (C++20)                                | Ideal for processing subsets or transformations of data without creating extra copies.               |

## 2.9 Now the `while` Loop which we all love

The `while` loop is another fundamental control structure in C++ that is often used in competitive programming. It repeatedly executes a block of code as long as a specified condition evaluates to true. In this section, we will explore the different use cases for `while` loops, their performance considerations, and scenarios where they may be preferable to `for` loops. We will also examine their application with both small and large datasets.

### 2.9.1. Basic `while` Loop

A `while` loop continues executing its block of code until the condition becomes false. This makes it ideal for situations where the number of iterations is not known beforehand.

```cpp
int i = 0;
while (i < n) {
    std::cout << i << " ";
    i++;
}
```

The `while` loop is simple and provides clear control over the loop's exit condition. The loop runs while `i < n`, and the iterator `i` is incremented manually within the loop. This offers flexibility in determining when and how the loop terminates.

**Input Size Consideration**:

- **For Small Inputs**: This structure is efficient, especially when the number of iterations is small and predictable.
- **For Large Inputs**: The `while` loop can be optimized for larger inputs by ensuring that the condition is simple to evaluate and that the incrementing logic doesn't introduce overhead.

### 2.9.2. `while` Loop with Complex Conditions

`while` loops are particularly useful when the condition for continuing the loop involves complex logic that cannot be easily expressed in a `for` loop.

```cpp
int i = 0;
while (i < n && someComplexCondition(i)) {
    std::cout << i << " ";
    i++;
}
```

In this case, the loop runs not only based on the value of `i`, but also on the result of a more complex function. This makes `while` loops a good choice when the exit condition depends on multiple variables or non-trivial logic.

**Input Size Consideration**::

- **For Small Inputs**: This is ideal for small inputs where the condition can vary significantly during the iterations.
- **For Large Inputs**: Be cautious with complex conditions when dealing with large inputs, as evaluating the condition on every iteration may add performance overhead.

### 2.9.3. Infinite `while` Loops

An infinite `while` loop is a loop that runs indefinitely until an explicit `break` or `return` statement is encountered. This type of loop is typically used in scenarios where the termination condition depends on an external event, such as user input or reaching a specific solution.

```cpp
while (true) {
    // Process some data
    if (exitCondition()) break;
}
```

The loop runs until `exitCondition()` is met, at which point it breaks out of the loop. This structure is useful for algorithms that require indefinite running until a specific event happens.

**Input Size Consideration**:

- **For Small Inputs**: Generally unnecessary for small inputs unless the exit condition is based on dynamic factors.
- **For Large Inputs**: Useful for large inputs when the exact number of iterations is unknown, and the loop depends on a condition that could be influenced by the data itself.

### 2.9.4. `do-while` Loop

The `do-while` loop is similar to the `while` loop, but it guarantees that the code block is executed at least once. This is useful when you need to run the loop at least one time regardless of the condition.

```cpp
int i = 0;
do {
    std::cout << i << " ";
    i++;
} while (i < n);
```

In this case, the loop will print `i` at least once, even if `i` starts with a value that makes the condition false. This ensures that the loop runs at least one iteration.

**Input Size Consideration**:

- **For Small Inputs**: Ideal when you need to guarantee that the loop runs at least once, such as with small datasets where the minimum iteration is essential.
- **For Large Inputs**: Suitable for large datasets where the first iteration must occur independently of the condition.

### 2.9.5. `while` Loop with Early Exit

The `while` loop can be combined with early exit strategies using `break` or `return` statements to optimize performance, particularly when the loop can terminate before completing all iterations.

```cpp
int i = 0;
while (i < n) {
    if (shouldExitEarly(i)) break;
    std::cout << i << " ";
    i++;
}
```

By including a condition inside the loop that checks for an early exit, you can significantly reduce runtime in cases where processing all elements is unnecessary.

**Input Size Consideration**:

- **For Small Inputs**: It can improve performance when early termination conditions are common or likely.
- **For Large Inputs**: Highly efficient for large datasets, particularly when the early exit condition is met frequently, saving unnecessary iterations.

### 2.9.6. Combining `while` with Multiple Conditions

A `while` loop can easily incorporate multiple conditions to create more complex termination criteria. This is particularly useful when multiple variables determine whether the loop should continue.

```cpp
int i = 0;
while (i < n && someOtherCondition()) {
    std::cout << i << " ";
    i++;
}
```

This allows the loop to run based on multiple dynamic conditions, providing more control over the iteration process than a standard `for` loop might offer.

**Input Size Consideration**:

- **For Small Inputs**: A flexible option when the conditions governing the loop may change during execution, even for small datasets.
- **For Large Inputs**: Can be optimized for large datasets by ensuring that the condition checks are efficient and that unnecessary re-evaluations are minimized.

### 2.9.7. Optimal `while` Loops for Competitive Programming

Choosing the right type of `while` loop depends on the nature of the input and the complexity of the condition. The following table summarizes the optimal choices for different input sizes:

| Input Size | Best `while` Loop Option                   | Reasoning                                                                                                                  |
| ---------- | ------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------- |
| Small      | Basic `while` Loop                         | Offers straightforward control over iteration with minimal overhead and is easy to implement.                              |
| Small      | `do-while` Loop                            | Ensures at least one execution of the loop.             |
| Large      | `while` with Early Exit                    | Improves performance by terminating the loop early when a specific condition is met, saving unnecessary iterations.        |
| Large      | `while` with Complex Conditions            | Allows dynamic and flexible exit conditions, making it suitable for large datasets with evolving parameters.               |
| Continuous | Infinite `while` Loop with Explicit Breaks | Best for situations where the exact number of iterations is unknown and depends on external factors or dynamic conditions. |

## 2.10 Special Loops in C++20

In C++20, several advanced looping techniques have been introduced, each offering unique ways to improve code efficiency and readability. While some of these techniques provide remarkable performance optimizations, not all are well-suited for competitive programming. competitive programmings often involve handling dynamic inputs and generating outputs within strict time limits, so techniques relying heavily on compile-time computation are less practical. This section focuses on the most useful loop structures for competitive programmings, emphasizing runtime efficiency and adaptability to varying input sizes.

### 2.10.1. Range-Based Loops with `std::ranges::views`

C++20 introduces `ranges` and `views`, which allow you to create expressive and efficient loops by operating on views of containers without copying data. Views are lazily evaluated, meaning that operations like filtering, transformation, or reversing are applied only when accessed.

**Example**:

```cpp
#include <ranges>
#include <vector>
#include <iostream>

int main() {
    std::vector<int> vec = {1, 2, 3, 4, 5};

    // Using views to iterate in reverse
    for (auto elem : vec | std::views::reverse) {
        std::cout << elem << " ";
    }

    return 0;
}
```

**Benefits**:

Efficient and lazy evaluation ensures that operations like reversing or filtering are performed only when needed, rather than precomputing them or creating unnecessary copies of the data. This approach optimizes memory usage and speeds up execution, particularly when working with large datasets.

The syntax is also highly expressive and concise, allowing you to write clear and readable code. This is particularly useful when applying multiple transformations in sequence, as it helps maintain code simplicity while handling complex operations.

**Considerations for competitive programmings**:

Range views are particularly useful when working with large datasets, as they enable efficient processing by avoiding the creation of unnecessary copies and reducing memory overhead. This approach allows for smoother handling of extensive input data, improving overall performance.

Additionally, range views provide clarity and simplicity when dealing with complex operations. They streamline the process of transforming data, making it easier to apply multiple operations in a clean and readable manner, which is especially beneficial in competitive programming scenarios.

### 2.10.2. Parallel Loops with `std::for_each` and `std::execution::par`

C++20 enables parallelism in standard algorithms with `std::execution`. Using parallel execution policies, you can distribute loop iterations across multiple threads, which can drastically reduce the execution time for computationally expensive loops. This is especially useful when working with large datasets in competitive programming.

**Example**:

```cpp
#include <execution>
#include <vector>

int main() {
    std::vector<int> vec(1000000, 1);

    std::for_each(std::execution::par, vec.begin(), vec.end(), [](int& elem) {
        elem *= 2;
    });

    return 0;
}
```

**Benefits**:

Parallel loops offer high performance, particularly when dealing with large input sizes that involve intensive computation. By utilizing multiple CPU cores, they significantly reduce execution time and handle heavy workloads more efficiently.

What makes this approach even more practical is that it requires minimal changes to existing code. The parallel execution is enabled simply by adding the execution policy `std::execution::par`, allowing traditional loops to run in parallel without requiring complex modifications.

**Considerations for competitive programmings**:

Parallel loops are highly effective for processing large datasets, making them ideal in competitive programming scenarios where massive inputs need to be handled efficiently. They can dramatically reduce execution time by distributing the workload across multiple threads.

However, they are less suitable for small inputs. In such cases, the overhead associated with managing threads may outweigh the performance gains, leading to slower execution compared to traditional loops.

## 2.11. `constexpr` Loops

With C++20, `constexpr` has been extended to allow more complex loops and logic at compile time. While this can lead to ultra-efficient code where calculations are precomputed during compilation, this technique has limited utility in competitive programming, where dynamic inputs are a central aspect of the problem. Since competitive programming requires handling varying inputs provided at runtime, `constexpr` loops are generally less useful in this context.

**Example**:

```cpp
#include <array>
#include <iostream>

constexpr std::array<int, 5> generate_squares() {
    std::array<int, 5> arr{};
    for (int i = 0; i < 5; ++i) {
        arr[i] = i * i;
    }
    return arr;
}

int main() {
    constexpr auto arr = generate_squares();
    for (int i : arr) {
        std::cout << i << " ";  // 0 1 4 9 16
    }

    return 0;
}
```

**Benefits**:

Compile-time efficiency allows for faster runtime performance, as all necessary computations are completed during the compilation phase. This eliminates the need for processing during execution, leading to quicker program runs.

This approach is ideal for constant, static data. When all relevant data is known ahead of time, compile-time computation removes the need for runtime processing, providing a significant performance boost by bypassing real-time calculations.

### 2.11.1 Considerations for competitive programmings

While constexpr loops are not suitable for processing dynamic inputs directly, they can be strategically used to create lookup tables or pre-compute values that are then utilized during runtime calculations. This can be particularly useful in problems involving mathematical sequences, combinatorics, or other scenarios where certain calculations can be predetermined. _However, it's important to balance the use of pre-computed data with memory constraints, as large lookup tables might exceed memory limits in some competitive programming environments_.

## 2.12. Early Exit Loops

In competitive programming, optimizing loops to exit early when a condition is met can drastically reduce execution time. This approach is especially useful when the solution does not require processing the entire input if an early condition is satisfied.

**Example**:

```cpp
#include <vector>
#include <iostream>

int main() {
    std::vector<int> vec = {1, 2, 3, 4, 5};

    // Early exit if a condition is met
    for (int i = 0; i < vec.size(); ++i) {
        if (vec[i] == 3) break;
        std::cout << vec[i] << " ";
    }

    return 0;
}
```

**Benefits**:

Early exit loops improve efficiency by terminating as soon as a specified condition is met, thus avoiding unnecessary iterations. This approach helps save time, especially when the loop would otherwise continue without contributing to the result. This technique is particularly useful in search problems. By exiting the loop early when a target value is found, it can improve performance, reducing the overall execution time.

_Early exit loops are highly practical, as they allow a solution to be reached without the need to examine all the data. By cutting down unnecessary iterations, they help reduce execution time, making them particularly useful in scenarios where a result can be determined quickly based on partial input._

## 2.13. Indexed Loops with Range-Based `for`

While C++ offers powerful range-based `for` loops, there are scenarios where accessing elements by index is essential, especially when the loop logic requires modifying the index or accessing adjacent elements. Range-based `for` loops cannot directly access the index, so indexed loops remain valuable for such cases.

**Example**:

```cpp
#include <vector>
#include <iostream>

int main() {
    std::vector<int> vec = {1, 2, 3, 4, 5};

    for (size_t i = 0; i < vec.size(); ++i) {
        std::cout << vec[i] << " ";
    }

    return 0;
}
```

**Benefits**:

Indexed loops offer precise control by providing direct access to elements through their index, giving you full control over how the index changes during iteration. This level of control allow fine-tuning the behavior of the loop.

They are essential when modifying iteration behavior, especially in cases where you need to adjust the index dynamically. This is useful for tasks such as skipping elements or implementing non-linear iteration patterns, allowing for flexible loop management.

Indexed loops are well-suited for dynamic access, offering the flexibility required for more complex iteration logic. This makes them ideal for scenarios where direct control over the loop's behavior is necessary.

However, they are less expressive compared to range-based loops. While they provide detailed control, they tend to be more verbose and less concise than the streamlined syntax offered by range-based alternatives.

## 2.14. Standard Library Algorithms

Using standard library algorithms like `std::for_each` and `std::transform` allows for highly optimized iteration and transformation of container elements. These algorithms are highly optimized, making them ideal for competitive programming scenarios.

**Example**:

```cpp
#include <algorithm>
#include <vector>
#include <iostream>

int main() {
    std::vector<int> vec = {1, 2, 3, 4, 5};

    std::for_each(vec.begin(), vec.end(), [](int& x) { x *= 2; });

    for (const int& x : vec) {
        std::cout << x << " ";
    }

    return 0;
}
```

**Benefits**:

Standard library algorithms are highly optimized for performance, often surpassing the efficiency of manually written loops. Their internal optimizations make them a powerful tool for handling operations in a time-efficient manner.

Additionally, these functions are concise and clear, providing a clean and expressive syntax to apply operations on containers. This simplicity improve code readability while maintaining high performance, making them ideal for competitive programming.

Standard library algorithms are great for transformation tasks, allowing you to apply operations on container elements with minimal code. They maximize efficiency while keeping the implementation simple and concise, making them particularly effective for handling transformations in competitive programming scenarios.

## 2.15 Summary Table of Useful Loop Techniques

| Technique                                 | Best Use Case                            | Efficiency Considerations                                                          |
| ----------------------------------------- | ---------------------------------------- | ---------------------------------------------------------------------------------- |
| `std::ranges::views`                      | Transforming or filtering large datasets | Lazily evaluated operations reduce memory overhead and improve runtime efficiency. |
| Parallel Loops with `std::execution::par` | Large computational tasks                | Parallelism significantly improves performance for large, independent tasks.       |
| Early Exit Loops                          | Search or conditional exit problems      | Avoids unnecessary iterations, improving efficiency in scenarios with early exits. |
| Indexed Loops                             | Precise control over iteration           | Offers flexibility and control for complex iteration logic or index manipulation.  |
| Standard Library Algorithms               | Applying transformations or actions      | Well-optimized algorithms that simplify code and improve performance.              |

**Techniques Not Recommended for competitive programmings**:

| Technique         | Reasoning                                                                                                      |
| ----------------- | -------------------------------------------------------------------------------------------------------------- |
| `constexpr` Loops | Compile-time only, cannot handle dynamic input, thus impractical for runtime competitive programming problems. |

## Complete Series

[Previous]({{ site.baseurl }}/competitive-programming-insights-introduction/)[Next]({{ site.baseurl }}/2-competitive-programming-hacks/)

## References

[^book1]: Silberschatz, A., Galvin, P. B., & Gagne, G. (2013). **Operating system concepts essentials** (2nd ed.). John Wiley & Sons.

[^book2]: Sedgewick, R. (1998). **Algorithms in C++** (4rd ed.). Addison-Wesley.

[^lib1]: Felker, R. (2011-2024). **musl libc** - a new standard C library. https://musl.libc.org/

[^article1]: MUSSER, D.R. (1997), **Introspective Sorting and Selection Algorithms**. Softw: Pract. Exper., 27: 983-993. https://doi.org/10.1002/(SICI)1097-024X(199708)27:8<983::AID-SPE117>3.0.CO;2-#