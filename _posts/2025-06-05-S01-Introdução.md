---
layout: post
title: Sistemas Operacionais - Fundamentos, Evolução e Arquitetura
author: Frank
categories: |-
    disciplina
    Ciência da Computação
    artigo
tags: |-
    sistemas operacionais
    arquitetura de computadores
    gerenciamento de recursos
    multiprogramação
    evolução histórica
    kernel
    processos
    memória virtual
image: assets/images/operating-systems.webp
featured: false
rating: 5
description: ""
date: 2025-06-06T15:00:00.000Z
preview: Uma exploração abrangente dos sistemas operacionais, desde suas origens históricas até os conceitos fundamentais que regem o funcionamento dos computadores modernos.
keywords: |-
    sistemas operacionais
    kernel
    processos
    gerenciamento de memória
    multiprogramação
    evolução histórica
    arquitetura de computadores
    recursos compartilhados
    abstração de hardware
toc: true
published: false
lastmod: 2025-06-08T02:21:33.146Z
---

## Desvendando o Maestro Invisível: Uma Introdução aos Sistemas Operacionais

Em cada computador, smartphone ou dispositivo inteligente que utilizamos diariamente, existe um software fundamental que orquestra silenciosamente todas as operações: o **sistema operacional**, que como um maestro dirige uma orquestra sinfônica, coordenando cada instrumento para criar uma harmonia perfeita, coordena os sistemas de hardware e software criando um ambiente computacional funcional e eficiente. Contudo, ao contrário do maestro, cuja presença é evidente, a natureza ubíqua dos sistemas operacionais torna-os quase invisíveis para a maioria dos usuários. Quando a cuidadosa leitora salva um arquivo, executa um programa ou conecta à internet, o faz sem se dar conta dos mecanismos complexos que tornam essas ações possíveis. Ainda assim, por trás dessa aparente simplicidade, reside uma das criações mais sofisticadas e interessantes da engenharia de software: um sistema capaz de gerenciar recursos limitados, coordenar atividades concorrentes, garantir segurança e fornecer uma interface amigável, simultânea e eficientemente.

*Compreender os sistemas operacionais não é apenas uma questão de curiosidade acadêmica, mas uma necessidade fundamental para qualquer profissional que deseje trabalhar com tecnologia de forma competente*. Maximize esta necessidade em tempos de crescente complexidade tecnológica, nos quais as novas ferramentas e tecnologias de inteligência artificial, computação em nuvem e dispositivos móveis estão integradas em nossas vidas diárias.

Os sistemas operacionais formam as pontes entre o hardware bruto e as aplicações que utilizamos, definindo como os recursos computacionais são utilizados e como as tarefas destes sistemas são executadas. Neste ponto, a atenta leitora deve ter percebido que este conhecimento é essencial para o desenvolvimento de softwares eficientes, a resolução de problemas de desempenho e a compreensão das limitações e possibilidades dos sistemas computacionais. Se a tecnologia avança, também avançam os sistemas operacionais.

Neste texto, iremos percorrer uma jornada através da evolução histórica dos sistemas operacionais, desde as primeiras máquinas programáveis até os sistemas modernos que gerenciam data centers inteiros. Exploraremos as funções fundamentais que todos os sistemas operacionais devem realizar, as diferentes perspectivas através das quais podemos compreendê-los, e os princípios arquiteturais que orientam seu design. Nossa meta é construir uma compreensão sólida que sirva como fundação para estudos mais avançados em ciência da computação e engenharia de software.

Escrevo com a esperança, e ambição, que este seja apenas o primeiro porto que visitaremos e que, ao final desta jornada, você não apenas compreenda os sistemas operacionais, mas que seja capaz de utilizar esse conhecimento para resolver problemas práticos, otimizar sistemas e contribuir para o avanço da tecnologia. Que o céu esteja azul e que os ventos sejam justos!

## A Jornada através do Tempo: Evolução Histórica dos Sistemas Operacionais

A história dos sistemas operacionais foi impulsionada pela constante evolução do hardware, pelas crescentes demandas dos usuários e, principalmente pela criatividade aplicada a solução de novos problemas ou a busca de novos recursos. A linha do tempo apresentada na Figura 1 divide e ilustra as principais eras da evolução dos sistemas operacionais de forma simples e intuitiva.

![Linha temporal horizontal mostrando as eras (1940s-presente) com marcos tecnológicos chave, sistemas operacionais representativos e inovações de hardware correspondentes. Incluir ícones representativos para cada era](/assets/images/timeline_evolutivo_so.webp)
_Figura 1: Linha de tempo da evolução dos sistemas operacionais_{: class="legend"}

O tempo, e os momentos que o marcam, resumem os conceitos e avanços fundamentais mas não são suficientes. Talvez seja necessário um pouco mais de contexto para compreender como chegamos até aqui e antever onde podemos ir.

### O Estágio Nascente: Máquinas Nuas e Programação Direta (1940s - início dos 1950s)

Os primórdios da computação, a era do bit lascado, foram caracterizados por máquinas colossais que utilizavam **válvulas termiônicas** e **painéis de conexão** (*plugboards*), operando sem qualquer forma de sistema operacional. Estas máquinas primitivas eram verdadeiras "máquinas nuas" (*bare machines*), nas quais os programadores interagiam diretamente com o hardware. Cada instrução era codificada manualmente em formato binário. Além disso, as funções que a máquina deveria executar eram controladas através da fiação física dos painéis de conexão. As máquina precisavam ser montadas, fisicamente configuradas, para cada tarefa específica. Muitos programadores eram especialistas em eletrônica, capazes de entender e manipular o hardware diretamente.

Como a atenta leitora deve estar imaginando, esse modo de operação era ineficiente, cansativo e tedioso. Os programadores precisavam se inscrever em listas para obter tempo de máquina, e a configuração era um processo demorado e propenso a erros. A introdução dos **cartões perfurados** representou uma melhoria na entrada de dados, mas a operação continuava predominantemente manual. Um computador desse período, que poderia levar dias ou até semanas para ser configurado e programado para uma tarefa específica, pode ser visto na Figura 2.

![Computador ENIAC com painéis de conexão e cartões perfurados](/assets/images/eniac2.webp)
_Figura 2: O ENIAC, um dos primeiros computadores programáveis, com painéis de conexão e cartões perfurados. Artificialmente colorizada.( WIKIMEDIA COMMONS, 2025)_{: class="legend"}

> **ENIAC**
>
> O ENIAC (Electronic Numerical Integrator and Computer) é considerado um dos primeiro computador digital eletrônico de grande escala. Este equipamento foi desenvolvido durante a Segunda Guerra Mundial e concluído em 1945. Projetado por [John Presper Eckert](https://pt.wikipedia.org/wiki/John_Presper_Eckert) e [John William Mauchly](https://pt.wikipedia.org/wiki/John_Mauchly) na Universidade da Pensilvânia, o ENIAC foi criado para calcular trajetórias balísticas para o Exército dos Estados Unidos. No entanto, sua utilidade transcendeu esse propósito inicial, marcando o início da era dos computadores eletrônicos. O ENIAC era uma máquina colossal, ocupando uma área de aproximadamente 167 metros quadrados e pesando cerca de 30 toneladas. Apesar de seu tamanho e complexidade, o ENIAC era capaz de realizar cálculos em uma velocidade sem precedentes para a época, revolucionando a forma como problemas complexos podiam ser resolvidos.
>
> **Tecnologia Inovadora para a Época**
>
> O ENIAC utilizava uma tecnologia revolucionária para a época, baseada em válvulas termiônicas (ou tubos de vácuo) em vez de componentes mecânicos. Com aproximadamente 17.468 válvulas, 7.200 diodos de cristal, 1.500 relés, 70.000 resistores e 10.000 capacitores, o ENIAC era uma maravilha da engenharia eletrônica. Esses componentes permitiam que o ENIAC realizasse cálculos a uma velocidade muito maior do que qualquer máquina anterior. A programação do ENIAC era feita através de painéis de conexão (no inglês: plugboards) e chaves manuais, um processo complexo e demorado que exigia conhecimento especializado. Apesar de suas limitações, como a falta de um sistema operacional moderno e a necessidade de reprogramação manual para cada nova tarefa, o ENIAC estabeleceu as bases para o desenvolvimento de computadores mais avançados e acessíveis, pavimentando o caminho para a revolução digital que viria a seguir.

O ENIAC, é um marco importante na história da computação. Mas, não foi o primeiro computador, nem o único. Outros computadores notáveis dessa era incluem o **Colossus**, usado para decifrar códigos durante a Segunda Guerra Mundial, e o **EDVAC**, que introduziu o conceito de armazenar programas na memória. E, graças aos problemas da segunda guerra mundial, ficou esquecido. Relegado a poeira do preconceito e medo.

O processo de redescoberta e reconhecimento da relevância do Z3 começou a ganhar força na década de 1990. Um marco importante ocorreu após a morte de [Konrad Zuse](https://pt.wikipedia.org/wiki/Konrad_Zuse), em 1995, quando houve um renovado interesse em seu trabalho, reacendendo debates sobre qual foi o primeiro computador da história. Além disso, em 1998, foi demonstrado que o Z3 era, em princípio, Turing-completo, ou seja, capaz de realizar qualquer cálculo que um computador moderno poderia fazer, desde que devidamente programado. Essa demonstração solidificou a posição do Z3 como um avanço fundamental na evolução da computação.

> **O Zuse Z3**
>
> O Zuse Z3, criado pelo engenheiro alemão [Konrad Zuse](https://pt.wikipedia.org/wiki/Konrad_Zuse) em 1941, é reconhecido como o primeiro computador programável e totalmente automático do mundo. Desenvolvido em Berlim, o Z3 foi uma inovação significativa na computação, utilizando relés eletromecânicos para realizar cálculos complexos. Zuse construiu o Z3 para resolver problemas de engenharia, e a máquina foi usada para cálculos estruturais e aerodinâmicos. Embora o Z3 tenha sido destruído durante um bombardeio aliado em 1943, sua arquitetura e conceitos pioneiros influenciaram profundamente o desenvolvimento subsequente dos computadores. O Z3 era capaz de realizar operações de ponto flutuante mas possuía uma memória limitada. Ainda assim, suficiente para as tarefas da época. A máquina era programada através de fitas perfuradas, o que permitia uma certa flexibilidade na execução de diferentes tarefas.
>
> **Tecnologia e Legado do Zuse Z3**
>
> O Z3 utilizava cerca de 2.600 relés eletromecânicos para realizar suas operações lógicas e aritméticas, uma tecnologia avançada para a época, mas limitada em comparação com os computadores eletrônicos que surgiriam posteriormente. A máquina operava com uma frequência de clock de aproximadamente 5 Hz, o que, embora lento pelos padrões atuais, era uma conquista notável para a tecnologia da época. O Z3 também introduziu conceitos fundamentais de computação, como a separação entre programa e dados, e a capacidade de executar operações condicionais. Apesar de suas limitações, o Z3 demonstrou a viabilidade de computadores programáveis e automáticos, abrindo caminho para desenvolvimentos futuros. O trabalho de Konrad Zuse é considerado pioneiro e visionário, e seu legado continua a ser celebrado na história da computação.

Observe, atenta leitora, que o Eniac usava válvulas termiônicas, enquanto o Z3 utilizava relés eletromecânicos. Isto parece implicar que o ENIAC era muito mais rápido. Contudo, o Z3 era programado por fitas perfuradas, enquanto o ENIAC utilizava painéis de conexão. O que significa que o Z3 era mais flexível e fácil de programar. Ou seja, este pobre autor acredita que o tempo entre a definição do problema e a solução do mesmo era menor no Z3 do que no ENIAC. O que, em última análise, é o que importa.

Para nós, nesta jornada, o mais importante é compreender que, mesmo sem sistemas operacionais, os computadores já eram capazes de realizar tarefas complexas. No entanto, a falta de abstração e automação tornava o processo trabalhoso, dolorosamente tedioso  e propenso a erros. Nesse ponto da história começa a surgir a necessidade de camada extra de tecnologia que permitisse automatizar as tarefas necessárias para resolver problemas computacionais, sem a necessidade de intervenção manual constante. 

### A Revolução Batch: Automatizando o Throughput (final dos 1950s - meados dos 1960s)

>**Throughput é uma palavra horrível**
> A palavra "throughput" da língua inglesa, não tem uma tradução direta para o português. Pode ser entendida como vazão, taxa de transferência ou capacidade de processamento. No contexto de sistemas operacionais, refere-se à quantidade de trabalho que um sistema pode realizar em um determinado período de tempo. É uma métrica importante para avaliar a eficiência e o desempenho de um sistema, especialmente em ambientes de computação onde múltiplas tarefas são executadas simultaneamente.
>
> Eu vou usar throughput, na esperança que Cecília Meireles e Fernando Pessoa me perdoem o estrangeirismo.

A substituição das válvulas por **transistores** tornou os computadores menores, mais confiáveis, rápidos e práticos. Contudo, e apesar disso, as máquinas da época eram extremamente caras e gerenciados centralmente. Estas grandes máquinas centralizadas ficaram conhecidas como **mainframes**. Elas eram operadas por equipes de especialistas e utilizadas principalmente para tarefas críticas em grandes organizações, como bancos e universidades. E enfrentavam um problema significativo: a **subutilização da unidade central de processamento**. A unidade central de processamento, que ficou conhecida como CPU, ficava ociosa enquanto esperava por operações de Entrada/Saída (E/S) ou pela conclusão de outros processos, resultando em desperdício de recursos.

A solução emergiu na forma de **Sistemas Batch**.

Os sistemas batch, uma palavra do inglês que pode ser traduzida por lote, apresentavam características distintas que os diferenciavam das abordagens anteriores de computação. Uma das principais inovações era a capacidade de agrupar tarefas com necessidades similares, formando lotes, ou batchs, que eram executados de maneira sequencial, permitindo uma utilização mais eficiente dos recursos computacionais. *Esses sistemas contavam com um monitor residente, um componente precursor dos sistemas operacionais modernos, que tinha a função de automatizar o sequenciamento dos trabalhos, eliminando a necessidade de intervenção manual entre a execução de cada tarefa*. Para controlar esse processo, foi desenvolvida a **Job Control Language (JCL)**, uma linguagem específica que permitia instruir o monitor sobre como processar os trabalhos (do inglês, jobs), definindo parâmetros e sequências de execução. Além disso, os sistemas batch introduziram o conceito de processamento offline, no qual a saída dos trabalhos era direcionada para fitas magnéticas, permitindo que a impressão dos resultados fosse realizada posteriormente, sem ocupar o valioso tempo de processamento da unidade central de processamento. Essa abordagem representou um avanço significativo na automação da operação dos computadores, aumentando consideravelmente a utilização da CPU e o throughput dos sistemas.

**Sistemas influentes desta era**:

- **FMS (Fortran Monitor System)**: um dos primeiros sistemas de monitoramento para programas FORTRAN. O **FMS** foi um dos primeiros sistemas de monitoramento desenvolvido especificamente para programas escritos em FORTRAN (do inglês: FORmula TRANslation), uma das primeiras linguagens de programação, utilizada para aplicações científicas e de engenharia de alto desempenho ainda hoje. O **FMS** permitia que *múltiplos programas FORTRAN fossem executados em sequência sem a necessidade de intervenção manual entre cada execução*. O **FMS** introduziu os conceitos básicos de gerenciamento de tarefas e alocação de recursos, que se tornariam fundamentais para os sistemas operacionais. Além disso, o **FMS** facilitava a compilação e execução de programas FORTRAN, tornando o processo de desenvolvimento mais eficiente e menos propenso a erros.

- **IBSYS**: sistema batch para o IBM 7094, que estabeleceu alguns conceitos importantes até hoje. O IBSYS introduziu técnicas sofisticadas de gerenciamento de memória e escalonamento de tarefas, permitindo que múltiplos trabalhos fossem processados de maneira mais eficiente. O IBSYS também implementou mecanismos de proteção de memória, garantindo que um programa não interferisse na execução de outros, um conceito crucial para a estabilidade e confiabilidade dos sistemas computacionais. Além disso, o IBSYS oferecia suporte a dispositivos de entrada e saída diversos, incluindo leitores de cartões, impressoras e unidades de fita magnética, permitindo uma maior flexibilidade na manipulação de dados.

*O objetivo principal dos sistemas **Batch** era maximizar a utilização da CPU e o throughput*. Deve voltar a definição de throughput, só por via das dúvidas. A atenta leitora deve registrar que esta era marcou o primeiro passo na automação da operação do computador e impulsionou o conceito de abstração da máquina.

### Malabarismo de Recursos: O Advento da Multiprogramação (meados dos 1960s - 1970s)

A introdução dos **Circuitos Integrados (CIs)** marcou um avanço significativo, resultando em computadores ainda mais poderosos, compactos e acessíveis. No entanto, mesmo com a eficiência aprimorada dos sistemas batch, um problema persistia: a CPU permanecia ociosa durante as operações de **entrada e saída de dados (E/S)**. O gargalo residia no fato de que as operações de E/S são ordens de magnitude mais lentas do que a execução de instruções pela CPU.

Nesse contexto surgiu a **multiprogramação**. Essa técnica revolucionária propunha manter múltiplos processos na memória principal simultaneamente. A ideia era simples, mas transformadora: se um processo em execução precisasse realizar uma operação de E/S, um sistema de gestão poderia rapidamente comutar a CPU para outro processo que estivesse pronto para executar, em vez de esperar o término da lenta operação de E/S. Essa abordagem aumentou drasticamente a utilização da CPU, reduziu o tempo ocioso e revolucionou a forma como os recursos computacionais são gerenciados.

A eficácia da multiprogramação pode ser modelada matematicamente. Se um processo gasta uma fração $p$ do seu tempo esperando por operações de E/S, a probabilidade de $n$ processos, todos residentes na memória, estarem simultaneamente esperando por E/S é $p^n$. A CPU só estará ociosa se todos os processos estiverem esperando. Portanto, a utilização da CPU é a probabilidade de que pelo menos um processo não esteja esperando por E/S, o que pode ser expresso pela fórmula:

$$
\text{Utilização da CPU} = 1 - p^n
$$

Nesta equação:

- $p$ representa a fração de tempo que um processo gasta em operações de E/S.
- $n$ é o número total de processos mantidos na memória.

Como a esperta leitora deve observar que, mesmo com um valor de $p$ relativamente alto (por exemplo, 0.5, significando que os processos passam metade do tempo em E/S), aumentar o número de processos $n$ na memória faz com que o termo $p^n$ diminua exponencialmente, levando a utilização da CPU para perto de 100%.

![ Gráfico mostrando múltiplos processos na memória com estados (CPU, I/O, waiting) e cronograma temporal demonstrando como a CPU alterna entre processos durante operações de I/O de outros](/assets/images/multiprogramacao_cpu.webp)
_Figura 3: Representação da alocação de processos em memória._{: class="legend"}

Em resumo, a multiprogramação introduziu conceitos fundamentais que moldaram a construção dos sistemas operacionais. Entre eles, destacam-se:

- **Múltiplos jobs na memória**: permitia que vários trabalhos fossem mantidos simultaneamente na memória principal;
- **Comutação de contexto**: quando um job necessitava realizar operações de E/S, o sistema de gestão rapidamente transferia a CPU para outro job pronto para execução;
- **Gerenciamento de memória**: surgia a necessidade de alocar espaço para múltiplos trabalhos de forma eficiente;
- **Escalonamento de CPU**: eram desenvolvidos algoritmos para decidir qual job seria executado em seguida, otimizando o uso da CPU.

>**jobs**: o termo "job" refere-se a uma tarefa ou trabalho que um sistema operacional deve executar. Em sistemas batch, um job é um conjunto de instruções e dados que são processados em sequência, sem interação do usuário durante a execução. Os jobs são frequentemente agrupados com base em suas características ou requisitos de recursos, permitindo que o sistema operacional otimize o uso da CPU e minimize o tempo de espera. *O equivalente atual do job é o processo*, que é uma instância de um programa em execução, incluindo seu estado, dados e recursos alocados.

Outro avanço significativo foi o **Spooling (Simultaneous Peripheral Operation On-Line)**, uma técnica que utilizava o disco como buffer intermediário para operações de E/S. Isso permitia que a CPU e os dispositivos de E/S operassem de forma mais concorrente, melhorando a eficiência geral do sistema. Um exemplo marcante dessa era é o **OS/360 da IBM**, em 7 de abril de 1964, um sistema de multiprogramação que estabeleceu muitos dos conceitos ainda utilizados nos sistemas operacionais modernos. O termo OS/360 refere-se a uma família de sistemas operacionais desenvolvidos pela IBM para sua linha de mainframes System/360, que introduziu a multiprogramação como um recurso central. O OS/360 foi projetado para suportar uma ampla gama de aplicações, desde processamento de dados até computação científica, e estabeleceu padrões que influenciaram profundamente o desenvolvimento de sistemas operacionais subsequentes.

>**Spooling** vem do inglês Simultaneous Peripheral Operations On-Line e refere-se ao processo de gerenciamento de dados para operações de entrada e saída (E/S). Ele permite que dispositivos periféricos, como impressoras, operem de forma eficiente, armazenando temporariamente os dados em uma área de *buffer*, uma área de memória temporária ou fila, sem interromper o processamento principal da CPU.
>
>**buffer** é um destes termos em inglês que chegaram na computação, em inglês, de uma forma pouco ortodoxa. Talvez, algum pesquisador tenha se lembrado de algo da infância, ou de alguma outra área do vida e trouxe para a computação. O termo "buffer" deriva do verbo em inglês antigo "buff", que significava golpear ou amortecer um golpe. Esse sentido inicial estava ligado à ideia de suavizar ou absorver um impacto físico, como uma pancada. Na física, um "buffer" é um dispositivo ou mecanismo que reduz o impacto ou choque, como os amortecedores usados em trens ou carros para suavizar colisões. Também pode se referir a algo ou alguém que funciona como uma barreira protetora. Em computação Um "buffer" é uma área de armazenamento temporário para dados, usada enquanto eles estão sendo transferidos entre dois lugares, ou processos, distintos. Por exemplo, um buffer pode guardar informações de um dispositivo rápido, como um processador, antes de enviá-las para um dispositivo mais lento, como uma impressora, ajudando a equilibrar diferenças de velocidade.

Novamente: o poetas mortos da língua portuguesa perdoai este pobre autor pelos crimes que comete!

>O pobre autor começou sua vida profissional em um velho mainframe IBM 360/30, com o OS/360 rodando Cobol, PL/1 e RPG. O sistema era tão antigo que o manual de operação era um livro de papel, com mais de 1000 páginas, e o computador tinha apenas 32 KB de memória. Era o final dos anos 1970 poucos meses antes deste 360/30 ser descomissionado e substituído por um IBM 370/10 que, usando memória virtual chegava a 16 MBytes de memória. Imagine!

A IBM não criou o termo sistema operacional, mas foi fundamental em sua popularização. O termo já existia na comunidade de computação antes do lançamento do OS/360 pela IBM em 1964. Por exemplo, sistemas como o [GM-NAA I/O](https://en.wikipedia.org/wiki/GM-NAA_I/O), desenvolvido em 1956, e o [CTSS](https://pt.wikipedia.org/wiki/Compatible_Time-Sharing_System), descrito em 1962, já eram chamados de sistemas operacionais em contextos acadêmicos e de pesquisa. No entanto, o OS/360, marcou um ponto de virada na história da computação. Deste ponto em diante, podemos usar o termo **sistema operacional** para nos referirmos a um software que gerencia recursos de hardware e fornece serviços essenciais para programas de aplicação. A multiprogramação e o spooling foram marcos importantes na evolução dos sistemas operacionais, estabelecendo as bases para a abstração de hardware e a automação do gerenciamento de recursos.

### Era da Interatividade: Sistemas de Tempo Compartilhado (final dos 1960s - 1980s)

Os sistemas de tempo compartilhado, do inglês time-sharing, representaram uma evolução natural da multiprogramação, com um foco especial na experiência do usuário além eficiência no uso da CPU. Esses sistemas revolucionaram a computação ao dividir o tempo da CPU entre múltiplos usuários interativos simultaneamente, criando um ambiente no qual cada usuário tinha a impressão de estar utilizando um computador dedicado exclusivamente a ele.

A abordagem de time-sharing marcou uma mudança significativa de paradigma nos sistemas computacionais. Essa transição foi possível graças à implementação do time slicing. Nome em inglês para uma técnica na qual cada processo recebe uma pequena fatia de tempo da CPU, que podemos chamar de quantum para aproveitar os tempos atuais e o conceito da física, antes de ser temporariamente suspenso para permitir que outros processos sejam executados. Essa abordagem cria a ilusão de que cada usuário tem acesso exclusivo aos recursos do computador, melhorando significativamente a interatividade e a experiência geral do usuário.

O uso dos conceitos de time slicing, inglês para fatiamento de tempo, permitiram que múltiplos usuários trabalhassem simultaneamente no mesmo sistema, cada um com a impressão de estar utilizando um computador dedicado, enquanto na realidade os recursos eram compartilhados de maneira eficiente e transparente.

**Sistemas Influentes**:

Entre os sistemas de tempo compartilhado mais influentes da história da computação, destacam-se três que deixaram um legado significativo.

1. **CTSS (Compatible Time-Sharing System)**: desenvolvido no Massachusetts Institute of Technology (MIT). Este sistema foi pioneiro no uso de fatiamento de tempo com interrupções, uma técnica que permitia a múltiplos usuários compartilharem os recursos de um computador de maneira eficiente. O CTSS estabeleceu muitos dos conceitos fundamentais que ainda hoje são a base dos sistemas interativos modernos, incluindo mecanismos de alocação de recursos e gerenciamento de processos que garantiam uma experiência de usuário mais responsiva e interativa.

2. **MULTICS (Multiplexed Information and Computing Service)**: resultado de um projeto colaborativo entre o MIT, a General Electric e os Bell Labs. O **MULTICS** introduziu uma série de conceitos revolucionários que mudaram para sempre a computação. Entre essas inovações estavam a memória de nível único, que simplificava o gerenciamento de memória, a ligação dinâmica de código, que permitia maior flexibilidade na execução de programas, e um sistema de arquivos hierárquico, que organizava os dados de maneira mais intuitiva. Além disso, o MULTICS tinha um forte foco em segurança, introduzindo mecanismos avançados de proteção de dados e controle de acesso. Embora o MULTICS tenha tido um sucesso comercial limitado, sua influência no desenvolvimento de sistemas operacionais subsequentes foi imensa, estabelecendo padrões que ainda são seguidos hoje.

3. **UNIX**, desenvolvido nos Bell Labs por Ken Thompson e Dennis Ritchie, merece destaque especial. Inspirado pelo MULTICS, o **UNIX** foi criado com uma filosofia de simplicidade e elegância que o tornou extremamente popular. Diferente de seu predecessor, o **UNIX** foi escrito predominantemente na **Linguagem C**, o que lhe conferiu uma portabilidade notável, permitindo que fosse executado em uma variedade de plataformas de hardware. O **UNIX** também se destacou por seu ambiente multiusuário e multitarefa, que permitia que múltiplos usuários trabalhassem simultaneamente no mesmo sistema, cada um executando várias tarefas ao mesmo tempo. Os sistemas UNIX de 1993 apresentavam pilhas TCP/IP maduras (sockets BSD desde 1983), memória virtual sofisticada com paginação por demanda (4.3BSD), sistemas de arquivos avançados e capacidades de computação distribuída através de NFS e RPC.Além disso, o **UNIX** introduziu um sistema de arquivos hierárquico e um shell de comando poderoso, que oferecia aos usuários uma interface flexível e eficiente para interagir com o sistema.

>O nome "**UNIX**" é uma brincadeira derivada de "Multics", um sistema operacional anterior no qual seus criadores trabalharam. O Multics era um projeto ambicioso, mas complexo e pesado. Quando Ken Thompson e Dennis Ritchie começaram a desenvolver um sistema mais simples e eficiente, chamaram-no de **UNIX** como um trocadilho, sugerindo algo mais unitário e simplificado em contraste com o Multics. O nome também pode ser interpretado como uma abreviação de "UNIpleXed Information and Computing Service", embora isso seja mais uma explicação retroativa do que a intenção original.
>
>A **Linguagem C** foi criada por Dennis Ritchie na Bell Labs entre 1972 e 1973, sendo desenvolvida especificamente para facilitar o desenvolvimento do sistema operacional **UNIX**. Dennis Ritchie descreveu o **C** como "uma linguagem de implementação de sistema para o nascente sistema operacional **UNIX**". Cronologicamente temos:
>
>1. ****UNIX** inicial (1969-1971)**: **UNIX** foi originalmente escrito em assembly language para o computador PDP-7
>
>2. **Desenvolvimento da linguagem B**: Ken Thompson primeiro criou a linguagem B, uma versão simplificada do BCPL, para desenvolver utilitários para o **UNIX**
>
>3. **Evolução para **C** (1971-1973)**: Em 1971, Ritchie começou a melhorar a linguagem B para aproveitar recursos do PDP-11 mais poderoso, adicionando tipos de dados como caracteres. Esta versão foi chamada "New B" (NB) e posteriormente evoluiu para C
>
>4. **Reescrita do **UNIX** em **C** (1973)**: Na versão 4 do **UNIX**, lançada em novembro de 1973, o kernel do **UNIX** foi extensivamente reimplementado em C
>
>A **Linguagem C** foi projetada para ser uma linguagem de programação de sistemas, com foco em eficiência, portabilidade e expressividade. Ela permitiu que o **UNIX** fosse reescrito de forma mais concisa e legível, facilitando a manutenção e evolução do sistema. Conforme mais do sistema operacional foi reescrito em C, a portabilidade também aumentou, permitindo que o **UNIX** rodasse em diferentes arquiteturas de computador. Além disso, a **Linguagem C** tinha o objetivo de mover o código do kernel **UNIX** do assembly para uma linguagem de alto nível, que realizaria as mesmas tarefas com menos linhas de código. Finalmente, Dennis Ritchie construiu a **Linguagem C** sobre a linguagem B, herdando a sintaxe concisa de Thompson que tinha uma poderosa mistura de funcionalidades de alto nível com os recursos detalhados necessários para programar um sistema operacional que fosse portável entre diferentes plataformas de hardware.

O desenvolvimento do **UNIX** ilustra um princípio importante no design de sistemas: *soluções pragmáticas e focadas muitas vezes ganham maior adoção do que aquelas excessivamente ambiciosas e complexas*. A portabilidade do **UNIX**, facilitada pela **Linguagem C**, foi um divisor de águas, permitindo sua disseminação por uma vasta gama de plataformas de hardware.

_Pessoas mais inteligentes que eu, dizem que a tecnologia, e a civilização, avançam em rampas e degraus. De tempos em tempos, uma inovação ou descoberta significativa ocorre, criando um salto qualitativo na capacidade tecnológica. O par **UNIX** e **C** é, claramente, um destes degraus._

### A Democratização da Computação: Era dos Computadores Pessoais (final dos 1970s - presente)

A invenção e popularização dos **microprocessadores**, impulsionadas pelos avanços em **LSI (Large Scale Integration)** integração em larga escala em inglês e em **VLSI (Very Large Scale Integration)**, integração em escala muito grande em inglês, levaram ao surgimento de computadores pessoais acessíveis. A curiosa leitora precisa saber que no final dos anos 1980, no Brasil, era mais fácil comprar um computador pessoal importado, que um telefone.

As novas tecnologias de microprocessadores permitiram a miniaturização e a redução de custos, tornando possível a criação de computadores que poderiam ser adquiridos por indivíduos e pequenas empresas. Esses computadores pessoais, ou **PCs**, eram significativamente mais baratos do que os mainframes e minicomputadores da época, tornando a computação acessível a um público muito mais amplo.

_Esta era representou uma mudança drástica do modelo de computação centralizada para sistemas de usuário individual._

**Sistemas Influentes**:

1. **CP/M (Control Program for Microcomputers)** - Desenvolvido por [Gary Kildall](https://pt.wikipedia.org/wiki/Gary_Kildall) na Digital Research em 1974, o CP/M foi um marco fundamental na evolução dos sistemas operacionais para microcomputadores. Este sistema estabeleceu convenções duradouras para a organização de arquivos e comandos que influenciariam profundamente o desenvolvimento posterior de sistemas como o MS-DOS. O CP/M introduziu o conceito de Basic Input/Output System (BIOS), uma camada de abstração entre o hardware e o sistema operacional que permitia maior portabilidade entre diferentes microcomputadores baseados no processador Intel 8080 e Zilog Z80. Sua estrutura modular, com Command Console Processor (CCP), Basic Disk Operating System (BDOS) e BIOS, tornou-se um modelo arquitetônico para sistemas posteriores. Durante o final dos anos 1970 e início dos 1980, o CP/M dominou o mercado de microcomputadores comerciais, estabelecendo padrões para nomenclatura de drives (A:, B:, C:) e comandos básicos que persistem até hoje.

    > O pobre autor teve que comprar uma placa de expansão para rodar o CP/M no seu Apple II. A placa tinha um processador Z80, 64 KB de memória e um drive de disquete de 5.25 polegadas. O CP/M rodava em modo texto, mas permitia o uso de programas como o WordStar e o dBase II, que eram muito populares na época. O CP/M foi um dos primeiros sistemas operacionais a permitir a execução de múltiplos programas simultaneamente, embora não fosse multitarefa no sentido moderno. Mais importante, eu tinha, em casa, a disposição, uma máquina que podia ser programada em **C**. Me livrando do Basic infernal do Apple II.

2. **MS-DOS (Microsoft Disk Operating System)** - Originado como uma adaptação do 86-DOS (QDOS - Quick and Dirty Operating System) desenvolvido por [Tim Paterson](https://pt.wikipedia.org/wiki/Tim_Paterson) na Seattle Computer Products, **o MS-DOS foi adquirido pela Microsoft em 1981 para atender à demanda da IBM por um sistema operacional para seu novo Personal Computer**. O sistema mantinha compatibilidade conceitual com o CP/M, facilitando a migração de aplicações, mas foi otimizado para o processador Intel 8086/8088. Sua interface de linha de comando, embora aparentemente simples, oferecia recursos poderosos como redirecionamento de entrada/saída, processamento em lote através de arquivos .BAT, e suporte a dispositivos através de drivers carregáveis. O MS-DOS evoluiu significativamente ao longo de suas versões, introduzindo suporte a discos rígidos (versão 2.0), estruturas de diretórios hierárquicas, e eventualmente suporte limitado à memória estendida. Sua natureza monotarefa e arquitetura de 16 bits, embora limitantes, proporcionaram estabilidade e previsibilidade que contribuíram para o estabelecimento do padrão IBM PC como plataforma dominante na computação pessoal por mais de uma década.

    > Este, o pobre autor, rodava em um PC-386, com co-processador matemático, comprado em consórcio e  construído pela Cobra Informática, uma empresa brasileira que importava componentes e montava computadores sob medida. O MS-DOS era o sistema operacional padrão para PCs compatíveis com IBM, e eu o utilizava para rodar programas como o WordPerfect e o Lotus 1-2-3. Usava o Borland C++ para programar em C++, e o Turbo Pascal para programar em Pascal. Mas, devo confessar, este último só quando eu queria me martirizar.

3. **Apple Macintosh OS (Classic Mac OS)** - Lançado em 1984, o Sistema Operacional do Macintosh representou uma revolução paradigmática na interação humano-computador, popularizando conceitos que hoje consideramos fundamentais na computação moderna. Inspirado no trabalho pioneiro realizado nos Laboratórios Xerox Alto e Star, o Mac OS implementou de forma comercialmente viável a metáfora da área de trabalho, onde arquivos eram representados como documentos físicos e pastas como contêineres organizacionais. O sistema aproveitou as ideias dos Laboratórios da Xerox e introduziu o mouse como dispositivo primário de navegação, implementou o conceito de WYSIWYG, abreviatura do What You See Is What You Get, na edição de documentos, e estabeleceu padrões de interface como menus suspensos, caixas de diálogo modais, e manipulação direta de objetos gráficos. Tecnicamente, o Mac OS original baseava-se em um núcleo de processamento cooperativo que, embora não oferecesse proteção robusta de memória ou multitarefa preemptiva, proporcionava uma experiência de usuário fluida e intuitiva. Sua arquitetura de recursos, no inglês: resource fork, permitia a incorporação de elementos gráficos, sonoros e de interface diretamente nos arquivos executáveis, facilitando a localização e personalização de aplicações.

4. **Microsoft Windows** - Iniciado em 1985 como um ambiente gráfico executado sobre o MS-DOS, o Windows passou por três fases distintas de desenvolvimento. As versões 1.0 a 3.1 funcionavam essencialmente como ambientes gráficos, oferecendo uma interface visual para o MS-DOS subjacente, mas mantendo as limitações fundamentais de um sistema de 16 bits. O Windows 95 marcou uma transição crucial, introduzindo multitarefa preemptiva de 32 bits, um sistema de arquivos mais robusto, e uma interface redesenhada que incorporava elementos como a barra de tarefas e o menu Iniciar. Paralelamente, a linha Windows NT, iniciada em 1993 sob a liderança de [Dave Cutler](https://en.wikipedia.org/wiki/Dave_Cutler), representou uma abordagem completamente nova: *um sistema operacional construído desde o foundation com arquitetura de 32 bits, microkernel híbrido, e recursos avançados de segurança baseados em Access Control Lists (ACLs) e domínios*. O NT introduziu conceitos  importados do padrão POSIX, como threading avançado, proteção de memória robusta, e suporte nativo a redes, estabelecendo as bases arquitetônicas que persistem nas versões modernas do Windows.

    >**O Windows NT e o Padrão POSIX**
    >O Windows NT representou uma adaptação sofisticada de princípios estabelecidos da ciência da computação que já estavam padronizados ou implementados em sistemas UNIX. O POSIX.1 foi ratificado em 1988 precisamente quando [Dave Cutler](https://en.wikipedia.org/wiki/Dave_Cutler) iniciou o desenvolvimento do NT na Microsoft, criando uma convergência histórica única. *O POSIX.1b-1993, publicado apenas meses antes do lançamento do NT em julho de 1993, já havia padronizado extensões avançadas de tempo real incluindo escalonamento de prioridade, travamento de memória, objetos de memória compartilhada, filas de mensagens e temporizadores de alta resolução* - capacidades que o subsistema POSIX mínimo do NT ignorou completamente.
    >
    >Em 1993, os padrões POSIX definiam capacidades sofisticadas de multiprocessamento com escalonamento de prioridade de 32 níveis, arquivos mapeados em memória, semáforos e sinais de tempo real. O Windows NT implementou apenas a revisão básica POSIX.1-1990 para conformidade com contratos governamentais.
    >
    >A o uso de threading é particularmente reveladora da influência do POSIX: enquanto o NT foi lançado com threading nativo em 1993, o [Mach](https://en.wikipedia.org/wiki/Mach_(kernel)) havia introduzido threads em sistemas semelhantes ao UNIX em 1985, oito anos antes. Os padrões de threading POSIX estavam em desenvolvimento durante a criação do NT e foram publicados como POSIX.1c em 1995.
    >
    >O POSIX.1b-1993 especificou interfaces de travamento de memória, arquivos mapeados em memória, escalonamento preemptivo de prioridade fixa com mínimo de 32 níveis de prioridade, semáforos nomeados e não-nomeados, filas de mensagens e temporizadores de precisão de nanossegundos** - tudo antes do lançamento do NT.
    >
    >A implementação POSIX real do NT foi deliberadamente mínima - suportando apenas chamadas de sistema básicas sem utilitários de shell, interfaces de threading ou extensões de tempo real. O subsistema POSIX da Microsoft era uma caixa de seleção para conformidade, não um esforço sério de compatibilidade UNIX.
    >
    >As inovações genuínas do NT foram integração arquitetônica ao invés de avanços fundamentais. O design de microkernel híbrido suportando múltiplas personalidades de  **Sistema Operacional**  (Win32, POSIX, OS/2) simultaneamente foi arquitetonicamente inovador. A implementação abrangente da Camada de Abstração de Hardware excedeu as abordagens de portabilidade contemporâneas. A arquitetura de segurança integrada com controle de acesso baseado em capacidades representou um avanço genuíno sobre o modelo mais simples usuário/grupo/outros do UNIX.
    >
    >A vantagem arquitetônica do NT residia em seu **design unificado para multiprocessamento desde o início**, enquanto os sistemas UNIX estavam gradualmente adaptando suporte SMP. O escalonador centrado em threads do NT e a preempção integrada do kernel representaram engenharia superior de conceitos estabelecidos ao invés de inovação.
    >
    >No entanto, o UNIX mantinha vantagens significativas: **os sockets BSD tiveram uma década de refinamento até 1993, fornecendo interfaces de programação de rede maduras e comprovadas**. Os sistemas UNIX ofereciam ambientes de desenvolvimento sofisticados, estabilidade comprovada através de implantação em produção e serviços de rede abrangentes como NFS e frameworks de computação distribuída.
    >
    >A comunidade técnica avaliou o NT como **"VMS para hardware de PC"** - uma caracterização precisa dado que Cutler transferiu diretamente conceitos de sua experiência com [VMS](https://www.stromasys.com/resources/future-of-vax-vms-migration-and-emulation/). Alegações persistem de que o NT incorporou código do sistema operacional [PRISM](https://en.wikipedia.org/wiki/DEC_MICA) cancelado da DEC, apoiando ainda mais a narrativa de adaptação ao invés de inovação.

5. **Linux** - Concebido em 1991 por [Linus Torvalds](https://pt.wikipedia.org/wiki/Linus_Torvalds) como um hobby pessoal para criar um sistema semelhante ao [MINIX](https://www.minix3.org/) para computadores 386, o Linux evoluiu para se tornar um dos projetos de software livre mais bem-sucedidos da história. Sua arquitetura monolítica modular permite a incorporação dinâmica de funcionalidades através de módulos carregáveis, oferecendo flexibilidade sem comprometer performance. O desenvolvimento do Linux seguiu um modelo colaborativo distribuído sem precedentes, conhecido como "bazar" segundo [Eric Raymond](https://pt.wikipedia.org/wiki/Eric_S._Raymond), onde milhares de desenvolvedores contribuem simultaneamente para diferentes aspectos do sistema. Tecnicamente, o Linux implementa recursos avançados como gerenciamento de memória virtual, multiprocessamento simétrico (SMP), agendamento de tarefas em tempo real, e suporte extensivo a sistemas de arquivos diversos ([ext4](https://www.kernel.org/doc/html/latest/admin-guide/ext4.html), [Btrfs](https://btrfs.readthedocs.io/en/latest/), [ZFS](https://docs.freebsd.org/en/books/handbook/zfs/)). Sua natureza de código aberto, e a linguagem **C**, permitiram adaptações para uma variedade extraordinária de plataformas, desde supercomputadores até dispositivos embarcados, smartphones (Android), e sistemas de tempo real.

>A [Linux Fundation](https://www.linuxfoundation.org/), criada em 2000, desempenhou um papel crucial na promoção e suporte ao desenvolvimento do Linux, garantindo sua sustentabilidade e evolução contínua. O Linux não é apenas um sistema operacional; é uma plataforma que impulsiona a inovação em diversas áreas, desde servidores web até dispositivos móveis, e continua a ser um pilar fundamental da infraestrutura de TI moderna. Porém, do ponto de vista do desenvolvimento de sistemas operacionais dizemos que o Línux é o Kernel, ou núcleo, de um sistema operacional. Neste caso, um Kernel monolítico.

![Lista contendo os logos da Ericsson, Microsoft, Fujitsu, Hitachi, Huawe, Intel, Meta, Nec, Oracle, Qualcomm, IBM, RedHat e Samsung ](/assets/images/linus-donors.webp)
_Figura 4: Lista dos Maiores Doadores da Linux Foundation._{: class="legend"}

A era do PC inicialmente levou a uma simplificação de alguns recursos do Sistema Operacional em comparação com os  **Sistemas Operacionais**  de mainframe, mas gradualmente reintroduziu sofisticação conforme o hardware se tornava mais poderoso.

## Fronteiras Modernas

As últimas décadas foram marcadas por uma proliferação sem precedentes de novas plataformas e paradigmas computacionais. Esta evolução transformou não apenas a forma como os seres humanos interagem com a tecnologia, mas também expandiu as capacidades de processamento, armazenamento e comunicação de dados. Desde os dispositivos móveis que se tornaram extensões de nossas vidas cotidianas, quase como órteses, até as vastas infraestruturas de computação em nuvem e os complexos sistemas distribuídos que sustentam a economia digital global, cada avanço representa um novo horizonte de possibilidades e tem impacto profundo nas tecnologias que usamos para desenvolver os sistemas operacionais.

Tecnologias como **computação móvel**, **sistemas distribuídos**, **computação em nuvem** e, mais recentemente, **computação quântica** e **inteligência artificial** estão moldando os sistemas operacionais modernos. Ao mesmo tempo em que só podem ser criadas graças a existência destes sistemas em uma laço de realimentação. Entre estas inovações, destacamos que a convergência entre Modelos de Linguagem de Grande Escala (LLMs) e computação quântica está força a criação urgente de uma nova geração de sistemas operacionais que combinará processamento de linguagem natural avançado com capacidades computacionais quânticas. Esta sinergia tecnológica promete revolucionar não apenas a interação humano-computador, mas também as capacidades fundamentais de processamento e segurança dos sistemas computacionais.

### Sistemas Operacionais Móveis

A ascensão dos dispositivos móveis, como smartphones e tablets, redefiniu a computação pessoal e impulsionou a necessidade de sistemas operacionais altamente especializados. Diferentemente dos sistemas para desktops, os sistemas operacionais móveis são projetados para operar em hardware com recursos inerentemente limitados em termos de capacidade de processamento, memória e autonomia de bateria.

Desde o iPhone (2005), o foco no design dos sistemas operacionais móveis centrou-se em interfaces de toque intuitivas, com a introdução de gestos multitoque como *swiping* e *pinch-to-zoom*, que se tornaram padrão e transformaram a experiência do usuário em um diferencial competitivo fundamental. Com impacto direto na criação de novos conceitos para o desenvolvimento dde sistemas operacionais, como a introdução de *widgets* e notificações interativas, que permitiram uma interação mais dinâmica e personalizada com o usuário. Além disso, a integração de sensores como acelerômetros, giroscópios e GPS ampliou as possibilidades de interação e personalização, permitindo que os dispositivos móveis se tornassem não apenas ferramentas de comunicação, mas também plataformas multifuncionais para uma variedade de aplicações, desde navegação até monitoramento de saúde.

As duas plataformas predominantes no mercado de sistemas operacionais móveis são o [Android](https://www.android.com/intl/pt_br/what-is-android/), desenvolvido pelo Google, e o [iOS](https://www.apple.com/br/ios/ios-18/), da Apple. O Android é baseado no kernel Linux e adota um modelo de código aberto, o que permite aos fabricantes uma ampla customização e adaptação aos seus dispositivos, embora essa flexibilidade também contribua para a fragmentação do ecossistema. O Android utiliza o [SQLite](https://www.sqlite.org/) para armazenamento de dados estruturados e, historicamente, a [máquina virtual Dalvik](https://source.android.com/docs/core/runtime?hl=pt-br), posteriormente substituída pela [Android Runtime - ART](https://source.android.com/docs/core/ota/modular-system/art?hl=pt-br), para a execução de aplicativos desenvolvidos primariamente em Java ou Kotlin. O Android oferece suporte extensivo a uma vasta gama de tecnologias de conectividade, incluindo GSM/EDGE, CDMA, EV-DO, UMTS, LTE, 5G, Bluetooth, Wi-Fi e WiMAX.

O iOS é derivado do [macOS](https://www.apple.com/br/macos/macos-sequoia/) e opera em um modelo de plataforma fechada, com uma integração vertical forte entre hardware e software, o que frequentemente resulta em alto desempenho e otimização de recursos. Sua arquitetura é organizada em camadas distintas: *Core OS, que inclui o kernel do sistema operacional, gerenciamento de energia e segurança*, *Core Services, responsável por serviços como acesso a arquivos, rede e banco de dados SQLite*, *Media, para áudio, vídeo e gráficos, e *Cocoa Touch, que gerencia as interações do usuário, incluindo gestos multitoque e acesso a sensores*.

A conectividade é uma das pedras angulares dos sistemas operacionais móveis, com suporte essencial para um amplo espectro de tecnologias de rede, incluindo Wi-Fi, redes celulares (3G, 4G e, cada vez mais, 5G) e Bluetooth, garantindo comunicação constante e acesso a serviços online. A chegada do 5G, com suas promessas de velocidades significativamente mais altas e latência ultrabaixa, impõe novas demandas aos sistemas operacionais móveis para gerenciar essas capacidades e habilitar novas classes de aplicações, como realidade aumentada (AR) e interações em tempo real mais ricas.

Segurança e privacidade são preocupações primordiais no design de sistemas operacionais móveis. Eles implementam modelos de permissão granulares, exigindo consentimento explícito do usuário para que aplicativos acessem recursos sensíveis como câmera, microfone, dados de localização e contatos. O *sandboxing* de aplicativos é uma técnica comum, isolando os processos e dados de cada aplicativo para prevenir interferências maliciosas e limitar o impacto de possíveis vulnerabilidades. A criptografia de dados, tanto em repouso no dispositivo quanto em trânsito pela rede, é amplamente utilizada para proteger informações sensíveis. Apesar desses mecanismos, os sistemas operacionais móveis enfrentam desafios contínuos devido à evolução constante de ameaças cibernéticas sofisticadas e à complexidade do ecossistema de aplicativos.

A amável leitora deve ter usado um destes sistemas operacionais móveis e percebido que ambos colocam uma ênfase significativa em segurança e privacidade, incorporando recursos como autenticação biométrica e criptografia de ponta a ponta para comunicações. No entanto, o gerenciamento eficiente de energia é, talvez, o desafio mais importante para os sistemas operacionais móveis, dada a dependência de baterias com capacidade finita. Para enfrentar essa questão, os sistemas operacionais móveis empregam estratégias sofisticadas. Estas estratégias incluem o gerenciamento dinâmico de estados de energia dos componentes de hardware, como a CPU, que pode operar em modos de baixo consumo ou ser colocada em estados de *sleep* durante períodos de inatividade. Isso só é possível graças a relação simbiótica entre o sistema operacional e o hardware, nesta relação, o sistema operacional é responsável por monitorar a atividade do usuário e ajustar dinamicamente o desempenho da CPU e outros componentes para otimizar o consumo de energia. Novamente em um laço de realimentação: há uma necessidade, cria-se um hardware que atenda a esta necessidade, o sistema operacional é adaptado para tirar proveito deste hardware, e assim por diante.

O Android, por exemplo, implementa seu próprio sistema de gerenciamento de energia sobre o [Linux Power Management](https://docs.kernel.org/power/index.html), utilizando **wake locks** para permitir que aplicações requisitem recursos da CPU apenas quando necessário, garantindo que a CPU não consuma energia desnecessariamente se não houver aplicações ou serviços ativos demandando processamento.

É possível que a observadora leitora tenha notado, nos últimos anos, a evolução das técnicas de gerenciamento de energia, transcendendo os modos manuais de economia para sistemas adaptativos e preditivos baseados em inteligência artificial. O Android introduziu recursos como **Adaptive Battery**, que aprende os padrões de uso do usuário para otimizar o consumo de energia, gerenciando o desempenho e a eficiência em segundo plano.Similarmente, o iOS, a partir da versão 19, deve introduzir otimizações de bateria baseadas em inteligência artificial, que aprendem os hábitos de uso de aplicativos, limitam atividades em segundo plano de forma inteligente e preveem necessidades de recarga, com todo o processamento ocorrendo no dispositivo para preservar a privacidade do usuário.

_A atenta leitora deve ter em mente que esta transição para uma gestão energética proativa, na qual o Sistema Operacional antecipa e se adapta às necessidades do usuário de forma quase invisível, usando inteligência artificial, representa uma mudança fundamental, aliviando o usuário da carga cognitiva de gerenciar manualmente essas configurações. Tirando relação entre hardware e software do mundo determinístico da computação imperativa para o mundo probabilístico, mais fluido e adaptativo da inteligência artificial. Neste admirável mundo novo o sistema aprenderá e se ajustará continuamente às necessidades do usuário._

A crescente sofisticação da IA no gerenciamento de energia e na personalização da experiência do usuário, embora traga benefícios evidentes em termos de usabilidade e eficiência, também levanta questões importantes sobre a privacidade dos dados de uso do dispositivo. Mesmo com o processamento ocorrendo localmente no dispositivo, como destacado para o iOS, a coleta e análise detalhada de hábitos de uso – quais aplicativos são usados, em que horários, possivelmente inferindo locais e rotinas – são inerentemente sensíveis. Surge um dilema entre a conveniência da automação inteligente, que torna o gerenciamento de recursos "invisível e contínuo", e a manutenção da transparência e do controle por parte do usuário sobre as operações do seu dispositivo. Enquanto algumas plataformas, como a One UI da Samsung, buscam oferecer "controles granulares", a tendência geral da IA é para uma adaptação cada vez mais autônoma. Este equilíbrio delicado entre personalização avançada, privacidade e controle do usuário continuará a ser um campo de debate e desenvolvimento crucial para os futuros sistemas operacionais móveis, podendo influenciar as preferências dos consumidores e até mesmo levar a novas regulamentações sobre os dados utilizados por IAs embarcadas.

A tabela a seguir apresenta um comparativo entre as duas principais plataformas de sistemas operacionais móveis, Android e iOS, destacando suas características fundamentais e abordagens recentes, especialmente no que tange ao gerenciamento de energia.

| Característica | Android | iOS |
| :---- | :---- | :---- |
| **Arquitetura Base** | Kernel Linux | Derivado do macOS, arquitetura em camadas (Core OS, Core Services, Media, Cocoa Touch) |
| **Modelo de Distribuição** | Código aberto, customizável por fabricantes | Plataforma fechada, proprietária da Apple |
| **Interface Predominante** | Interfaces de toque, alta customização da UI pelos fabricantes | Interfaces de toque (multitoque, gestos), design de UI consistente e controlado pela Apple |
| **Gerenciamento de Energia** | Android Power Management, wake locks, Adaptive Battery, controles granulares (One UI) | Gerenciamento de energia integrado, otimização de bateria baseada em IA (a partir do iOS 19) |
| **Conectividade** | Amplo suporte: GSM/EDGE, CDMA, EV-DO, UMTS, LTE, 5G, Bluetooth, Wi-Fi, WiMAX | Amplo suporte: GSM/EDGE, CDMA, EV-DO, UMTS, LTE, 5G, Bluetooth, Wi-Fi |
| **Segurança** | Sandboxing de apps, modelo de permissões, criptografia, Google Play Protect | Sandboxing de apps, modelo de permissões, criptografia forte, Face ID/Touch ID, Secure Enclave |
| **Ecossistema de Aplicativos** | Google Play Store, permite sideloading (instalação de apps de fora da loja oficial) | Apple App Store, política restrita de distribuição de apps |

_Tabela 1: Comparativo entre Android e iOS, destacando suas características fundamentais e abordagens recentes, especialmente no que tange ao gerenciamento de energia._{: class="legend"}

A atenta leitora deve observar que esta comparação evidencia as filosofias distintas de design e as abordagens para desafios comuns, como o gerenciamento de energia, na qual ambas as plataformas estão convergindo para soluções mais inteligentes e adaptativas.

#### Sistemas Distribuídos

_Um sistema distribuído é conceitualmente definido como uma coleção de computadores autônomos que se comunicam e cooperam através de uma rede, mas que se apresentam aos seus usuários como um único sistema coerente e unificado_. Os principais objetivos para a construção de sistemas distribuídos são: o compartilhamento eficiente de recursos, hardware, software ou dados; o aumento de desempenho através do processamento paralelo; e a obtenção de maior confiabilidade e disponibilidade.

Para que um sistema distribuído funcione efetivamente e seja percebido como uma entidade única, ele deve exibir algumas características. Entre elas, destaca-se a **transparência** como uma das mais importantes. Neste caso, usamos a palavra transparência para fazer referência à capacidade do sistema de ocultar a separação e a distribuição de seus componentes dos usuários e dos programadores de aplicação. Existem diversas formas de transparência, sendo a **transparência de localização** e a **transparência de acesso** particularmente comuns.

A **transparência de localização** garante que usuários e aplicações não precisem conhecer a localização física dos recursos, enquanto a **transparência de acesso** assegura que recursos locais e remotos sejam acessados utilizando operações idênticas, abstraindo os detalhes de como o acesso é realizado. Mas, estas não são as únicas formas de transparência de Sistemas Operacionais Distribuídos. Outras formas incluem as transparências de replicação, falha, concorrência e migração, todas contribuindo para a ilusão de um sistema único.

A **escalabilidade** é outra característica importante. Neste caso, _a escalabilidade denota a capacidade do sistema operar de forma eficaz e eficiente em diferentes escalas, ou seja, de se adaptar ao aumento da demanda por recursos sem que haja uma degradação significativa no desempenho ou a necessidade de alterar fundamentalmente o software ou as aplicações existentes_. Em um mundo ideal, o processamento deve ser independente do tamanho da rede. No entanto, a escalabilidade pode ser limitada por gargalos como algoritmos centralizados, dados centralizados ou serviços centralizados que atendem a todos os usuários e que não possam ser distribuídos por limitações técnicas, econômicas ou de segurança.

Finalmente, _a **tolerância a falhas** é a propriedade que permite a um sistema distribuído continuar operando corretamente, possivelmente com desempenho degradado, mesmo quando alguns de seus componentes falham_. Isso é tipicamente alcançado através da redundância de hardware, software e dados, combinada com um design de software que permite a recuperação do estado consistente após a detecção de uma falha. As falhas podem ser classificadas como transientes, ocorrem uma vez e desaparecem, intermitentes, ocorrem esporadicamente, ou permanentes, persistem até serem reparadas. Intimamente relacionada à tolerância a falhas está a **disponibilidade**, que em _sistemas distribuídos implica que a falha de um componente geralmente afeta apenas a parte do sistema que utiliza diretamente aquele componente, permitindo que o restante continue funcional_.

Atualmente, uma das tendências mais significativas no desenvolvimento de sistemas distribuídos, com impacto direto na criação de sistemas operacionais, é a adoção da **arquitetura de microserviços**, que propõe _a decomposição de aplicações monolíticas complexas em um conjunto de serviços menores, independentes e fracamente acoplados_. Cada microserviço executa seu próprio processo e se comunica com outros serviços através de APIs leves, frequentemente baseadas em HTTP/REST. Esta abordagem oferece benefícios como implantação independente de cada serviço, escalabilidade granular, permitindo que apenas os serviços mais demandados sejam escalados, e a possibilidade de usar diferentes tecnologias para diferentes serviços. A integração de microserviços com tecnologias de conteinerização, como [Docker](https://www.docker.com/), e orquestradores, como [Kubernetes](https://kubernetes.io/), tem se mostrado particularmente eficaz para aumentar a tolerância a falhas e a resiliência, pois falhas em um microserviço podem ser isoladas sem derrubar toda a aplicação.

Outra tendência proeminente é a **arquitetura orientada a eventos (Event-Driven Architecture - EDA)**. Em sistemas **EDA**, os componentes reagem a eventos, notificações assíncronas que representam ocorrências significativas, promovendo um baixo acoplamento entre eles e facilitando a escalabilidade. Por exemplo, em um sistema de comércio eletrônico, a conclusão de uma compra pode gerar um evento que é consumido por outros serviços, como o de faturamento, o de notificação ao cliente e o de expedição, sem que o serviço de compra precise conhecer diretamente esses outros serviços. O uso de servidores de mensagens, como [Apache Kafka](https://kafka.apache.org/), é comum em EDAs para mediar a comunicação assíncrona.

O **modelo distribuído [AKKA](https://akka.io/)**, implementado por um toolkit e runtime para construir aplicações concorrentes, distribuídas e resilientes na JVM, Java Virtual Machine, baseado no modelo de atores, também ganhou tração para a construção de sistemas concorrentes e distribuídos resilientes e escaláveis. Os atores são entidades computacionais leves que se comunicam exclusivamente através da troca de mensagens assíncronas, embora padrões síncronos como "ask" possam ser implementados sobre a comunicação assíncrona "tell". Estes atores podem ser distribuídos em um cluster de máquinas, permitindo que aplicações complexas sejam construídas a partir da composição de múltiplos atores colaborando para um objetivo comum. Aqui há uma relação interessante entre sistemas operacionais, sistemas distribuídos, máquinas virtuais e linguagens de programação. O AKKA é uma implementação do modelo de atores, que foi proposto por [Carl Hewitt](https://en.wikipedia.org/wiki/Carl_Hewitt) em 1973, e que foi inspirado no conceito de processos concorrentes do [Lisp](https://pt.wikipedia.org/wiki/Lisp_(linguagem_de_programa%C3%A7%C3%A3o)). O AKKA foi escrito em [Scala](https://www.scala-lang.org/), uma linguagem funcional que roda na JVM, e que permite a criação de aplicações distribuídas e reativas com alta performance e baixa latência.

A esperta leitora deve considerar que as novas tendências arquitetônicas, como microserviços e EDA, não surgem isoladamente, mas como respostas evolutivas diretas aos desafios de concretizar as características fundamentais de escalabilidade e tolerância a falhas em sistemas que se tornam progressivamente mais complexos e com demandas crescentes. Aplicações monolíticas tradicionais, por exemplo, enfrentam dificuldades intrínsecas para escalar componentes individuais de forma granular ou para isolar falhas eficazmente; uma falha em um módulo pode comprometer todo o sistema. Em contraste, a arquitetura de microserviços, ao decompor a aplicação em unidades menores e independentes, permite que cada serviço seja escalado conforme sua necessidade específica e que falhas sejam contidas dentro do serviço afetado, preservando a funcionalidade do restante do sistema. Similarmente, a EDA, ao promover o desacoplamento através da comunicação assíncrona baseada em eventos, aumenta a resiliência, os serviços não dependem diretamente da disponibilidade imediata uns dos outros< e a escalabilidade, os produtores de eventos podem operar independentemente dos consumidores.

A proliferação de componentes distribuídos, sejam eles microserviços, atores, ou os inúmeros dispositivos de borda em um sistema de IoT, acarreta um aumento exponencial na complexidade do gerenciamento do sistema como um todo. Manter a coerência, a eficiência, o monitoramento e a depuração em um ambiente com milhares ou milhões de partes móveis é um desafio formidável que deve ser enfrentado pelos Sistemas Operacionais. Isso aponta para uma possível evolução em direção a sistemas operacionais distribuídos, ou camadas de gerenciamento de sistema equivalentes, que incorporem níveis mais elevados de inteligência artificial e aprendizado de máquina. Tais sistemas poderiam realizar auto-configuração, auto-otimização, auto-reparação e gerenciamento proativo de recursos de forma mais autônoma, uma trajetória análoga à observada nos sistemas operacionais móveis com suas capacidades adaptativas de gerenciamento de energia.

A tabela a seguir resume as propriedades essenciais dos sistemas distribuídos e como as tendências arquitetônicas modernas se alinham e aprimoram essas propriedades.

| Paradigma/Característica | Descrição | Tecnologias/Exemplos Chave | Benefícios Principais |
| :---- | :---- | :---- | :---- |
| **Transparência** (Localização, Acesso) | Ocultar a distribuição dos componentes, permitindo acesso uniforme a recursos locais/remotos. | Middleware, RPC, Nomes de Serviço. | Simplificação do desenvolvimento, percepção de sistema único. |
| **Escalabilidade** | Capacidade de operar eficientemente em diferentes escalas, adaptando-se ao aumento da demanda. | Balanceamento de Carga, Replicação, Particionamento de Dados. | Suporte ao crescimento, desempenho consistente. |
| **Tolerância a Falhas** | Continuar operando corretamente mesmo com falhas em componentes, através de redundância e recuperação. | Replicação de Dados/Serviços, Checkpointing, Transações Distribuídas. | Alta disponibilidade, resiliência. |
| **Arquitetura de Microserviços** | Decomposição da aplicação em pequenos serviços independentes e fracamente acoplados. | Docker, Kubernetes, APIs REST/gRPC. | Implantação independente, escalabilidade granular, diversidade tecnológica, resiliência. |
| **Arquitetura Orientada a Eventos (EDA)** | Sistemas reagem a eventos assíncronos, promovendo baixo acoplamento e escalabilidade. | Apache Kafka, RabbitMQ, Filas de Mensagens. | Desacoplamento, escalabilidade, resiliência, capacidade de resposta em tempo real. |
| **Computação de Borda/Névoa** | Processamento de dados mais próximo da origem, reduzindo latência e uso de banda. | Dispositivos IoT, Gateways de Borda, Edge AI, Plataformas de Fog Computing. | Baixa latência, economia de banda, processamento em tempo real, privacidade aprimorada. |

_Tabela 2: Propriedades essenciais dos sistemas distribuídos e como as tendências arquitetônicas modernas se alinham e aprimoram essas propriedades._{: class="legend"}

Esta visão panorâmica conecta os conceitos teóricos fundamentais dos sistemas distribuídos com as implementações práticas e as tendências que estão moldando ativamente este campo vital da computação.

### Computação em Nuvem

A [computação em nuvem](https://nvlpubs.nist.gov/nistpubs/legacy/sp/nistspecialpublication800-145.pdf), conforme definida pelo Instituto Nacional de Padrões e Tecnologia dos Estados Unidos (NIST), é um modelo que permite o acesso de rede ubíquo, conveniente e sob demanda a um conjunto compartilhado de recursos computacionais configuráveis. Tais como redes, servidores, armazenamento, aplicações e serviços que podem ser rapidamente provisionados e liberados com mínimo esforço de gerenciamento ou interação com o provedor de serviços. Esta definição é sustentada por cinco características essenciais, três modelos de serviço e quatro modelos de implantação que, juntos, definem o paradigma que conhecemos como computação em nuvem.

####################################################################PAREI AQUI####################################################################
As cinco características essenciais da computação em nuvem, de acordo com o NIST, são:

1. **Autoatendimento sob demanda (*On-demand self-service*):** Um consumidor pode provisionar unilateralmente capacidades computacionais, como tempo de servidor e armazenamento de rede, conforme necessário e automaticamente, sem requerer interação humana com cada provedor de serviço.
2. **Amplo acesso à rede (*Broad network access*):** As capacidades estão disponíveis através da rede e são acessadas por meio de mecanismos padrão que promovem o uso por plataformas de cliente heterogêneas (por exemplo, telefones celulares, tablets, laptops e estações de trabalho).
3. **Agrupamento de recursos (*Resource pooling*):** Os recursos computacionais do provedor são agrupados para servir a múltiplos consumidores usando um modelo multilocatário (*multi-tenant*), com diferentes recursos físicos e virtuais dinamicamente atribuídos e realocados de acordo com a demanda do consumidor. Há uma sensação de independência de localização, pois o cliente geralmente não tem controle ou conhecimento sobre a localização exata dos recursos fornecidos, mas pode ser capaz de especificar a localização em um nível mais alto de abstração (por exemplo, país, estado ou datacenter).
4. **Rápida elasticidade (*Rapid elasticity*):** As capacidades podem ser provisionadas e liberadas elasticamente, em alguns casos automaticamente, para escalar rapidamente para fora (aumentar) e para dentro (diminuir) de acordo com a demanda. Para o consumidor, as capacidades disponíveis para provisionamento muitas vezes parecem ser ilimitadas e podem ser apropriadas em qualquer quantidade, a qualquer momento.
5. **Serviço mensurado (*Measured service*):** Os sistemas em nuvem controlam e otimizam automaticamente o uso de recursos, aproveitando uma capacidade de medição em algum nível de abstração apropriado ao tipo de serviço (por exemplo, armazenamento, processamento, largura de banda e contas de usuário ativas). O uso de recursos pode ser monitorado, controlado e relatado, fornecendo transparência tanto para o provedor quanto para o consumidor do serviço utilizado, frequentemente resultando em um modelo de pagamento pelo uso (*pay-as-you-go*).

Dentre estes, a **elasticidade** é um princípio particularmente distintivo da nuvem. Refere-se à capacidade de um sistema baseado em nuvem de ajustar dinamicamente os recursos alocados – como poder de computação, memória ou armazenamento – em resposta a flutuações de demanda em tempo real. Isso difere da escalabilidade tradicional, que se refere mais à capacidade planejada de um sistema para lidar com um pico de carga antecipado. A elasticidade permite que o sistema escale automaticamente para cima durante picos de tráfego e para baixo quando a demanda diminui, otimizando tanto o desempenho quanto os custos. Ela pode operar horizontalmente (*scaling out*), adicionando mais instâncias ou servidores, ou verticalmente (*scaling up*), aumentando a capacidade dos recursos existentes. Essencialmente, a elasticidade visa prevenir o superprovisionamento (desperdício de recursos ociosos) e a subutilização (degradação do desempenho por falta de recursos).

O **provisionamento sob demanda**, intrinsecamente ligado à característica de autoatendimento sob demanda do NIST, permite que os usuários obtenham e configurem recursos computacionais conforme suas necessidades, tipicamente através de um portal web ou APIs, sem a necessidade de intervenção manual demorada por parte do provedor de serviços. Isso contrasta fortemente com os modelos tradicionais de aquisição de TI, que envolvem longos ciclos de compra e configuração de hardware. Com o provisionamento sob demanda, as empresas podem acessar rapidamente os recursos de que precisam e pagar apenas pelo que efetivamente utilizam, evitando grandes investimentos iniciais em infraestrutura.

A **multilocação (*multitenancy*)** é uma arquitetura de software onde uma única instância de uma aplicação de software, rodando em um servidor, atende a múltiplos clientes, chamados locatários. Cada locatário tem seus dados e configurações isolados e mantidos seguros dos outros locatários, embora compartilhem a mesma infraestrutura subjacente. Este princípio é fundamental para a eficiência de custos da nuvem pública e é um facilitador chave para a característica de "agrupamento de recursos" definida pelo NIST, permitindo que os provedores de nuvem otimizem a utilização de seus datacenters.

Os modelos de serviço da nuvem, conforme o NIST, categorizam como os recursos da nuvem são oferecidos:

* **Software como Serviço (SaaS):** O consumidor utiliza aplicações do provedor que rodam na infraestrutura da nuvem. O consumidor não gerencia a infraestrutura subjacente, mas pode ter controle limitado sobre configurações específicas da aplicação (ex: Gmail, Salesforce).
* **Plataforma como Serviço (PaaS):** O consumidor implanta na infraestrutura da nuvem aplicações criadas por ele ou adquiridas, usando linguagens de programação, bibliotecas, serviços e ferramentas suportadas pelo provedor. O consumidor não gerencia a infraestrutura subjacente (rede, servidores, sistemas operacionais, armazenamento), mas tem controle sobre as aplicações implantadas e, possivelmente, configurações do ambiente de hospedagem da aplicação (ex: AWS Elastic Beanstalk, Google App Engine).
* **Infraestrutura como Serviço (IaaS):** O consumidor provisiona processamento, armazenamento, redes e outros recursos computacionais fundamentais onde pode implantar e executar software arbitrário, que pode incluir sistemas operacionais e aplicações. O consumidor não gerencia a infraestrutura da nuvem subjacente, mas tem controle sobre os sistemas operacionais, armazenamento e aplicações implantadas, e possivelmente controle limitado de componentes de rede selecionados (ex: Amazon EC2, Microsoft Azure VMs).

Finalmente, os modelos de implantação descrevem como a infraestrutura da nuvem é organizada e quem tem acesso a ela:

* **Nuvem Pública:** A infraestrutura da nuvem é provisionada para uso aberto pelo público em geral. Pertence, é gerenciada e operada por uma organização empresarial, acadêmica ou governamental, ou alguma combinação delas.
* **Nuvem Privada:** A infraestrutura da nuvem é provisionada para uso exclusivo por uma única organização que compreende múltiplos consumidores (

## As Funções Essenciais: O Que Todo Sistema Operacional Deve Fazer

Um sistema operacional desempenha uma miríade de funções para garantir que um sistema computacional opere de forma suave, eficiente e segura. Essas funções podem ser organizadas em categorias principais, todas trabalhando em conjunto para atingir os objetivos primários do  **Sistema Operacional**.

![Diagrama central com "Sistema Operacional" no centro, conectado radialmente às principais funções (gerenciamento de processos, memória, arquivos, I/O, redes, segurança) com sub-componentes e interconexões mostrando relacionamentos](/assets/images/mapa_funcoes_essenciais_so.webp)
_Figura 5: Mapa Intuitivo das funções essenciais de um sistema operacional_{: class="legend"}

### Gerenciamento de Processos: Coordenando a Execução

Um **processo** é um programa em execução, incluindo o código do programa, seus dados, pilha, contador de programa e registradores da CPU. O sistema operacional é responsável por todas as atividades relacionadas aos processos:

**Atividades Fundamentais**:

- **Criação e exclusão** de processos de usuário e de sistema
- **Suspensão e retomada** de processos conforme necessário
- **Sincronização de processos** para coordenar acesso a recursos compartilhados
- **Comunicação entre processos (IPC)** através de pipes, sockets, memória compartilhada
- **Tratamento de deadlocks** - situações nas quais processos ficam permanentemente bloqueados

**Escalonamento da CPU**:
O escalonador determina qual processo, entre os prontos para executar, deve obter acesso à CPU:

$$\text{Tempo de Resposta} = \text{Tempo de Término} - \text{Tempo de Chegada}$$

$$\text{Tempo de Espera} = \text{Tempo de Resposta} - \text{Tempo de Execução}$$

**Algoritmos de Escalonamento Comuns**:

- **First-Come, First-Served (FCFS)**: processos são executados na ordem de chegada
- **Shortest Job First (SJF)**: prioriza processos com menor tempo de execução estimado
- **Round Robin**: cada processo recebe uma fatia de tempo fixa
- **Priority Scheduling**: processos com maior prioridade são executados primeiro

### Gerenciamento de Memória: Otimizando o Uso de RAM

A memória principal (RAM) é um recurso volátil que deve ser gerenciado cuidadosamente:

**Responsabilidades Principais**:

- **Controle de alocação**: manter rastreamento de quais partes da memória estão em uso
- **Alocação dinâmica**: atribuir e liberar espaço conforme processos são criados e terminados
- **Proteção de memória**: garantir que processos não acessem memória de outros processos
- **Gerenciamento de memória virtual**: criar ilusão de mais memória que a fisicamente disponível

**Técnicas de Gerenciamento**:

1. **Particionamento Fixo**: memória dividida em partições de tamanho fixo
2. **Particionamento Dinâmico**: partições criadas dinamicamente conforme necessário
3. **Paginação**: memória dividida em páginas de tamanho fixo

   $$\text{Endereço Físico} = \text{Número da Página} \times \text{Tamanho da Página} + \text{Offset}$$

4. **Segmentação**: memória dividida em segmentos de tamanho variável

**Memória Virtual**:
Permite que programas maiores que a memória física sejam executados através de:

- **Swapping**: mover processos inteiros entre memória e disco
- **Paginação sob demanda**: carregar páginas apenas quando necessárias

### Gerenciamento do Sistema de Arquivos: Organizando Dados Persistentes

O sistema de arquivos fornece uma visão lógica e uniforme do armazenamento de informações:

**Funcionalidades Essenciais**:

- **Operações básicas**: criar, ler, escrever, excluir arquivos e diretórios
- **Organização hierárquica**: estrutura em árvore de diretórios
- **Mapeamento para storage**: tradução de arquivos lógicos para blocos físicos
- **Gerenciamento de espaço**: controle do espaço livre e alocação
- **Controle de acesso**: permissões e direitos de usuários

**Estruturas de Dados**:

- **Tabela de arquivos abertos**: rastreia arquivos atualmente em uso
- **Diretórios**: mapeiam nomes para localizações de arquivos
- **Metadados**: informações sobre arquivos (tamanho, data de criação, permissões)

### Gerenciamento de Entrada/Saída: Coordenando Dispositivos

O  **Sistema Operacional**  gerencia a comunicação entre o computador e seus diversos dispositivos:

**Componentes Principais**:

- **Drivers de dispositivo**: software específico para cada tipo de hardware
- **Sistema de interrupções**: mecanismo para dispositivos sinalizarem eventos
- **Buffering**: áreas temporárias para compensar diferenças de velocidade
- **Caching**: armazenamento de dados frequentemente acessados

**Técnicas de E/S**:

1. **E/S Programada**: CPU verifica constantemente status do dispositivo
2. **E/S por Interrupção**: dispositivo interrompe CPU quando termina operação
3. **DMA (Direct Memory Access)**: dispositivo acessa memória diretamente

### Suporte a Redes: Conectividade e Comunicação

Sistemas operacionais modernos fornecem capacidades de rede integradas:

**Funcionalidades de Rede**:

- **Gerenciamento de interfaces**: configuração de placas de rede
- **Implementação de protocolos**: pilha TCP/IP, routing
- **Compartilhamento de recursos**: arquivos, impressoras, serviços
- **Sistemas de arquivos distribuídos**: NFS, SMB/CIFS
- **Comunicação remota**: sockets, RPC (Remote Procedure Call)

### Segurança e Proteção: Garantindo Integridade

Estes aspectos são cruciais para a confiabilidade do sistema:

**Proteção**: mecanismos para controlar acesso de processos a recursos
- **Modos de operação**: kernel mode vs. user mode
- 
- **Proteção de memória**: isolamento entre processos
- **Proteção de E/S**: controle de acesso a dispositivos

**Segurança**: defesa contra ameaças internas e externas

- **Autenticação**: verificação de identidade de usuários
- **Autorização**: controle de permissões de acesso
- **Auditoria**: registro de atividades para detecção de problemas

## Duas Perspectivas Fundamentais: Compreendendo a Natureza Dual dos Sistemas Operacionais

Para compreender plenamente a natureza e o papel de um sistema operacional, é útil considerá-lo sob duas perspectivas distintas, porém complementares: como um **gerente de recursos** e como uma **máquina estendida**.

![Diagrama conceitual com duas visões lado a lado: (1)  **Sistema Operacional**  como gerente de recursos mostrando alocação de CPU, memória, I/O; (2)  **Sistema Operacional**  como máquina estendida mostrando camadas de abstração do hardware até aplicações](/assets/images/perspectivas_duais_so.webp)
_Figura 6: As duas perspectivas fundamentais dos sistemas operacionais - Gerente de Recursos e Máquina Estendida_{: class="legend"}

### O Sistema Operacional como Gerente de Recursos

Nesta visão, o foco principal do sistema operacional é **gerenciar e alocar todos os recursos do sistema** de forma controlada e eficiente. O  **Sistema Operacional**  atua como um "governo" ou "programa de controle", tomando decisões sobre como distribuir recursos entre programas e usuários concorrentes.

**Recursos Gerenciados**:

- **Tempo da CPU**: através de algoritmos de escalonamento
- **Espaço na memória principal**: via gerenciamento de memória
- **Espaço em dispositivos de armazenamento**: através do sistema de arquivos
- **Dispositivos de E/S**: por meio de drivers e filas de requisições

**Tarefas Fundamentais do Gerente de Recursos**:

1. **Monitoramento**: manter controle do uso dos recursos
2. **Políticas de alocação**: decidir quem obtém qual recurso e quando
3. **Recuperação**: liberar recursos após o uso para realocação

**Exemplo: Escalonamento de CPU**

```shell
Processo A ────┐
Processo B ────┼──→ Escalonador ──→ CPU
Processo **C** ────┘
```

O escalonador implementa políticas como:

- **Prioridades**: processos críticos primeiro
- **Justiça**: todos os processos recebem tempo de CPU
- **Eficiência**: minimizar overhead de troca de contexto

### O Sistema Operacional como Máquina Estendida

Alternativamente, o sistema operacional pode ser visto como uma entidade que **fornece uma interface mais simples, limpa e poderosa** do que a oferecida diretamente pelo hardware bruto.

**Abstrações Fundamentais**:

- **Arquivos e Diretórios**: em vez de setores e trilhas de disco
- **Processos**: em vez de controle direto da CPU
- **Memória Virtual**: em vez de endereços físicos de memória
- **Sockets**: em vez de controle direto de placas de rede

**Hierarquia de Abstrações**:

```shell
Aplicações
    ↑
Sistema Operacional (Chamadas de Sistema)
    ↑
Hardware
```

Cada camada esconde a complexidade da camada inferior, fornecendo uma interface mais conveniente para a camada superior.

**Exemplo: Abstração de Arquivos**
Um simples comando como `write("arquivo.txt", dados)` esconde:

- Localização física no disco
- Controle do motor do disco
- Gerenciamento de setores defeituosos
- Conversão de dados para formato do disco
- Sincronização com outros acessos ao disco

### Visões Complementares: A Sinergia entre Gerência e Abstração

As duas perspectivas não são contraditórias, mas sim **facetas complementares** do mesmo sistema:

**Relação Simbiótica**:

- A **máquina estendida** utiliza as capacidades de **gerenciamento de recursos** para implementar abstrações
- O **gerenciamento de recursos** serve ao propósito de fornecer um ambiente conveniente (máquina estendida)

**Exemplo Integrado: Memória Virtual**:

- **Como Gerente de Recursos**: gerencia memória física escassa, decide quais páginas manter em RAM
- **Como Máquina Estendida**: fornece a cada processo a ilusão de ter um espaço de endereçamento grande e contíguo

**Trade-offs no Design**:

O equilíbrio entre essas perspectivas frequentemente envolve compromissos:

- **Simplicidade vs. Eficiência**: abstrações simples podem ter overhead
- **Segurança vs. Desempenho**: proteção rigorosa pode impactar velocidade
- **Funcionalidade vs. Confiabilidade**: mais recursos podem introduzir complexidade

Esta dualidade é fundamental para compreender como diferentes sistemas operacionais fazem escolhas de design distintas baseadas em suas prioridades e ambiente de uso.

## Objetivos Orientadores: Princípios que Guiam o Design de Sistemas Operacionais

O projeto de um sistema operacional é guiado por um conjunto de objetivos de alto nível que determinam as escolhas arquiteturais e de implementação:

### Conveniência para o Usuário

**Facilidade de Uso**: o sistema deve ser intuitivo e acessível

- **Interfaces amigáveis**: GUIs, shells, comandos intuitivos
- **Documentação clara**: manuais, help systems, tutoriais
- **Ferramentas produtivas**: editores, compiladores, depuradores

**Abstração de Complexidade**: esconder detalhes técnicos
desnecessários

- **Operações de alto nível**: em vez de controle direto de hardware
- **Automatização**: tarefas repetitivas executadas automaticamente
- **Configuração simplificada**: instalação e manutenção facilitadas

### Eficiência na Utilização de Recursos

**Otimização de Desempenho**:

- **Throughput máximo**: quantidade de trabalho por unidade de tempo
- **Tempo de resposta mínimo**: para sistemas interativos
- **Utilização equilibrada**: CPU, memória, E/S trabalhando harmoniosamente

**Métricas de Eficiência**:
$$\text{Utilização da CPU} = \frac{\text{Tempo Útil de CPU} }{\text{Tempo Total} } \times 100\%$$

$$\text{Throughput} = \frac{\text{Número de Jobs Completados} }{\text{Tempo Total} }$$

### Capacidade de Evolução e Adaptação

**Design Modular**: facilitando modificações e extensões

- **Interfaces bem definidas**: entre componentes do sistema
- **Separação de política e mecanismo**: flexibilidade de configuração
- **Drivers carregáveis**: suporte dinâmico para novo hardware

**Escalabilidade**: capacidade de crescer com as demandas

- **Suporte a múltiplos processadores**: SMP, NUMA
- **Gerenciamento de grandes volumes de memória**: 64-bit addressing
- **Sistemas distribuídos**: clusters, cloud computing

### Confiabilidade e Tolerância a Falhas

**Robustez**: capacidade de lidar com erros graciosamente

- **Detecção de falhas**: monitoring, checksums, timeouts
- **Recuperação**: rollback, restart, failover
- **Isolamento**: falhas localizadas não afetam o sistema todo

**Integridade de Dados**: garantindo consistência e durabilidade

- **Transações**: operações atômicas
- **Backups automáticos**: proteção contra perda de dados
- **Verificação de integridade**: checksums, ECC memory

### Trade-offs Inevitáveis

Os objetivos frequentemente entram em conflito, exigindo compromissos:

**Segurança vs. Desempenho**:

- Verificações de segurança introduzem overhead
- Criptografia consome recursos computacionais
- Isolamento rigoroso pode limitar compartilhamento eficiente

**Simplicidade vs. Funcionalidade**:

- Mais recursos aumentam complexidade
- Interfaces simples podem limitar funcionalidade avançada
- Configuração automática vs. controle manual

**Portabilidade vs. Otimização**:

- Código específico para hardware pode ser mais eficiente
- Abstrações genéricas facilitam portabilidade mas podem ter overhead
- APIs padronizadas vs. recursos únicos de plataforma

## Conclusão: Estabelecendo as Fundações

Esta exploração dos sistemas operacionais estabeleceu as bases conceituais fundamentais para compreender estes sistemas complexos que são o coração de toda a computação moderna. Traçamos a evolução histórica desde as máquinas nuas até os sistemas distribuídos contemporâneos, demonstrando como cada era tecnológica trouxe novos desafios que impulsionaram inovações arquiteturais.

As funções essenciais que exploramos - gerenciamento de processos, memória, sistema de arquivos, E/S, redes e segurança - revelam a natureza multifacetada dos sistemas operacionais. Estas funções trabalham em harmonia para criar um ambiente computacional estável e eficiente, abstraindo a complexidade do hardware subjacente.

A compreensão dual dos sistemas operacionais como gerentes de recursos e máquinas estendidas oferece perspectivas complementares que iluminam diferentes aspectos de seu design e funcionamento. Esta dualidade explica por que diferentes sistemas fazem escolhas arquiteturais distintas baseadas em seus ambientes de uso e prioridades.

Os princípios orientadores - conveniência, eficiência, evolução e confiabilidade - demonstram que o design de sistemas operacionais envolve constantes trade-offs. Não existe um "melhor" sistema operacional universal; cada design reflete escolhas específicas sobre como equilibrar objetivos conflitantes.

Os conceitos aqui estabelecidos formam a base sobre a qual tecnologias computacionais mais avançadas são construídas. Seja em computação móvel, sistemas distribuídos, computação em nuvem ou Internet das Coisas, os princípios fundamentais de gerenciamento de recursos, abstração, concorrência e segurança permanecem centrais.

Esta compreensão fundamental prepara o terreno para exploração de tópicos mais avançados como arquiteturas de microkernel, sistemas de tempo real, virtualização e containers - todos construídos sobre os fundamentos aqui estabelecidos.

## Arquiteturas de Sistemas Operacionais: Estruturando a Complexidade

A organização interna de um sistema operacional determina fundamentalmente sua eficiência, confiabilidade e capacidade de manutenção. Diferentes abordagens arquiteturais refletem diferentes filosofias sobre como gerenciar a complexidade inerente aos sistemas operacionais modernos.

![Diagrama comparativo mostrando três colunas: arquitetura monolítica, microkernel e híbrida, ilustrando a localização dos componentes (kernel space vs user space) e fluxos de comunicação](/images/arquiteturas_so_comparacao.webp)
_Figura 4: Comparação entre diferentes arquiteturas de sistemas operacionais_{: class="legend"}

### Arquitetura Monolítica: Poder e Simplicidade

Na **arquitetura monolítica**, todo o sistema operacional executa em um único espaço de endereçamento no modo kernel, com todos os serviços do  **Sistema Operacional**  executando no mesmo nível de privilégio.

**Características Principais**:

- **Espaço de endereçamento único**: todos os componentes compartilham o mesmo espaço de memória
- **Acesso direto**: componentes podem chamar funções uns dos outros diretamente
- **Modo kernel**: todo código do  **Sistema Operacional**  executa com privilégios máximos
- **Performance alta**: overhead mínimo de comunicação entre componentes

**Vantagens**:

- **Eficiência**: comunicação rápida entre componentes
- **Simplicidade de implementação**: sem necessidade de mecanismos complexos de IPC
- **Compartilhamento fácil**: estruturas de dados compartilhadas facilmente

**Desvantagens**:

- **Instabilidade**: falha em um componente pode derrubar todo o sistema
- **Segurança limitada**: todo código tem acesso total ao hardware
- **Dificuldade de manutenção**: modificações podem afetar o sistema inteiro
- **Escalabilidade limitada**: difícil de adaptar para diferentes arquiteturas

**Exemplos Clássicos**:

- **UNIX tradicional**: implementação original com kernel monolítico
- **Linux**: kernel monolítico moderno com módulos carregáveis
- **MS-DOS**: sistema simples com arquitetura monolítica básica

### Arquitetura de Microkernel: Minimalismo e Modularidade

A **arquitetura de microkernel** move a maioria dos serviços do sistema operacional para o espaço do usuário, deixando apenas as funções mais básicas no kernel.

**Princípios Fundamentais**:

- **Kernel mínimo**: apenas funções essenciais como comunicação entre processos, escalonamento básico e gerenciamento de memória de baixo nível
- **Serviços em user space**: drivers de dispositivo, sistema de arquivos, protocolos de rede executam como processos de usuário
- **Comunicação via IPC**: serviços comunicam através de message passing

**Componentes Típicos do Microkernel**:

```shell
User Space:
┌─────────────┬─────────────┬─────────────┐
│File System │Device Drivers│Network Stack│
│   Server    │   Servers   │   Server    │
└─────────────┴─────────────┴─────────────┘
              ↕ IPC ↕
┌───────────────────────────────────────────┐
│         Microkernel                       │
│  • Process Management                     │
│  • Memory Management                      │
│  • Inter-Process Communication           │
│  • Basic Scheduling                       │
└───────────────────────────────────────────┘
              Hardware
```

**Vantagens**:

- **Confiabilidade**: falha em um servidor não afeta outros componentes
- **Segurança**: isolamento entre componentes
- **Flexibilidade**: fácil de adicionar/remover serviços
- **Portabilidade**: kernel menor é mais fácil de portar
- **Manutenibilidade**: componentes podem ser atualizados independentemente

**Desvantagens**:

- **Performance**: overhead de IPC pode ser significativo
- **Complexidade**: design e debugging mais complexos
- **Overhead de desenvolvimento**: mais componentes para gerenciar

**Exemplos Notáveis**:

- **MINIX**: sistema educacional que influenciou o desenvolvimento do Linux
- **QNX**: sistema de tempo real comercial
- **L4**: família de microkernels focados em performance

### Arquitetura em Camadas: Hierarquia e Organização

A **abordagem em camadas** organiza o sistema operacional como uma hierarquia de camadas na qual, cada camada utiliza apenas os serviços da camada imediatamente inferior.

**Estrutura Hierárquica**:

```shell
Camada N: Aplicações de Usuário
Camada N-1: Interface do Usuário
Camada N-2: Comunicação E/S
Camada N-3: Operador-Processo de Comunicação
Camada N-4: Memória Virtual
Camada N-5: Escalonador da CPU
Camada 0: Hardware
```

**Características**:

- **Hierarquia rígida**: cada camada só acessa a camada imediatamente inferior
- **Abstração progressiva**: cada camada adiciona um nível de abstração
- **Modularidade**: facilita o entendimento e manutenção
- **Debugging facilitado**: problemas podem ser isolados por camada

**Exemplo Clássico: THE Operating System**
Desenvolvido por Dijkstra, demonstrou os benefícios da estruturação em camadas para sistemas operacionais.

### Arquiteturas Híbridas: Combinando Abordagens

Sistemas modernos frequentemente combinam elementos de diferentes arquiteturas para otimizar performance e manutenibilidade.

**Windows NT/Modern Windows**:

- **Kernel híbrido**: combina elementos monolíticos e microkernel
- **HAL (Hardware Abstraction Layer)**: isola código específico de hardware
- **Subsistemas protegidos**: serviços críticos em modo kernel, outros em user mode

**macOS/Darwin**:

- **Kernel XNU**: combina microkernel Mach com elementos BSD monolíticos
- **IOKit**: framework orientado a objetos para drivers
- **Serviços em user space**: muitos serviços executam fora do kernel

## Conceitos Avançados: Expandindo os Horizontes

### Virtualização: Abstraindo o Hardware Físico

A **virtualização** permite que múltiplos sistemas operacionais executem simultaneamente em uma única máquina física, cada um acreditando ter controle exclusivo do hardware.

**Tipos de Virtualização**:

1. **Virtualização Completa (Full Virtualization)**

   - O hypervisor simula completamente o hardware
   - **Sistemas Operacionais**  guest não precisam ser modificados
   - Exemplos: VMware vSphere, Hyper-V

2. **Paravirtualização**

   - **Sistema Operacional**  guest é modificado para colaborar com o hypervisor
   - Melhor performance que virtualização completa
   - Exemplo: Xen paravirtualization

3. **Virtualização de Containers**

   - Compartilha kernel do host entre containers
   - Isolamento a nível de processo/namespace
   - Exemplos: Docker, LXC, containerd

**Benefícios da Virtualização**:

- **Consolidação de servidores**: múltiplos  **Sistemas Operacionais**  em uma máquina
- **Isolamento**: falhas em uma VM não afetam outras
- **Flexibilidade**: migração de VMs entre hosts
- **Desenvolvimento**: ambientes de teste isolados

### Sistemas Distribuídos: Coordenando Múltiplas Máquinas

**Sistemas operacionais distribuídos** gerenciam recursos espalhados por múltiplas máquinas, apresentando uma visão unificada do sistema para os usuários.

**Desafios Fundamentais**:

- **Transparência**: esconder a distribuição dos usuários
- **Escalabilidade**: funcionar com milhares de nós
- **Tolerância a falhas**: continuar operando mesmo com falhas de componentes
- **Consistência**: manter dados sincronizados entre nós

**Modelos de Consistência**:

$\text{Strong Consistency}: \forall \text{ reads return the most recent write}$

$\text{Eventual Consistency}: \text{system will become consistent over time}$

**Algoritmos de Consenso**:

- **Paxos**: algoritmo teórico para consenso em sistemas distribuídos
- **Raft**: alternativa mais compreensível ao Paxos
- **PBFT**: Byzantine Fault Tolerance para ambientes adversariais

### Sistemas de Tempo Real: Garantindo Deadlines

**Sistemas de tempo real** devem responder a eventos dentro de limites de tempo rígidos. Atrasos podem resultar em falhas críticas.

**Classificações**:

- **Hard Real-Time**: deadlines absolutas, falhas são inaceitáveis
- **Soft Real-Time**: deadlines preferenciais, atrasos ocasionais toleráveis
- **Firm Real-Time**: resultados tardios são inúteis mas não catastróficos

**Características do Escalonamento em Tempo Real**:

- **Escalonamento preemptivo**: tarefas podem ser interrompidas
- **Prioridades fixas ou dinâmicas**: baseadas em deadlines ou importância
- **Análise de escalonabilidade**: garantir que todas as tarefas cumprirão deadlines

**Algoritmo Rate Monotonic (RM)**:
Para tarefas periódicas com deadlines iguais aos períodos:

$U = \sum_{i=1}^{n} \frac{C_i}{T_i} \leq n(2^{1/n} - 1)$

na qual, $C_i$ é o tempo de execução e $T_i$ é o período da tarefa $i$.

**Algoritmo Earliest Deadline First (EDF)**:
Para sistemas com utilização:

$U = \sum_{i=1}^{n} \frac{C_i}{T_i} \leq 1$

o conjunto de tarefas é escalonável.

### Segurança e Proteção: Guardando os Recursos

A **segurança** em sistemas operacionais envolve múltiplas camadas de proteção contra ameaças internas e externas.

**Modelos de Controle de Acesso**:

1. **Discretionary Access Control (DAC)**
   - Proprietários controlam acesso aos seus recursos
   - Implementado através de listas de controle de acesso (ACLs)
   - Usado em sistemas **UNIX**/Linux tradicionais

2. **Mandatory Access Control (MAC)**
   - Política de segurança definida centralmente
   - Usuários não podem modificar permissões
   - Implementado em sistemas como SELinux

3. **Role-Based Access Control (RBAC)**
   - Permissões atribuídas a papéis, não indivíduos
   - Facilita administração em organizações grandes
   - Princípio do menor privilégio

**Mecanismos de Proteção**:

- **Rings de proteção**: níveis de privilégio (Ring 0 = kernel, Ring 3 = user)
- **Segmentação com proteção**: bits de proteção em descritores de segmento
- **Paginação com proteção**: bits de read/write/execute em page tables
- **Capabilities**: tokens que concedem direitos específicos

**Técnicas Criptográficas**:

- **Hashing de senhas**: armazenamento seguro de credenciais
- **Assinaturas digitais**: verificação de integridade de código
- **Criptografia de disco**: proteção de dados em repouso

O estudo dos sistemas operacionais é, em essência, o estudo da gestão da complexidade em sistemas computacionais. Os princípios aprendidos transcendem o design de  **Sistemas Operacionais** , sendo aplicáveis a uma vasta gama de desafios em engenharia de software e arquitetura de sistemas complexos.

## Referências Bibliográficas

ACM. **The development of the C programming language**. Disponível em: https://dl.acm.org/doi/10.1145/234286.1057834. Acesso em: 7 jun. 2025.

AMD. **Computação quântica**. Disponível em: https://www.amd.com/pt/solutions/quantum-computing.html. Acesso em: 15 out. 2024.

AMNIC. **Cloud Computing Elasticity: A Game Changer for Modern Businesses**. Amnic, [s.d.]. Disponível em: https://amnic.com/blogs/cloud-computing-elasticity. Acesso em: 15 out. 2024.

ANDRADE, W. L.; SANTOS, G. L.; MACEDO, R. J. A. de. **ANÁLISE E AVALIAÇÃO FUNCIONAL DE SISTEMAS OPERACIONAIS MÓVEIS: VANTAGENS E DESVANTAGENS**. Revista de Sistemas de Informação da UNIFACS – RSI, Salvador, n. 3, p. 3-13, jan./jun. 2013. Disponível em: https://revistas.unifacs.br/index.php/rsc/article/download/2581/1950. Acesso em: 15 out. 2024.

APPLEINSIDER. **Apple turns to AI for battery management in iOS 19**. AppleInsider, 12 may 2025. Disponível em: https://appleinsider.com/articles/25/05/12/apple-turns-to-ai-for-battery-management-in-ios-19. Acesso em: 15 out. 2024.

ARUTE, F. *et al*. **Quantum supremacy using a programmable superconducting processor**. Nature, v. 574, n. 7779, p. 505-510, Oct. 2019.

AZURE. **Introdução à computação quântica híbrida - Azure Quantum**. Microsoft Learn, 07 ago. 2024. Disponível em: https://learn.microsoft.com/pt-br/azure/quantum/hybrid-computing-overview. Acesso em: 15 out. 2024.

BELL, J. **Operating Systems: Introduction**. Computer Science, University of Illinois at Chicago. Disponível em: https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/1_Introduction.html. Acesso em: 6 jun. 2025.

BERTRAND, E. D. **Introduction to Operating Systems**. School of Electrical and Computer Engineering, Purdue University. Disponível em: https://engineering.purdue.edu/~ebertd/469/notes/EE469-ch1.pdf. Acesso em: 6 jun. 2025.

BRITANNICA. **Dennis M. Ritchie | Biography & Facts**. Disponível em: https://www.britannica.com/biography/Dennis-M-Ritchie. Acesso em: 7 jun. 2025.

CARVALHO, C. A. G. F. **Características de Sistemas Distribuídos**. Universidade Federal de Pernambuco, Centro de Informática. Disponível em: https://www.cin.ufpe.br/~cagf/sdgrad/aulas/Caracteristicas.pdf. Acesso em: 15 out. 2024.

CLOUDFLARE. **O que é multilocação? | Arquitetura multi-inquilinos**. Cloudflare. Disponível em: https://www.cloudflare.com/pt-br/learning/cloud/what-is-multitenancy/. Acesso em: 15 out. 2024.

CLOUDZERO. **What Is Cloud Elasticity? (+How Does It Affect Cloud Spend?)**. CloudZero. Disponível em: https://www.cloudzero.com/blog/cloud-elasticity/. Acesso em: 15 out. 2024.

COMPUTER HISTORY MUSEUM. **Dennis Ritchie - CHM**. Disponível em: https://computerhistory.org/profile/dennis-ritchie/. Acesso em: 7 jun. 2025.

CORE. **Operating systems for computer networks**. Academic Repository. Disponível em: https://core.ac.uk/download/pdf/228680543.pdf. Acesso em: 6 jun. 2025.

DEITEL, H. M.; DEITEL, P. J.; CHOFFNES, D. R. **Operating Systems**. 3. ed. Boston: Pearson, 2004.

**DENNIS Ritchie and Ken Thompson on the history of UNIX**. Disponível em: <https://my3.my.umbc.edu/groups/csee/media/1799>. Acesso em: 7 jun. 2025.

**EARLY UNIX history and evolution**. Nokia Bell Labs. Disponível em: <https://www.nokia.com/bell-labs/about/dennis-m-ritchie/hist.html>. Acesso em: 7 jun. 2025.

FERRIOLS, F. **iPhone 17 AI Battery Improvements in iOS 19: More Than Just a Nice-to-Have**. Thinborne, 23 May 2025. Disponível em: https://thinborne.com/blogs/news/iphone-17-ai-battery-improvements-in-ios-19-more-than-just-a-nice-to-have. Acesso em: 15 out. 2024.

FOSSCOMICS. **The Origins of UNIX and the C Language**. Disponível em: https://fosscomics.com/8.%20The%20Origins%20of%20Unix%20and%20the%20C%20Language/. Acesso em: 7 jun. 2025.

GIORTAMIS, E. et al. **QOS: A Quantum Operating System**. arXiv:2406.19120v2, 28 Jun. 2024. Disponível em: https://arxiv.org/html/2406.19120v2. Acesso em: 15 out. 2024.

HONEYWELL. **How Quantum Will Transform the Future of 5 Industries**. Honeywell, Jul. 2020. Disponível em: https://www.honeywell.com/br/pt/news/2020/07/how-quantum-will-transform-the-future-of-5-industries. Acesso em: 15 out. 2024.

IT BRIEFCASE. **New Trends Increase the Effectiveness of Distributed Computing**. IT Briefcase, 17 Dec. 2024. Disponível em: https://itbriefcase.net/new-trends-increase-the-effectiveness-of-distributed-computing/. Acesso em: 15 out. 2024.

JONES, P. J. **Operating Systems**. Department of Computer Science, University of Manchester. Disponível em: https://www.cs.man.ac.uk/~pjj/cs1011/filestore/node2.html. Acesso em: 6 jun. 2025.

KERNIGHAN, Brian. **Computer Hope**. Disponível em: <https://www.computerhope.com/people/brian_kernighan.htm>. Acesso em: 7 jun. 2025.

KLABUNDE, R. et al. **Hybrid Quantum-Classical Computing Systems: Architectures, Interfaces, and Applications**. arXiv:2503.18868v1, 27 Mar. 2025. Disponível em: https://arxiv.org/html/2503.18868v1. Acesso em: 15 out. 2024.

KNOTT, W. J. **UNIX and Operating Systems Fundamentals**. Department of Computing, Imperial College London. Disponível em: http://www.doc.ic.ac.uk/~wjk/UNIX/Lecture1.html. Acesso em: 6 jun. 2025.

**LESSONS Learned from 30 Years of MINIX**. Communications of the ACM. Disponível em: <https://cacm.acm.org/research/lessons-learned-from-30-years-of-minix/>. Acesso em: 7 jun. 2025.

LIBERTY UNIVERSITY. **Operating Systems – CSIS 443**. Liberty University Online. Disponível em: https://www.liberty.edu/online/courses/csis443/. Acesso em: 6 jun. 2025.

LIVINGINTERNET. **History of C Programming Language**. Disponível em: https://www.livinginternet.com/i/iw_unix_c.htm. Acesso em: 7 jun. 2025.

MELL, P.; GRANCE, T. **The NIST Definition of Cloud Computing**. National Institute of Standards and Technology, Special Publication 800-145, Sep. 2011. Disponível em: https://peasoup.cloud/nist-definition-of-cloud-computing/ e https://cic.gsa.gov/basics/cloud-basics. Acesso em: 15 out. 2024.

MICROSOFT AZURE. **O que é computação elástica?**. Dicionário de Computação em Nuvem do Azure. Disponível em: https://azure.microsoft.com/pt-br/resources/cloud-computing-dictionary/what-is-elastic-computing. Acesso em: 15 out. 2024.

MIT OPENCOURSEWARE. **6.828 Operating System Engineering**. Electrical Engineering and Computer Science Department. Disponível em: https://ocw.mit.edu/courses/6-828-operating-system-engineering-fall-2012/. Acesso em: 6 jun. 2025.

MOBILE OPERATING SYSTEM. **The Flying Theatre Company**. Disponível em: https://theflyingtheatre.com/UserFiles/images/files/punel.pdf. Acesso em: 15 out. 2024.

NORTHWESTERN UNIVERSITY. **COMP_SCI 343: Operating Systems**. Computer Science Department, McCormick School of Engineering. Disponível em: https://www.mccormick.northwestern.edu/computer-science/academics/courses/descriptions/343.html. Acesso em: 6 jun. 2025.

NUTT, G. **Operating Systems: A Modern Perspective**. 3. ed. Boston: Addison-Wesley, 2004.

ORACLE. **O que é computação em nuvem?**. Oracle Brasil. Disponível em: https://www.oracle.com/br/cloud/what-is-cloud-computing/. Acesso em: 15 out. 2024.

ORGANICK, E. I. **The Multics System: An Examination of its Structure**. Cambridge: MIT Press, 1972.

**POWER MANAGEMENT TECHNIQUES IN SMARTPHONES OPERATING SYSTEMS**. IJCSI International Journal of Computer Science Issues, v. 9, i. 3, n. 3, May 2012. Disponível em: https://www.researchgate.net/publication/268409514_Power_Management_Techniques_in_Smartphones_Operating_Systems. Acesso em: 15 out. 2024.

**QUANTUM COMPUTING: AN EMERGING ECOSYSTEM AND INDUSTRY USE CASES**. McKinsey & Company, Dec. 2021. Disponível em: https://www.westconference.org/WEST25/Custom/Handout/Speaker0_Session11706_1.pdf. Acesso em: 15 out. 2024.

REPOSITÓRIO UNIFESSPA. **Os desafios da computação em nuvem**. Universidade Federal do Sul e Sudeste do Pará. Disponível em: https://repositorio.unifesspa.edu.br/bitstream/123456789/228/1/TCC_%20Os%20desafios%20da%20computa%C3%A7%C3%A3o%20em%20nuvem.pdf. Acesso em: 15 out. 2024.

RITCHIE, D. M.; THOMPSON, K. **The UNIX Time-Sharing System**. Communications of the ACM, v. 17, n. 7, p. 365-375, 1974.

SALTZER, J. H.; SCHROEDER, M. D. **The protection of information in computer systems**. Proceedings of the IEEE, v. 63, n. 9, p. 1278-1308, 1975.

SHARMA, A. **One UI 7 could bring even smarter power-saving options to Galaxy phones**. Android Authority, 15 May 2025. Disponível em: https://www.androidauthority.com/one-ui-7-power-saving-options-3558362/. Acesso em: 15 out. 2024.

SIEGFRIED, S. **CSC 553 Operating Systems - Lecture 2**. Computer Science Department, Adelphi University. Disponível em: https://home.adelphi.edu/~siegfried/cs553/553l2.pdf. Acesso em: 6 jun. 2025.

SILBERSCHATZ, A.; GALVIN, P. B.; GAGNE, G. **Operating System Concepts**. 10. ed. Hoboken: John Wiley & Sons, 2018.

SPINQ. **Quantum Computer Operating System: The Key to Quantum Power**. SpinQ Technology, 16 Jan. 2025. Disponível em: https://www.spinquanta.com/news-detail/quantum-computer-operating-system-the-key-to-quantum-power20250116104617. Acesso em: 15 out. 2024.

STALLINGS, W. **Operating Systems: Internals and Design Principles**. 9. ed. Boston: Pearson, 2018.

SWEISS, W. **Chapter 1: Introduction to Operating Systems**. Computer Science Department, Hunter College, CUNY. Disponível em: https://www.cs.hunter.cuny.edu/~sweiss/course_materials/csci340/slides/chapter01.pdf. Acesso em: 6 jun. 2025.

TANENBAUM, A. S.; BOS, H. **Modern Operating Systems**. 4. ed. Boston: Pearson, 2015.

THE MOONLIGHT. **QOS: A Quantum Operating System**. The Moonlight Review. Disponível em: https://www.themoonlight.io/en/review/qos-a-quantum-operating-system. Acesso em: 15 out. 2024.

TOPTAL. **Why the C Programming Language Still Runs the World**. Disponível em: https://www.toptal.com/c/after-all-these-years-the-world-is-still-powered-by-c-programming. Acesso em: 7 jun. 2025.

UNIVERSITY OF COLORADO. **CSCI 3753 Operating Systems Syllabus**. Computer Science Department. Disponível em: https://home.cs. Acesso em: 6 jun. 2025.

**UNIX and Multics**. Disponível em: <https://multicians.org/UNIX.html>. Acesso em: 7 jun. 2025.

**UNIX | Definition, Meaning, History, & Facts**. Britannica. Disponível em: <https://www.britannica.com/technology/UNIX>. Acesso em: 7 jun. 2025.

**UNIX - Wikipedia**. Wikipedia. Disponível em: <https://en.wikipedia.org/wiki/UNIX>. Acesso em: 7 jun. 2025.

VON KYPKE, L.; WACK, A. **How an Operating System for Quantum Computers Should Be Architected**. arXiv:2410.13482v1, 21 Oct. 2024. Disponível em: https://arxiv.org/html/2410.13482v1. Acesso em: 15 out. 2024.

ZDNET. **I changed 12 settings on my Android phone to give it an instant battery boost**. ZDNet. Disponível em: https://www.zdnet.com/article/i-changed-12-settings-on-my-android-phone-to-give-it-an-instant-battery-boost/. Acesso em: 15 out. 2024.

## Glossário - Sistemas Operacionais: Fundamentos e Evolução

### A

**Abstração**
Processo de esconder detalhes complexos de implementação, fornecendo uma interface mais simples e amigável para os usuários e programadores.

**Alocação de Memória**
Processo de atribuir blocos de memória principal aos processos que necessitam de espaço para execução.

**API (Application Programming Interface)**
Conjunto de rotinas, protocolos e ferramentas que especificam como componentes de software devem interagir.

### B

**Batch Processing (Processamento em Lote)**
Neste método de processamento os programas são executados sequencialmente sem interação direta do usuário, maximizando a utilização da CPU.

**Buffering**
Técnica que utiliza áreas de memória temporária para compensar diferenças de velocidade entre dispositivos, melhorando o desempenho do sistema.

### C

**Cache**
Memória de alta velocidade que armazena dados frequentemente acessados para reduzir o tempo de acesso médio.

**Chamadas de Sistema (System Calls)**
Interface programática através da qual processos solicitam serviços do sistema operacional.

**Concorrência**
Capacidade de múltiplos processos ou threads executarem simultaneamente, compartilhando recursos do sistema.

**Context Switch (Troca de Contexto)**
Processo de salvar o estado de um processo em execução e carregar o estado de outro processo para execução.

**CP/M (Control Program for Microcomputers)**
Um dos primeiros sistemas operacionais dominantes para microcomputadores de 8 bits.

**CPU Scheduling**
Processo de determinar qual processo deve utilizar a CPU em um determinado momento.

**CTSS (Compatible Time-Sharing System)**
Sistema pioneiro de tempo compartilhado desenvolvido no MIT que estabeleceu conceitos fundamentais de sistemas interativos.

### D

**Deadlock**
Nessa situação dois ou mais processos ficam permanentemente bloqueados, cada um esperando que o outro libere um recurso.

**Device Driver**
Software específico que permite ao sistema operacional comunicar-se com dispositivos de hardware particulares.

**DMA (Direct Memory Access)**
Técnica que permite a dispositivos de E/S acessar a memória principal diretamente, sem intervenção da CPU.

### E

**Escalonamento (Scheduling)**
Processo de decidir qual processo, thread ou tarefa deve ser executado em um determinado momento.

**Espaço de Endereçamento**
Conjunto de endereços de memória que um processo pode utilizar para armazenar dados e código.

### F

**FCFS (First-Come, First-Served)**
Algoritmo de escalonamento no qual os processos são executados na ordem de chegada.

**File System (Sistema de Arquivos)**
Método de organizar e armazenar arquivos em dispositivos de armazenamento secundário.

**FMS (Fortran Monitor System)**
Um dos primeiros sistemas de monitoramento para programas FORTRAN.

### G

**GUI (Graphical User Interface)**
Interface que utiliza elementos gráficos como janelas, ícones e menus para interação com o usuário.

### H

**Hardware Abstraction Layer (HAL)**
Camada de software que esconde diferenças específicas de hardware, proporcionando uma interface uniforme.

### I

**IBSYS**
Sistema batch para o IBM 7094 que estabeleceu muitos conceitos fundamentais de sistemas operacionais.

**Interrupção**
Sinal que informa à CPU sobre a ocorrência de um evento que requer atenção imediata.

**IPC (Inter-Process Communication)**
Mecanismos que permitem a processos trocar dados e sincronizar suas atividades.

### J

**JCL (Job Control Language)**
Linguagem específica utilizada para instruir sistemas batch sobre como processar trabalhos.

### K

**Kernel**
Parte central do sistema operacional que gerencia recursos do sistema e fornece serviços fundamentais.

### L

**Linux**
Sistema operacional de código aberto baseado em **UNIX**, desenvolvido por Linus Torvalds.

**LSI (Large Scale Integration)**
Tecnologia de circuitos integrados que permitiu a criação de microprocessadores e computadores pessoais.

### M

**Máquina Virtual**
Abstração de software que simula um computador completo, permitindo execução de múltiplos sistemas operacionais.

**Memory Management**
Função do sistema operacional responsável por controlar e coordenar o uso da memória principal.

**MS-DOS (Microsoft Disk Operating System)**
Sistema operacional que dominou computadores pessoais na década de 1980.

**MULTICS (Multiplexed Information and Computing Service)**
Sistema avançado que introduziu conceitos como memória virtual e sistema de arquivos hierárquico.

**Multiprogramação**
Técnica que permite múltiplos programas residirem na memória simultaneamente, melhorando a utilização da CPU.

**Multitasking**
Capacidade de um sistema executar múltiplas tarefas aparentemente em paralelo através de compartilhamento de tempo.

### N

**NFS (Network File System)**
Sistema que permite acesso a arquivos através de uma rede como se fossem locais.

### O

**OS/360**
Sistema operacional da IBM que estabeleceu muitos conceitos fundamentais de multiprogramação.

### P

**Paginação**
Técnica de gerenciamento de memória que divide a memória em páginas de tamanho fixo.

**PCB (Process Control Block)**
Estrutura de dados que contém informações sobre um processo específico.

**Preemptive Scheduling**
Tipo de escalonamento no qual o sistema operacional pode interromper um processo em execução para dar lugar a outro.

**Processo**
Programa em execução, incluindo código, dados, pilha e contexto de execução.

### Q

**Quantum**
Fatia de tempo atribuída a um processo em algoritmos de escalonamento round-robin.

### R

**Round Robin**
Algoritmo de escalonamento no qual cada processo recebe uma fatia de tempo fixa antes de ser preemptado.

### S

**Segmentação**
Técnica de gerenciamento de memória que divide o espaço de endereçamento em segmentos lógicos.

**SJF (Shortest Job First)**
Algoritmo de escalonamento que prioriza processos com menor tempo de execução estimado.

**Spooling (Simultaneous Peripheral Operation On-Line)**
Técnica que utiliza disco como buffer para operações de E/S.

**Swapping**
Técnica de mover processos inteiros entre memória principal e armazenamento secundário.

**System Call**
Interface através da qual programas de usuário solicitam serviços do kernel.

### T

**Thread**
Unidade básica de utilização da CPU dentro de um processo, permitindo execução concorrente.

**Throughput**
Medida da quantidade de trabalho realizado por unidade de tempo.

**Time-Sharing (Tempo Compartilhado)**
Sistema no qual múltiplos usuários compartilham recursos computacionais simultaneamente.

**Time Slice**
Período de tempo durante o qual um processo pode utilizar a CPU antes de ser preemptado.

### U

****UNIX****
Sistema operacional multiusuário e multitarefa desenvolvido nos Bell Labs, altamente influente.

### V

**Virtual Memory (Memória Virtual)**
Técnica que permite a execução de programas maiores que a memória física disponível.

**VLSI (Very Large Scale Integration)**
Tecnologia avançada de circuitos integrados que permitiu maior densidade de componentes.
R