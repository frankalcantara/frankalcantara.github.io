---
author: Frank
beforetoc: '[Anterior](2024-09-20-2-Sem-T%C3%ADtulo.md)

  [Próximo](2024-09-20-4-Sem-T%C3%ADtulo.md)'
categories:
- Matemática
- Linguagens Formais
- Programação
description: Dynamic Programming in C++ with practical examples, performance analysis,
  and detailed explanations to optimize your coding skills and algorithm efficiency.
draft: null
featured: true
image: assets/images/prog_dynamic.jpeg
keywords:
- Dynamic Programming
- C++ Algorithms
- Coding Examples
- Performance Optimization
- Algorithm Efficiency
- Programming Guide
- Code Comparison
- Developer Tips
lastmod: 2024-09-20 22:35:36.353000+00:00
layout: post
preview: In this comprehensive guide, we delve into the world of Dynamic Programming
  with C++. Learn the core principles of Dynamic Programming, explore various algorithmic
  examples, and understand performance differences through detailed code comparisons.
  Perfect for developers looking to optimize their coding skills and enhance algorithm
  efficiency.
published: 2024-06-27 19:43:15.124000+00:00
rating: 5
slug: competitive-programming-techniques-insights
tags:
- Matemática
- Linguagens Formais
- Programação Dinâmica
- Dynamic Programming
- C++ Algorithms
- Performance Analysis
- Coding Examples
- Algorithm Optimization
- Practical Programming Guide
title: 4. Introduction to File I/O in C++
toc: true
---
# 4. Introduction to File I/O in C++

In C++, file input and output (I/O) operations are handled through classes provided by the `<fstream>` library. The three main classes used for this purpose are `std::ifstream`, `std::ofstream`, and `std::fstream`. Each of these classes is specialized for different types of I/O operations.

## 4.1 `std::ifstream`: File Reading

The `std::ifstream` class (input file stream) is used exclusively for reading files. It inherits from `std::istream`, the base class for all input operations in C++.

### 4.1.1 Opening Files for Reading

In our code, we use `std::ifstream` to open a text file and read its contents:

```cpp
std::ifstream file(argv[1]);
```

- `std::ifstream file(argv[1]);`: Tries to open the file whose name is passed as a command-line argument. If the file cannot be opened, the `file` stream will be invalid.

Off course we can use `std::ifstream` to read files from command line:

```cpp
#include <fstream>
#include <iostream>
#include <string>

int main(int argc, char* argv[]) {
    if (argc != 2) {
        std::cerr << "Usage: " << argv[0] << " <filename>\n";
        return 1;
    }

    // Abre o arquivo apenas para leitura
    std::ifstream file(argv[1]);

    if (!file.is_open()) {
        std::cerr << "Error: Could not open the file " << argv[1] << "\n";
        return 1;
    }

    std::string line;

    // Lê o conteúdo do arquivo linha por linha e exibe no console
    std::cout << "Contents of the file:\n";
    while (std::getline(file, line)) {
        std::cout << line << "\n";
    }

    file.close();
    return 0;
}
```

### 4.1.2 Verifying File Opening

After attempting to open the file, it’s crucial to check whether the opening was successful:

```cpp
if (!file) {
    std::cerr << "Error opening file: " << argv[1] << "\n";
    return 1;
}
```

- `if (!file)`: Checks if the `file` stream is in an invalid state (which indicates the file was not opened correctly). If the file can't be opened, an error message is displayed, and the program exits.

Again, in competitive programmings, the input file will most often be handled by an automated testing system, so you probably won't need to check whether the file opened correctly or not.

### 4.1.3 File Reading

Once the file is successfully opened, we can read its contents:

```cpp
std::getline(file, line);
while (file >> num) {
    vec.push_back(num);
}
```

- `std::getline(file, line);`: Reads a full line from the file and stores it in the string `line`.
- `file >> num`: Reads numbers from the file and stores them in `num`, which are then added to the vector `vec` using `vec.push_back(num);`.

### 4.1.4 File Closing

After finishing with a file, it should be closed to free the associated resources. This happens automatically when the `std::ifstream` object is destroyed, but it can also be done explicitly:

```cpp
file.close();
```

- `file.close();`: Closes the file manually. Although the file is automatically closed when the object goes out of scope, explicitly closing the file can be useful to ensure the data is correctly released before the program ends or before opening another file.

### 4.1.5 File Writing - `std::ofstream`

While we didn’t use `std::ofstream` in the provided code, it's important to mention it. The `std::ofstream` class (output file stream) is used for writing to files. It inherits from `std::ostream`, the base class for all output operations in C++.

1. **Opening Files for Writing**

   The syntax for opening a file for writing using `std::ofstream` is similar to that of `std::ifstream`:

   ```cpp
   std::ofstream outFile("output.txt");
   ```

   - `std::ofstream outFile("output.txt");`: Opens or creates a file called `output.txt` for writing. If the file already exists, its contents will be truncated (erased).

### 4.1.6 File Reading and Writing - `std::fstream`

The `std::fstream` class combines the functionality of both `std::ifstream` and `std::ofstream`, allowing for both reading from and writing to files. It inherits from `std::iostream`, the base class for bidirectional I/O operations.

An example of how to open a file for both reading and writing would be:

```cpp
std::fstream file("data.txt", std::ios::in | std::ios::out);
```

- `std::fstream file("data.txt", std::ios::in | std::ios::out);`: Opens `data.txt` for both reading and writing. The parameter `std::ios::in | std::ios::out` specifies that the file should be opened for both input and output.

Or to use files read from command line we could use:

```cpp
#include <fstream>
#include <iostream>
#include <string>

int main(int argc, char* argv[]) {
    if (argc != 2) {
        std::cerr << "Usage: " << argv[0] << " <filename>\n";
        return 1;
    }

    // Abre o arquivo com leitura e escrita
    std::fstream file(argv[1], std::ios::in | std::ios::out);

    if (!file.is_open()) {
        std::cerr << "Error: Could not open the file " << argv[1] << "\n";
        return 1;
    }

    std::string line;

    // Lê o conteúdo do arquivo e exibe no console
    std::cout << "Contents of the file:\n";
    while (std::getline(file, line)) {
        std::cout << line << "\n";
    }

    // Reposiciona o ponteiro para o início do arquivo
    file.clear(); // Limpa qualquer flag de erro
    file.seekg(0, std::ios::beg);

    // Adiciona uma nova linha ao final do arquivo
    file << "\nNew line added to the file.\n";

    // Reposiciona o ponteiro para o início novamente para leitura após a escrita
    file.clear();
    file.seekg(0, std::ios::beg);

    std::cout << "\nUpdated contents of the file:\n";

    // Lê e exibe o conteúdo atualizado do arquivo
    while (std::getline(file, line)) {
        std::cout << line << "\n";
    }

    file.close();
    return 0;
}
```

### 4.1.7 File Opening Modes

When opening files, we can specify different opening modes using values from the `std::ios_base::openmode` enumeration. Some of the most common modes include:

- `std::ios::in`: Open for reading (default for `std::ifstream`).
- `std::ios::out`: Open for writing (default for `std::ofstream`).
- `std::ios::app`: Open for writing at the end of the file, without truncating it.
- `std::ios::ate`: Open and move the file pointer to the end of the file.
- `std::ios::trunc`: Truncate the file (erase existing content).
- `std::ios::binary`: Open the file in binary mode.

## 4.2 Advanced File I/O Techniques in C++

There are faster ways to open and process files in C++, which can be especially useful in competitive programming when dealing with large data sets. Here are some techniques that can enhance the efficiency of file handling:

1. **Disable I/O Synchronization**

   As mentioned previously, disabling the synchronization between the C and C++ I/O libraries using `std::ios::sync_with_stdio(false)` and unlinking `std::cin` from `std::cout` with `std::cin.tie(nullptr)` can significantly speed up data reading.

2. **Use Manual Buffering**

   Manual buffering allows you to read the file in large chunks, which reduces the overhead of multiple I/O operations. Below is the code, followed by a detailed explanation of how we efficiently read the entire file into a buffer:

   ```cpp
   #include <fstream>
   #include <iostream>
   #include <vector>

   int main(int argc, char* argv[]) {
       if (argc != 2) {
           std::cerr << "Usage: " << argv[0] << " <file_name>\n";
           return 1;
       }

       std::ifstream file(argv[1], std::ios::in | std::ios::binary);
       if (!file) {
           std::cerr << "Error opening file: " << argv[1] << "\n";
           return 1;
       }

       // Move file pointer to the end to determine file size
       file.seekg(0, std::ios::end);
       size_t fileSize = file.tellg();
       file.seekg(0, std::ios::beg);

       // Create buffer and read file in one go
       std::vector<char> buffer(fileSize);
       file.read(buffer.data(), fileSize);

       // Process buffer contents
       // Example: Print the first 100 characters of the file
       for (int i = 0; i < 100 && i < fileSize; ++i) {
           std::cout << buffer[i];
       }

       return 0;
   }
   ```

   Let’s break down the most important lines used to read the file efficiently:

   ```cpp
   file.seekg(0, std::ios::end);
   ```

   This line moves the file pointer to the end of the file. The `seekg` function (seek "get" position) is used to set the position of the next read operation. Here, the first argument `0` means no offset, and the second argument `std::ios::end` moves the pointer to the end of the file. This allows us to calculate the size of the file, which is essential for creating a buffer that will hold the entire file's content.

   ```cpp
   size_t fileSize = file.tellg();
   ```

   After moving the pointer to the end of the file, we use `tellg()` (tell "get" position) to retrieve the current position of the pointer, which is now at the end. Since the file pointer is at the end, the value returned by `tellg()` represents the total size of the file in bytes. This value is stored in the variable `fileSize`, which we will use to allocate a buffer large enough to hold the file’s contents.

   ```cpp
   file.seekg(0, std::ios::beg);
   ```

   Now that we know the file's size, we move the file pointer back to the beginning of the file using `seekg(0, std::ios::beg)`. The argument `std::ios::beg` means we are setting the pointer to the start of the file, where the reading will begin. This ensures we are ready to read the file from the first byte.

   ```cpp
   std::vector<char> buffer(fileSize);
   ```

   We then create a `std::vector<char>` buffer with the size `fileSize`. This buffer will store the contents of the entire file in memory. Using a `std::vector` is convenient because it automatically manages memory and provides access to the underlying data using the `data()` method.

   ```cpp
   file.read(buffer.data(), fileSize);
   ```

   Finally, we use `file.read()` to read the entire file into the buffer. The method `buffer.data()` provides a pointer to the beginning of the buffer where the file’s contents will be stored. The second argument, `fileSize`, specifies how many bytes to read from the file. Since `fileSize` equals the total size of the file, the entire file is read into the buffer in one go.

   By using `seekg()` to calculate the file size and then reading the file all at once into a buffer, we avoid multiple I/O operations, which would otherwise slow down the process. Reading the file in one operation reduces system calls and minimizes overhead, making the process faster, especially when dealing with large files.

3. **Reading Lines More Efficiently**

   Instead of using `std::getline()`, which can be relatively slow for large files, you can implement a custom buffer to store multiple lines at once, reducing the overhead of repeatedly calling the I/O functions.

### 4.2.1 Using `mmap` for Faster File I/O in Unix-Based Systems

In competitive programming, especially in contests like ICPC where the environment is Unix-based (typically Linux), it is crucial to explore every possible optimization for handling large input files. One such technique is using the `mmap` system call, which provides an extremely fast option for reading large files by mapping them directly into memory. This allows almost instantaneous access to the file's content without multiple read operations, significantly reducing I/O overhead.

The `mmap` function maps a file or device into memory. Once the file is mapped, it behaves as if it's part of the program's memory space, allowing you to access file contents through pointer arithmetic rather than explicit file read operations. This eliminates the need for repeated system calls for reading file data, as you access the file as if it were a simple array in memory.

This approach is useful in environments like ICPC, where files can be very large, and efficiency is paramount. **However, it's important to note that `mmap` is specific to Unix-based systems and is not portable across all operating systems, such as Windows**.

#### 4.2.1.1 How to Use `mmap`

Here's an example of how you can use `mmap` to read a file efficiently in C++ on a Unix-based system:

```cpp
#include <sys/mman.h>
#include <fcntl.h>
#include <unistd.h>
#include <sys/stat.h>
#include <iostream>

int main(int argc, char* argv[]) {
    if (argc != 2) {
        std::cerr << "Usage: " << argv[0] << " <file_name>\n";
        return 1;
    }

    // Open the file
    int fd = open(argv[1], O_RDONLY);
    if (fd == -1) {
        std::cerr << "Error opening file: " << argv[1] << "\n";
        return 1;
    }

    // Get the size of the file
    struct stat sb;
    if (fstat(fd, &sb) == -1) {
        std::cerr << "Error getting file size\n";
        close(fd);
        return 1;
    }
    size_t fileSize = sb.st_size;

    // Memory-map the file
    char* fileData = (char*)mmap(nullptr, fileSize, PROT_READ, MAP_PRIVATE, fd, 0);
    if (fileData == MAP_FAILED) {
        std::cerr << "Error mapping file to memory\n";
        close(fd);
        return 1;
    }

    // Process the file data (example: print the first 100 characters)
    for (size_t i = 0; i < 100 && i < fileSize; ++i) {
        std::cout << fileData[i];
    }

    // Unmap the file and close the file descriptor
    if (munmap(fileData, fileSize) == -1) {
        std::cerr << "Error unmapping file\n";
    }
    close(fd);

    return 0;
}
```

**Explanation of Key Steps**:

1. **Opening the File**:

   ```cpp
   int fd = open(argv[1], O_RDONLY);
   ```

   The `open()` function opens the file specified in the command-line arguments in read-only mode. The file descriptor `fd` is returned, which is later used to map the file into memory.

2. **Getting the File Size**:

   ```cpp
   struct stat sb;
   fstat(fd, &sb);
   ```

   The `fstat()` function retrieves the size of the file and stores it in the `stat` structure. The file size is crucial for knowing how much memory to map.

3. **Mapping the File into Memory**:

   ```cpp
   char* fileData = (char*)mmap(nullptr, fileSize, PROT_READ, MAP_PRIVATE, fd, 0);
   ```

   The `mmap()` function maps the entire file into memory. The `PROT_READ` flag allows read-only access, and `MAP_PRIVATE` ensures that any modifications to the memory are private to this process (although we won't modify the file in this example). Once the file is mapped, `fileData` points to the beginning of the file's contents in memory.

4. **Processing the Data**:
   After mapping the file, you can access the file's content using `fileData` as if it were an array. For example, the above code prints the first 100 characters from the file.

5. **Unmapping and Closing**:

   ```cpp
   munmap(fileData, fileSize);
   close(fd);
   ```

   After processing the file, it is important to unmap the memory with `munmap()` and close the file descriptor with `close()`. This ensures that system resources are properly freed.

`mmap` provides several advantages when it comes to handling large file I/O. First, it offers **speed** by allowing direct access to file contents in memory, eliminating the need for repeated system calls, which significantly reduces overhead. Additionally, **simplicity** is a key benefit, as the file can be accessed like a normal array after mapping, streamlining file processing logic. Finally, **memory efficiency** is improved, as `mmap` only loads the required parts of the file into memory, avoiding the need to load the entire file into a buffer, which is especially useful for large files.

**portability**: it's important to note that the `mmap` function is specific to POSIX-compliant operating systems such as Linux, macOS, and other Unix-like systems. This function is not natively available on Windows platforms, which may limit the portability of code that uses it. For cross-platform development or in environments that include Windows systems, it's advisable to provide an alternative implementation or use libraries that offer similar functionality in a portable manner. In programming competitive programmings that occur in controlled environments, such as ICPC, where the operating system is usually specified (often Linux), the use of `mmap` may be appropriate. However, for code that needs to run on multiple platforms, consider using more universal I/O methods, such as `std::ifstream` or `fread`, which are supported on a wider range of operating systems.

### 4.2.2 Parallel Input/Output with Threads (C++20)

C++20 introduced several improvements for parallel programming, including the efficient use of threads and asynchronous tasks with `std::async`. In many competitive programming scenarios, input and output (I/O) operations are performed sequentially. **However, despite it being quite rare for input files to be very large in competitive programmings, in cases of intensive I/O or when there is a need to process large volumes of data simultaneously, parallel I/O can be an advantageous strategy**.

In situations with heavy I/O workloads, such as reading and processing large input files or performing intensive calculations while still reading or writing data, `std::async` and threads can be used to split operations and execute different tasks simultaneously, making the best use of available time.

**Example of Parallel I/O Using `std::async`**

Below is a simple example of how to use `std::async` to perform input and output operations in parallel. In this example, while data is being read, another thread can be used to process or display the data simultaneously, optimizing the time spent on I/O operations:

```cpp
#include <iostream>
#include <future>
#include <vector>

// Function to read input from the user
void read_input(std::vector<int>& vec, int n) {
for (int i = 0; i < n; ++i) {
std::cin >> vec[i];
}
}

// Function to process and print the output
void process_output(const std::vector<int>& vec) {
for (int i : vec) {
std::cout << i << " ";
}
std::cout << std::endl;
}

int main() {
int n;
std::cin >> n;

    // Create a vector of size 'n'
    std::vector<int> numbers(n);

    // Use std::async to read the input asynchronously
    auto readTask = std::async(std::launch::async, read_input, std::ref(numbers), n);

    // Wait for the input reading to complete before proceeding
    readTask.wait();

    // Process and print the vector after reading
    process_output(numbers);

    return 0;
}
```

In this example, the `std::async` function is used to run the `read_input` function asynchronously on a separate thread. This means that the data can be read in the background while other operations are prepared or started.

`std::async` executes the `read_input` function in a new thread, passing the `numbers` vector and the number of inputs `n` as parameters. The `std::launch::async` option ensures that the function is run in parallel, and not lazily (i.e., when the result is needed). The call to `readTask.wait()` ensures that the asynchronous read operation is completed before the program continues. This synchronizes the operation, ensuring that the input is fully read before trying to process the data.

Although this example uses the main thread to process the output after reading, in more complex scenarios, both processing and reading could be parallelized, or even multiple reads could occur simultaneously, depending on the needs:

```cpp
#include <iostream>
#include <future>
#include <vector>

// Function to read input from the user
void read_input(std::vector<int>& vec, int n) {
    for (int i = 0; i < n; ++i) {
        std::cin >> vec[i];
    }
}

// Function to process and sum the input
void process_output(const std::vector<int>& vec) {
    int sum = 0;
    for (int i : vec) {
        sum += i;
    }
    std::cout << "Sum of elements: " << sum << std::endl;
}

int main() {
    int n;
    std::cin >> n;

    // Vectors to store the input data
    std::vector<int> numbers1(n);
    std::vector<int> numbers2(n);

    // Asynchronous read of the first data set
    auto readTask1 = std::async(std::launch::async, read_input, std::ref(numbers1), n);

    // Asynchronous read of the second data set in parallel
    auto readTask2 = std::async(std::launch::async, read_input, std::ref(numbers2), n);

    // Asynchronous processing of the first data set in parallel
    auto processTask = std::async(std::launch::async, [&]() {
        readTask1.wait(); // Wait for the first read to complete before processing
        process_output(numbers1); // Process the first data set
    });

    // Wait for both reads to finish
    readTask1.wait();
    readTask2.wait();

    // Output the second set of numbers
    std::cout << "Second set of numbers: ";
    for (int i : numbers2) {
        std::cout << i << " ";
    }
    std::cout << std::endl;

    // Wait for the asynchronous processing to finish
    processTask.wait();

    return 0;
}
```

Using threads for parallel I/O can improve performance in scenarios where there is a large volume of data to be read or written, especially if the reading time can be masked while another thread is processing data or preparing the next phase of the program.

However, this technique should be used with care. Adding threads and asynchronous operations increases code complexity, requiring careful synchronization to avoid race conditions or data inconsistencies. That's why we should avoid this technique in competitive programming. While parallelism can improve execution time, creating and managing threads also has a computational cost. In some cases, the gain may not justify the added complexity. In many competitive programming environments, I/O is simple and sequential, meaning that this technique may not always be necessary or beneficial. It should be used in scenarios with extremely heavy I/O workloads or when processing and reading/writing can be separated.

The use of parallel I/O in programming competitive programmings typically applies to scenarios where there are many read/write operations or when the program needs to process large volumes of data while still reading or writing files. This situation is usual in [AI competitive programmings](https://opencv.org/opencv-ai-competitive-programming-2021/) and in hackatons. This technique can be useful in problems involving the manipulation of large datasets or intensive input/output processing, such as in "big data" challenges or reading/writing from disks. However, due to its complexity, the use of `std::async` and threads should be reserved for cases where parallelism offers a significant advantage over traditional sequential I/O.

## 4.3 Efficient Techniques for File I/O and Array Handling in Competitive Programming

| Function/Operation               | Most Efficient Technique                                                                        | Description                                                                                                                                          |
| -------------------------------- | ----------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| Reading from file (command line) | `std::ifstream` or `fread`/`mmap`                                                               | `std::ifstream` is efficient for small file reads, but `fread` and `mmap` are preferred for large files as they reduce system call overhead.         |
| Reading from standard input      | Disable synchronization with `std::ios::sync_with_stdio(false)` and use `std::cin.tie(nullptr)` | Disables C/C++ stream synchronization to improve performance when reading from `std::cin`.                                                           |
| Writing to terminal              | `putchar` or `printf`                                                                           | `putchar` is most efficient for writing individual characters, while `printf` is faster than `std::cout` in competitive programming.                 |
| Working with arrays              | `std::vector` with `std::span` (C++20)                                                          | `std::span` allows access to arrays and vectors without additional copies, providing bounds safety and efficiency in data handling without overhead. |
| Data processing                  | `std::ranges` (C++20)                                                                           | `std::ranges` enables efficient, lazy-evaluated chained operations like filtering and transforming data without extra memory allocation.             |
| Parallel I/O                     | `std::async` with asynchronous read and write operations                                        | `std::async` improves performance in high I/O scenarios by enabling parallel read/write operations.                                                  |
| Vector manipulation              | `std::vector` with preprocessing (e.g., macros, `constexpr`)                                    | Using macros or `constexpr` for frequent operations like sorting or summing elements can save time in competitive programmings.                      |
| Handling large data volumes      | Manual buffering with `fread` and `fwrite`                                                      | `fread` and `fwrite` allow efficient reading and writing of large blocks of data, minimizing system call overhead.                                   |

