<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Linguagens Formais e Autômatos - 19&nbsp; Aula: Princípios e Abstrações do MLIR</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./21-mlir-arch.html" rel="next">
<link href="./19-mlir-sintaxe.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles/custom.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./14-GeraInter.html">Geração de Código Intermediário</a></li><li class="breadcrumb-item"><a href="./20-mlir-plano.html"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Aula: Princípios e Abstrações do MLIR</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Linguagens Formais e Autômatos</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/frankalcantara/linguagens-formais" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Disciplina de Linguagens Formais</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Analisadores Léxicos</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-lexico.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Analisadores Léxicos</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01a-lexico.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Alfabetos, Linguagens e Strings: Fundamentos Matemáticos</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-lexico.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Autômatos Finitos Determinísticos</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Analisadores Sintáticos</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-Gramaticas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Gramáticas e Linguagens Livres de Contexto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-parsersLL1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Parsers LL(1): Começando a Análise Sintática</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-first-follow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Conjuntos FIRST e FOLLOW</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-parserLR1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Parsers <span class="math inline">\(LR(1)\)</span>: Análise Sintática <em>bottom-up</em></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-parserSLR1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Parsers <span class="math inline">\(SLR(1)\)</span>: A Ponte Entre Simplicidade e Poder</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Analisadores Semânticos</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-semantico.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Analisadores Semânticos: a determinação do significado</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10a-semantico.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Fundamentos Matemáticos da Semântica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10b-semantico.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Julgamento de Tipos em Linguagens Imperativas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10c-semantico.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">O Sistema de Tipos Hindley-Milner</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-tabelaSimbolos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Tabela de Símbolos em Compiladores Modernos</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Geração de Código Intermediário</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-GeraInter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Geração de Código Intermediário: A Linguagem Universal do Compilador</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-llvmIR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introdução à Representação Intermediária (IR) do <strong>LLVM</strong> com C++</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-peepOtimiza.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Otimizações Peephole: Algoritmos e Técnicas em Código Intermediário</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-mlir-sintaxe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title"><strong>MLIR</strong> 101: Nosso Primeiro Exemplo e Sintaxe Básica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-mlir-plano.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Aula: Princípios e Abstrações do MLIR</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21-mlir-arch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title"><strong>MLIR: Uma Análise Exaustiva dos Passes e do Abaixamento Multi-Nível na Engenharia Moderna de Compiladores</strong></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Projetos da Disciplina - 2025-2</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fase1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Fase 1 - Projeto Prático</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fase2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Fase 2 - Analisador Sintático <span class="math inline">\(LL(1)\)</span></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fase3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Fase 3 - Analisador Semântico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fase4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Fase 4 - Geração de Código Intermediário e Assembly</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./apend1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Apêndice 1: A Relação de Myhill-Nerode</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sol-exercicios.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Solução dos Exercícios</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./referencias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referências</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sumário</h2>
   
  <ul>
  <li><a href="#plano-de-aula-versão-01" id="toc-plano-de-aula-versão-01" class="nav-link active" data-scroll-target="#plano-de-aula-versão-01"><span class="header-section-number">20</span> Plano de Aula: Versão 01</a>
  <ul class="collapse">
  <li><a href="#módulo-1-fundamentos-da-ir-e-otimizações-locais" id="toc-módulo-1-fundamentos-da-ir-e-otimizações-locais" class="nav-link" data-scroll-target="#módulo-1-fundamentos-da-ir-e-otimizações-locais"><span class="header-section-number">20.1</span> Módulo 1: Fundamentos da IR e Otimizações Locais</a>
  <ul class="collapse">
  <li><a href="#anatomia-do-ir-generalizando-instruções-e-blocos" id="toc-anatomia-do-ir-generalizando-instruções-e-blocos" class="nav-link" data-scroll-target="#anatomia-do-ir-generalizando-instruções-e-blocos"><span class="header-section-number">20.1.1</span> Anatomia do IR: Generalizando Instruções e Blocos</a></li>
  <li><a href="#dialetos-func-e-arith-estruturação-e-computação-básica" id="toc-dialetos-func-e-arith-estruturação-e-computação-básica" class="nav-link" data-scroll-target="#dialetos-func-e-arith-estruturação-e-computação-básica"><span class="header-section-number">20.1.2</span> Dialetos func e arith: Estruturação e Computação Básica</a></li>
  <li><a href="#teoria-de-otimização-local-canonicalização-e-cse" id="toc-teoria-de-otimização-local-canonicalização-e-cse" class="nav-link" data-scroll-target="#teoria-de-otimização-local-canonicalização-e-cse"><span class="header-section-number">20.1.3</span> Teoria de Otimização Local: Canonicalização e CSE</a></li>
  </ul></li>
  <li><a href="#módulo-2-controle-de-fluxo-estruturado-scf" id="toc-módulo-2-controle-de-fluxo-estruturado-scf" class="nav-link" data-scroll-target="#módulo-2-controle-de-fluxo-estruturado-scf"><span class="header-section-number">20.2</span> Módulo 2: Controle de Fluxo Estruturado (SCF)</a>
  <ul class="collapse">
  <li><a href="#estruturado-vs-não-estruturado-uma-dicotomia-fundamental" id="toc-estruturado-vs-não-estruturado-uma-dicotomia-fundamental" class="nav-link" data-scroll-target="#estruturado-vs-não-estruturado-uma-dicotomia-fundamental"><span class="header-section-number">20.2.1</span> Estruturado vs Não Estruturado: Uma Dicotomia Fundamental</a></li>
  <li><a href="#o-dialeto-scf-abstração-de-loops-e-condicionais" id="toc-o-dialeto-scf-abstração-de-loops-e-condicionais" class="nav-link" data-scroll-target="#o-dialeto-scf-abstração-de-loops-e-condicionais"><span class="header-section-number">20.2.2</span> O Dialeto SCF: Abstração de Loops e Condicionais</a></li>
  <li><a href="#implicações-de-design-e-trade-offs" id="toc-implicações-de-design-e-trade-offs" class="nav-link" data-scroll-target="#implicações-de-design-e-trade-offs"><span class="header-section-number">20.2.3</span> Implicações de Design e Trade-offs</a></li>
  </ul></li>
  <li><a href="#módulo-3-modelagem-de-memória-e-análise-estática-affine" id="toc-módulo-3-modelagem-de-memória-e-análise-estática-affine" class="nav-link" data-scroll-target="#módulo-3-modelagem-de-memória-e-análise-estática-affine"><span class="header-section-number">20.3</span> Módulo 3: Modelagem de Memória e Análise Estática (Affine)</a>
  <ul class="collapse">
  <li><a href="#abstração-de-memória-memref-e-semântica-de-referência" id="toc-abstração-de-memória-memref-e-semântica-de-referência" class="nav-link" data-scroll-target="#abstração-de-memória-memref-e-semântica-de-referência"><span class="header-section-number">20.3.1</span> Abstração de Memória: Memref e Semântica de Referência</a></li>
  <li><a href="#o-dialeto-affine-restrição-para-análise" id="toc-o-dialeto-affine-restrição-para-análise" class="nav-link" data-scroll-target="#o-dialeto-affine-restrição-para-análise"><span class="header-section-number">20.3.2</span> O Dialeto Affine: Restrição para Análise</a></li>
  <li><a href="#análise-de-dependência-e-transformações" id="toc-análise-de-dependência-e-transformações" class="nav-link" data-scroll-target="#análise-de-dependência-e-transformações"><span class="header-section-number">20.3.3</span> Análise de Dependência e Transformações</a></li>
  <li><a href="#limitações-e-trade-offs-do-modelo-affine" id="toc-limitações-e-trade-offs-do-modelo-affine" class="nav-link" data-scroll-target="#limitações-e-trade-offs-do-modelo-affine"><span class="header-section-number">20.3.4</span> Limitações e Trade-offs do Modelo Affine</a></li>
  </ul></li>
  <li><a href="#módulo-4-o-pipeline-de-rebaixamento-lowering-de-loops" id="toc-módulo-4-o-pipeline-de-rebaixamento-lowering-de-loops" class="nav-link" data-scroll-target="#módulo-4-o-pipeline-de-rebaixamento-lowering-de-loops"><span class="header-section-number">20.4</span> Módulo 4: O Pipeline de Rebaixamento (Lowering) de Loops</a>
  <ul class="collapse">
  <li><a href="#o-princípio-do-rebaixamento-progressivo" id="toc-o-princípio-do-rebaixamento-progressivo" class="nav-link" data-scroll-target="#o-princípio-do-rebaixamento-progressivo"><span class="header-section-number">20.4.1</span> O Princípio do Rebaixamento Progressivo</a></li>
  <li><a href="#a-cascata-affine-scf-cf" id="toc-a-cascata-affine-scf-cf" class="nav-link" data-scroll-target="#a-cascata-affine-scf-cf"><span class="header-section-number">20.4.2</span> A Cascata: Affine → SCF → CF</a></li>
  <li><a href="#perda-de-informação-e-suas-implicações" id="toc-perda-de-informação-e-suas-implicações" class="nav-link" data-scroll-target="#perda-de-informação-e-suas-implicações"><span class="header-section-number">20.4.3</span> Perda de Informação e Suas Implicações</a></li>
  </ul></li>
  <li><a href="#módulo-5-passes-de-otimização-e-geração-de-llvm" id="toc-módulo-5-passes-de-otimização-e-geração-de-llvm" class="nav-link" data-scroll-target="#módulo-5-passes-de-otimização-e-geração-de-llvm"><span class="header-section-number">20.5</span> Módulo 5: Passes de Otimização e Geração de <strong>LLVM</strong></a>
  <ul class="collapse">
  <li><a href="#infraestrutura-de-passes-análise-e-transformação" id="toc-infraestrutura-de-passes-análise-e-transformação" class="nav-link" data-scroll-target="#infraestrutura-de-passes-análise-e-transformação"><span class="header-section-number">20.5.1</span> Infraestrutura de Passes: Análise e Transformação</a></li>
  <li><a href="#teoria-de-inlining-expansão-vs-sobrecarga" id="toc-teoria-de-inlining-expansão-vs-sobrecarga" class="nav-link" data-scroll-target="#teoria-de-inlining-expansão-vs-sobrecarga"><span class="header-section-number">20.5.2</span> Teoria de Inlining: Expansão vs Sobrecarga</a></li>
  <li><a href="#a-ponte-para-llvm-dialeto-llvm-e-tradução" id="toc-a-ponte-para-llvm-dialeto-llvm-e-tradução" class="nav-link" data-scroll-target="#a-ponte-para-llvm-dialeto-llvm-e-tradução"><span class="header-section-number">20.5.3</span> A Ponte para <strong>LLVM</strong>: Dialeto <strong>LLVM</strong> e Tradução</a></li>
  </ul></li>
  <li><a href="#módulo-6-abstrações-de-alto-nível-dialeto-linalg" id="toc-módulo-6-abstrações-de-alto-nível-dialeto-linalg" class="nav-link" data-scroll-target="#módulo-6-abstrações-de-alto-nível-dialeto-linalg"><span class="header-section-number">20.6</span> Módulo 6: Abstrações de Alto Nível (Dialeto Linalg)</a>
  <ul class="collapse">
  <li><a href="#a-necessidade-de-abstração-matemática" id="toc-a-necessidade-de-abstração-matemática" class="nav-link" data-scroll-target="#a-necessidade-de-abstração-matemática"><span class="header-section-number">20.6.1</span> A Necessidade de Abstração Matemática</a></li>
  <li><a href="#dialeto-linalg-modelando-operações-estruturadas" id="toc-dialeto-linalg-modelando-operações-estruturadas" class="nav-link" data-scroll-target="#dialeto-linalg-modelando-operações-estruturadas"><span class="header-section-number">20.6.2</span> Dialeto Linalg: Modelando Operações Estruturadas</a></li>
  <li><a href="#separação-de-interesses-e-portabilidade" id="toc-separação-de-interesses-e-portabilidade" class="nav-link" data-scroll-target="#separação-de-interesses-e-portabilidade"><span class="header-section-number">20.6.3</span> Separação de Interesses e Portabilidade</a></li>
  </ul></li>
  <li><a href="#módulo-7-rebaixamento-do-linalg-e-transformações-estruturais" id="toc-módulo-7-rebaixamento-do-linalg-e-transformações-estruturais" class="nav-link" data-scroll-target="#módulo-7-rebaixamento-do-linalg-e-transformações-estruturais"><span class="header-section-number">20.7</span> Módulo 7: Rebaixamento do Linalg e Transformações Estruturais</a>
  <ul class="collapse">
  <li><a href="#geração-de-loops-de-especificação-a-implementação" id="toc-geração-de-loops-de-especificação-a-implementação" class="nav-link" data-scroll-target="#geração-de-loops-de-especificação-a-implementação"><span class="header-section-number">20.7.1</span> Geração de Loops: De Especificação a Implementação</a></li>
  <li><a href="#transformações-estruturais-tiling-como-exemplo" id="toc-transformações-estruturais-tiling-como-exemplo" class="nav-link" data-scroll-target="#transformações-estruturais-tiling-como-exemplo"><span class="header-section-number">20.7.2</span> Transformações Estruturais: Tiling como Exemplo</a></li>
  <li><a href="#implicações-para-portabilidade-e-auto-tuning" id="toc-implicações-para-portabilidade-e-auto-tuning" class="nav-link" data-scroll-target="#implicações-para-portabilidade-e-auto-tuning"><span class="header-section-number">20.7.3</span> Implicações para Portabilidade e Auto-Tuning</a></li>
  </ul></li>
  <li><a href="#módulo-8-alvos-de-aceleração-gpu-e-metaprogramação-drr" id="toc-módulo-8-alvos-de-aceleração-gpu-e-metaprogramação-drr" class="nav-link" data-scroll-target="#módulo-8-alvos-de-aceleração-gpu-e-metaprogramação-drr"><span class="header-section-number">20.8</span> Módulo 8: Alvos de Aceleração (GPU) e Metaprogramação (DRR)</a>
  <ul class="collapse">
  <li><a href="#mapeamento-de-gpu-hierarquia-de-execução-em-ir" id="toc-mapeamento-de-gpu-hierarquia-de-execução-em-ir" class="nav-link" data-scroll-target="#mapeamento-de-gpu-hierarquia-de-execução-em-ir"><span class="header-section-number">20.8.1</span> Mapeamento de GPU: Hierarquia de Execução em IR</a></li>
  <li><a href="#mapeamento-de-linalg-para-gpu" id="toc-mapeamento-de-linalg-para-gpu" class="nav-link" data-scroll-target="#mapeamento-de-linalg-para-gpu"><span class="header-section-number">20.8.2</span> Mapeamento de Linalg para GPU</a></li>
  <li><a href="#tablegen-e-drr-metaprogramação-para-passes" id="toc-tablegen-e-drr-metaprogramação-para-passes" class="nav-link" data-scroll-target="#tablegen-e-drr-metaprogramação-para-passes"><span class="header-section-number">20.8.3</span> TableGen e DRR: Metaprogramação para Passes</a></li>
  <li><a href="#vantagens-e-limitações-da-metaprogramação" id="toc-vantagens-e-limitações-da-metaprogramação" class="nav-link" data-scroll-target="#vantagens-e-limitações-da-metaprogramação"><span class="header-section-number">20.8.4</span> Vantagens e Limitações da Metaprogramação</a></li>
  </ul></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/frankalcantara/linguagens-formais/edit/main/20-mlir-plano.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/frankalcantara/linguagens-formais/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./14-GeraInter.html">Geração de Código Intermediário</a></li><li class="breadcrumb-item"><a href="./20-mlir-plano.html"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Aula: Princípios e Abstrações do MLIR</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Aula: Princípios e Abstrações do MLIR</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="plano-de-aula-versão-01" class="level1" data-number="20">
<h1 data-number="20"><span class="header-section-number">20</span> Plano de Aula: Versão 01</h1>
<section id="módulo-1-fundamentos-da-ir-e-otimizações-locais" class="level2" data-number="20.1">
<h2 data-number="20.1" class="anchored" data-anchor-id="módulo-1-fundamentos-da-ir-e-otimizações-locais"><span class="header-section-number">20.1</span> Módulo 1: Fundamentos da IR e Otimizações Locais</h2>
<section id="anatomia-do-ir-generalizando-instruções-e-blocos" class="level3" data-number="20.1.1">
<h3 data-number="20.1.1" class="anchored" data-anchor-id="anatomia-do-ir-generalizando-instruções-e-blocos"><span class="header-section-number">20.1.1</span> Anatomia do IR: Generalizando Instruções e Blocos</h3>
<p>O MLIR fundamenta-se em uma generalização rigorosa dos conceitos tradicionais de representação intermediária. Enquanto IRs clássicas como a do <strong>LLVM</strong> definem tipos de instruções específicos (add, mul, br), o MLIR introduz uma metaestrutura que pode representar qualquer operação através de cinco componentes fundamentais.</p>
<p>A <em>Operation</em> é a unidade atômica de computação no MLIR. Conceitualmente, uma operação encapsula um cálculo que consome valores de entrada (operandos) e produz valores de saída (resultados). O aspecto decisivo é que a <em>Operation</em> não é uma classe específica de instruções, mas um contêiner genérico. A identidade de uma operação é determinada por seu nome qualificado por dialeto (por exemplo, arith.addi ou func.call), que define sua semântica através de um registro centralizado. Esta indireção permite que novos tipos de operações sejam definidos dinamicamente sem modificar a infraestrutura core do compilador.</p>
<p>Os operandos e resultados de uma operação são obrigatoriamente valores em forma SSA (Static Single Assignment). Esta restrição garante que cada valor seja definido exatamente uma vez, simplificando análises de fluxo de dados e transformações. No MLIR, valores SSA são first-class citizens, carregando informação de tipo completa e rastreabilidade de definição. A propriedade SSA é mantida mesmo em construções complexas como loops através do mecanismo de block arguments, que será explorado posteriormente.</p>
<p>Os Types especificam a natureza dos valores manipulados pelas operações. O sistema de tipos do MLIR é extensível: dialetos podem definir seus próprios tipos além dos tipos builtin (como i32 para inteiros de 32 bits ou f64 para floats de 64 bits). Um tipo como memref&lt;10xf32&gt; comunica não apenas que estamos lidando com memória, mas especifica dimensionalidade e tipo de elemento. Esta riqueza de informação de tipo permite verificações de corretude mais rigorosas e otimizações mais agressivas.</p>
<p>Os Attributes representam metadados conhecidos em tempo de compilação. Diferentemente de operandos (que são valores computados em runtime), atributos são constantes imutáveis que parametrizam o comportamento de operações. Um atributo pode especificar o valor de uma constante (como #arith.constant 42 : i32), propriedades de alinhamento de memória, ou configurações de precisão numérica. A distinção entre atributos e operandos é fundamental: atributos não participam do grafo SSA e podem ser inspecionados estaticamente durante a compilação.</p>
<p>As Regions são talvez a abstração mais poderosa do MLIR. Uma região é uma coleção ordenada de blocos básicos (Blocks) que pode ser aninhada dentro de uma operação. Este aninhamento permite representar estruturas de controle complexas de forma hierárquica. Por exemplo, uma operação scf.if contém duas regions (then e else), cada uma podendo conter múltiplos blocos. Esta hierarquia contrasta com CFGs (Control Flow Graphs) planos onde toda estrutura de controle é representada por branches explícitos entre blocos.</p>
<p>Um Block é uma sequência linear de operações terminada obrigatoriamente por uma operação terminadora (que transfere controle para outro bloco ou retorna). Blocos podem ter argumentos, que são o mecanismo pelo qual informação flui entre blocos mantendo a propriedade SSA. Quando o controle é transferido para um bloco, os argumentos daquele bloco recebem valores concretos, similar a parâmetros de função.</p>
<p>Esta arquitetura generalizada permite que o MLIR represente desde instruções simples de três endereços (típicas de IRs baixo nível) até operações tensoriais abstratas (típicas de IRs de alto nível) usando a mesma estrutura fundamental. A uniformidade simplifica a implementação de ferramentas de análise e transformação que operam genericamente sobre qualquer dialeto.</p>
</section>
<section id="dialetos-func-e-arith-estruturação-e-computação-básica" class="level3" data-number="20.1.2">
<h3 data-number="20.1.2" class="anchored" data-anchor-id="dialetos-func-e-arith-estruturação-e-computação-básica"><span class="header-section-number">20.1.2</span> Dialetos func e arith: Estruturação e Computação Básica</h3>
<p>O dialeto func fornece as primitivas para estruturação modular de código. A operação func.func define uma unidade de código reutilizável, especificando assinatura (tipos de parâmetros e retornos) e corpo (uma region contendo a implementação). Este dialeto é análogo ao conceito de função em linguagens de alto nível ou ao conceito de procedure em assembly. A operação func.call invoca uma função, conectando o sistema de valores SSA entre chamador e chamado. O dialeto func é fundamental porque estabelece o escopo de visibilidade de valores SSA: valores definidos dentro de uma função não são acessíveis fora dela, impondo encapsulamento.</p>
<p>O dialeto arith modela operações aritméticas sobre tipos escalares inteiros e de ponto flutuante. Operações como arith.addi (adição inteira), arith.mulf (multiplicação float), e arith.cmpi (comparação inteira) fornecem os building blocks para computação numérica. Um aspecto importante é que o dialeto arith é type-generic: a mesma operação arith.addi funciona sobre i8, i32, i64, etc., com a verificação de tipos garantindo que operandos e resultado sejam consistentes. Este design contrasta com IRs como <strong>LLVM</strong> onde diferentes instruções (add, fadd) existem para diferentes categorias de tipos.</p>
<p>A operação arith.constant merece atenção especial. Ela introduz um valor constante no grafo SSA, transformando um atributo (metadado) em um valor (operando). Esta operação é a ponte entre informação estática (conhecida em tempo de compilação) e o fluxo de computação dinâmico. A presença explícita de constantes no IR permite análises de propagação de constantes e otimizações como constant folding.</p>
</section>
<section id="teoria-de-otimização-local-canonicalização-e-cse" class="level3" data-number="20.1.3">
<h3 data-number="20.1.3" class="anchored" data-anchor-id="teoria-de-otimização-local-canonicalização-e-cse"><span class="header-section-number">20.1.3</span> Teoria de Otimização Local: Canonicalização e CSE</h3>
<p>Otimizações locais são transformações que operam dentro de um escopo limitado (tipicamente um bloco básico ou uma região pequena) sem análise interprocedural complexa. Estas otimizações são fundamentais porque preparam o IR para análises mais sofisticadas e frequentemente expõem oportunidades de otimização adicionais.</p>
<p>A canonicalização é o processo de transformar o IR para uma forma canônica, onde padrões equivalentes são normalizados para uma representação única. Por exemplo, a expressão x + 0 e x são semanticamente equivalentes, mas representações distintas. A forma canônica escolhe x como representante único. A canonicalização é benéfica por múltiplas razões. Primeiro, simplifica análises subsequentes: ao garantir que padrões equivalentes tenham representação única, análises não precisam considerar todas as variações possíveis. Segundo, reduz o tamanho do IR, diminuindo o tempo de compilação. Terceiro, expõe oportunidades de otimização: simplificar x + 0 para x pode permitir que x seja propagado adiante.</p>
<p>O constant folding é uma forma específica de canonicalização onde operações cujos operandos são todos constantes são avaliadas em tempo de compilação. Por exemplo, arith.addi(c3, c5) é substituído por c8 diretamente. Esta otimização elimina computação redundante em runtime e pode ser aplicada recursivamente: se o resultado de um folding é usado em outra operação constante, essa operação também pode ser folded. O constant folding é implementado no MLIR através de padrões de reescrita (rewrite patterns) que reconhecem operações com operandos constantes e computam o resultado estaticamente.</p>
<p>A eliminação de subexpressão comum (CSE - Common Subexpression Elimination) opera sob um princípio diferente. Considere o código onde x + y é computado duas vezes com os mesmos operandos. <strong>CSE</strong> reconhece esta redundância e computa a expressão uma única vez, reutilizando o resultado. A implementação de <strong>CSE</strong> requer uma análise de disponibilidade: um valor computado anteriormente só pode ser reutilizado se ele ainda está “vivo” no ponto de uso (não foi sobrescrito ou invalidado).</p>
<p>A limitação importante de <strong>CSE</strong> é que ela só se aplica a operações puras (sem efeitos colaterais). Uma operação que altera memória ou depende de estado global não pode ser eliminada mesmo se aparentemente redundante, pois sua execução múltipla pode produzir efeitos observáveis diferentes. O MLIR codifica esta informação através de traits de operação: operações marcadas como NoSideEffect podem ser eliminadas por CSE, enquanto operações com efeitos colaterais são preservadas.</p>
<p>A interação entre canonicalização e <strong>CSE</strong> é sinérgica. Canonicalização normaliza expressões, aumentando a probabilidade de que expressões equivalentes sejam reconhecidas como idênticas por <strong>CSE</strong>. Aplicar estas otimizações iterativamente em um fixed-point loop frequentemente resulta em simplificações substanciais do IR.</p>
</section>
</section>
<section id="módulo-2-controle-de-fluxo-estruturado-scf" class="level2" data-number="20.2">
<h2 data-number="20.2" class="anchored" data-anchor-id="módulo-2-controle-de-fluxo-estruturado-scf"><span class="header-section-number">20.2</span> Módulo 2: Controle de Fluxo Estruturado (SCF)</h2>
<section id="estruturado-vs-não-estruturado-uma-dicotomia-fundamental" class="level3" data-number="20.2.1">
<h3 data-number="20.2.1" class="anchored" data-anchor-id="estruturado-vs-não-estruturado-uma-dicotomia-fundamental"><span class="header-section-number">20.2.1</span> Estruturado vs Não Estruturado: Uma Dicotomia Fundamental</h3>
<p>A distinção entre controle de fluxo estruturado e não estruturado é central para compreender diferentes níveis de abstração em representações intermediárias. Em um CFG não estruturado tradicional, o controle de fluxo é representado através de um grafo de blocos básicos conectados por branches (saltos) arbitrários. Um bloco pode transferir controle para qualquer outro bloco (respeitando restrições de dominância), e estruturas de alto nível como loops e condicionais não são explicitamente representadas, mas emergem da topologia do grafo.</p>
<p>Esta representação tem vantagens: é completamente geral, podendo expressar qualquer padrão de controle de fluxo incluindo goto arbitrário, e mapeia diretamente para instruções de branch de máquina. No entanto, esta generalidade vem com custos significativos. Reconhecer estruturas de alto nível a partir de um CFG arbitrário é um problema difícil, limitando a eficácia de otimizações que dependem de compreender a estrutura de loops (como loop invariant code motion ou vectorização). Além disso, a liberdade de controle arbitrário facilita a introdução de bugs em transformações de compilador e dificulta análises formais de corretude.</p>
<p>O controle de fluxo estruturado impõe restrições sobre padrões de controle permitidos, tipicamente requerendo que todo bloco de código tenha um único ponto de entrada e um único ponto de saída. Loops são representados através de operações dedicadas (como scf.for) que encapsulam a estrutura do loop, e condicionais através de operações if-then-else hierárquicas. Esta representação sacrifica generalidade: certos padrões de controle (como múltiplas saídas de loop via break) requerem transformações adicionais. Em troca, obtém-se múltiplos benefícios.</p>
<p>Primeiro, análise simplificada. A estrutura explícita permite que otimizações identifiquem loops e suas propriedades (bounds, stride, corpo) diretamente, sem análise de CFG. Segundo, transformações mais seguras. Operações sobre controle estruturado preservam automaticamente propriedades de boa formação, reduzindo a superfície de erro. Terceiro, portabilidade melhorada. Controle estruturado mapeia naturalmente para construções de linguagens de alto nível e facilita targeting de arquiteturas não convencionais (como GPUs que penalizam branch divergence).</p>
</section>
<section id="o-dialeto-scf-abstração-de-loops-e-condicionais" class="level3" data-number="20.2.2">
<h3 data-number="20.2.2" class="anchored" data-anchor-id="o-dialeto-scf-abstração-de-loops-e-condicionais"><span class="header-section-number">20.2.2</span> O Dialeto SCF: Abstração de Loops e Condicionais</h3>
<p>O dialeto scf (Structured Control Flow) materializa o princípio de controle estruturado através de operações que encapsulam padrões comuns. A operação scf.for representa um loop com bounds conhecidos estaticamente ou dinamicamente, stride configurável, e um corpo executado iterativamente. A sintaxe típica especifica lower bound, upper bound, step, e optional initial values para loop-carried variables.</p>
<p>A semântica de scf.for merece análise detalhada. O loop itera sobre uma variável de indução que assume valores de lower_bound até (mas não incluindo) upper_bound, incrementando por step a cada iteração. O corpo do loop é uma region que pode conter operações arbitrárias. O corpo deve terminar com <em>scf.yield</em>, que especifica valores a serem “carregados” para a próxima iteração ou retornados quando o loop termina.</p>
<p>Este mecanismo de yield resolve um problema fundamental: como manter SSA em presença de loops. Em um loop imperativo tradicional, variáveis são mutadas a cada iteração, violando a propriedade SSA de definição única. O scf.for resolve isto através de loop-carried values. A operação scf.for pode receber initial values como operandos, e o corpo do loop recebe estes valores como block arguments. Ao final de cada iteração, scf.yield produz novos valores que se tornam os block arguments da próxima iteração. Quando o loop termina, os valores finais yieldados tornam-se os resultados da operação scf.for.</p>
<p>Este design mantém SSA rigorosamente: cada iteração opera sobre valores immutáveis, e a “mutação” é modelada como produção de novos valores. Para o programador habituado a loops imperativos, isto pode parecer contorcionista, mas é precisamente esta disciplina que permite análises poderosas. Um compilador pode raciocinar sobre dependências entre iterações inspecionando como valores fluem através de yield, algo impossível com mutação arbitrária de memória.</p>
<p>A operação scf.if modela condicionais de forma similar. Ela recebe uma condição booleana e contém duas regions: then (executada se condição verdadeira) e else (executada se falsa). Ambas regions devem terminar com scf.yield, e se scf.if produz resultados, ambos branches devem yieldar valores de tipos consistentes. Esta estrutura força equivalência de tipos entre branches, prevenindo situações onde diferentes paths produzem valores incompatíveis.</p>
<p>A combinação de scf.for e scf.if permite expressar lógica de controle complexa mantendo estrutura hierárquica. Loops podem ser aninhados, condicionais podem aparecer dentro de loops, e a hierarquia é sempre explícita e verificável. Esta propriedade é invaluável para análises que dependem de compreender aninhamento de loops (como cálculo de custos de acesso à memória baseado em localidade de cache).</p>
</section>
<section id="implicações-de-design-e-trade-offs" class="level3" data-number="20.2.3">
<h3 data-number="20.2.3" class="anchored" data-anchor-id="implicações-de-design-e-trade-offs"><span class="header-section-number">20.2.3</span> Implicações de Design e Trade-offs</h3>
<p>A escolha de controle estruturado no scf não é sem custos. Certos padrões de controle comuns em linguagens imperativas são difíceis de expressar diretamente. Um loop com break condicional (early exit) não tem representação direta em scf.for, requerendo transformação para scf.while ou introdução de flags booleanos. Return statements dentro de loops devem ser transformados similarmente. Esta restrição pode parecer limitante, mas é intencional.</p>
<p>O scf opera em um nível de abstração onde a estrutura de loops é mais importante que a conveniência de expressão de padrões arbitrários. Ferramentas de otimização que operam neste nível (como loop unrolling ou fusion) beneficiam-se enormemente da estrutura explícita. Quando necessário rebaixar para padrões mais complexos, a transformação para cf (control flow não estruturado) está sempre disponível, implementando o princípio de rebaixamento progressivo onde estrutura de alto nível é preservada enquanto possível e descartada apenas quando necessário.</p>
</section>
</section>
<section id="módulo-3-modelagem-de-memória-e-análise-estática-affine" class="level2" data-number="20.3">
<h2 data-number="20.3" class="anchored" data-anchor-id="módulo-3-modelagem-de-memória-e-análise-estática-affine"><span class="header-section-number">20.3</span> Módulo 3: Modelagem de Memória e Análise Estática (Affine)</h2>
<section id="abstração-de-memória-memref-e-semântica-de-referência" class="level3" data-number="20.3.1">
<h3 data-number="20.3.1" class="anchored" data-anchor-id="abstração-de-memória-memref-e-semântica-de-referência"><span class="header-section-number">20.3.1</span> Abstração de Memória: Memref e Semântica de Referência</h3>
<p>A modelagem de memória em compiladores apresenta desafios fundamentais. Memória é stateful (operações de leitura e escrita alteram estado global) e possui semântica de aliasing (múltiplas referências podem apontar para o mesmo endereço, dificultando análise de dependência). O MLIR introduz o tipo memref para representar regiões de memória multidimensionais de forma estruturada.</p>
<p>Um memref é caracterizado por shape (dimensões), element type, e optional layout e memory space. Por exemplo, memref&lt;10x20xf32&gt; representa um buffer bidimensional de 10×20 floats. A informação dimensional é first-class: o tipo carrega metadados sobre tamanho, permitindo verificações de bounds em certas condições e otimizações conscientes de layout.</p>
<p>A semântica de memref é de referência: um valor memref não contém os dados, mas aponta para um buffer de memória. Múltiplos valores memref podem referenciar o mesmo buffer (aliasing), e operações sobre memref (load, store) têm efeitos colaterais observáveis. Esta semântica contrasta com o tipo tensor do MLIR, que tem semântica de valor: um tensor contém seus dados imutavelmente, e operações sobre tensors produzem novos tensors sem mutação.</p>
<p>A distinção memref vs tensor é importante para diferentes fases de compilação. Tensors são adequados para representação de alto nível onde abstrações funcionais e transformações matemáticas dominam. Memrefs são necessários para geração de código onde explicitação de layout de memória e reuso de buffers são essenciais para performance. O processo de bufferização (bufferization) transforma código baseado em tensors para código baseado em memrefs, uma transformação complexa que deve garantir corretude semântica enquanto introduz mutação.</p>
</section>
<section id="o-dialeto-affine-restrição-para-análise" class="level3" data-number="20.3.2">
<h3 data-number="20.3.2" class="anchored" data-anchor-id="o-dialeto-affine-restrição-para-análise"><span class="header-section-number">20.3.2</span> O Dialeto Affine: Restrição para Análise</h3>
<p>O dialeto affine representa uma abordagem radicalmente diferente para modelagem de loops e acesso à memória. Enquanto scf permite loops arbitrários parametrizados por valores quaisquer, affine impõe restrições matemáticas rígidas sobre bounds de loops e índices de acesso. Esta restrição pode parecer limitante, mas é precisamente o que habilita análises poderosas.</p>
<p>Uma expressão afim é uma função linear de variáveis de loop e símbolos (parâmetros externos), mais uma constante. Formalmente, uma expressão afim sobre variáveis i₁, i₂, …, iₙ e símbolos s₁, s₂, …, sₘ tem a forma c₀ + c₁i₁ + c₂i₂ + … + cₙiₙ + d₁s₁ + … + dₘsₘ, onde todos coeficientes c e d são constantes inteiras. Um mapa afim é uma coleção de expressões afins.</p>
<p>A operação affine.for implementa um loop cujos bounds e stride são expressões afins. Por exemplo, um loop iterando de 0 até N-1 (onde N é um símbolo) é perfeitamente afim. Um loop iterando de 0 até f(N) onde f é não-linear não é representável diretamente. Esta restrição garante que o conjunto de iterações executadas pelo loop pode ser representado como um polyhedron convexo em um espaço de dimensão igual ao número de loops aninhados.</p>
<p>As operações affine.load e affine.store acessam memória usando mapas afins para computar índices. Por exemplo, affine.load %A[%i + %j] onde i e j são variáveis de loop é afim, mas affine.load %A[%i * %j] não é (multiplicação de variáveis viola linearidade). Esta restrição pode parecer severa, mas muitos padrões de acesso em computação científica e machine learning são naturalmente afins: acessos sequenciais, transposições, strided access, e patterns de tiling são todos expressos naturalmente.</p>
</section>
<section id="análise-de-dependência-e-transformações" class="level3" data-number="20.3.3">
<h3 data-number="20.3.3" class="anchored" data-anchor-id="análise-de-dependência-e-transformações"><span class="header-section-number">20.3.3</span> Análise de Dependência e Transformações</h3>
<p>A razão de ser do dialeto affine é habilitar análise de dependência polyhedral. Esta análise determina, para todo par de acessos à memória (dois loads, dois stores, ou load e store), se eles podem referenciar a mesma localização de memória e, se sim, sob quais condições sobre as variáveis de loop. Esta informação é fundamental para determinar a legalidade de transformações.</p>
<p>Considere dois acessos A[i] = … e … = A[j] em loops aninhados. Existe dependência se há valores de i e j (executados pelo loop) tais que i = j. Para loops afins, este problema reduz-se a decidir satisfatibilidade de sistemas de inequações lineares inteiras, um problema para o qual algoritmos eficientes existem (como o algoritmo de Farkas ou programação linear inteira).</p>
<p>Com dependências conhecidas, transformações poderosas tornam-se possíveis. Loop interchange (trocar ordem de loops aninhados) pode melhorar localidade de cache, mas é legal apenas se não violar dependências. Loop fusion (fundir dois loops em um) pode eliminar armazenamento intermediário, mas requer análise cuidadosa de dependências entre loops. Tiling (bloquear loops para processar dados em tiles que cabem em cache) requer compreensão precisa de padrões de acesso.</p>
<p>O dialeto affine permite que estas transformações sejam implementadas como passes que consultam análises de dependência, verificam legalidade, e aplicam reescritas ao IR. A verificação de legalidade é decidível: não é heurística, mas matematicamente precisa. Esta garantia é impossível em dialetos não restritos onde dependências podem depender de valores arbitrários computados dinamicamente.</p>
</section>
<section id="limitações-e-trade-offs-do-modelo-affine" class="level3" data-number="20.3.4">
<h3 data-number="20.3.4" class="anchored" data-anchor-id="limitações-e-trade-offs-do-modelo-affine"><span class="header-section-number">20.3.4</span> Limitações e Trade-offs do Modelo Affine</h3>
<p>A potência analítica do affine tem custos. Primeiro, nem todo código é afim. Loops com bounds computados por chamadas de função, acessos indiretos à memória (A[B[i]]), e muitos padrões de código real violam restrições afins. Para estes casos, affine não é aplicável, requerendo uso de scf ou cf.</p>
<p>Segundo, análise polyhedral tem complexidade não trivial. Decidir satisfatibilidade de sistemas de inequações é polinomial no pior caso, mas para código com muitos loops aninhados pode ser caro. Implementações práticas usam heurísticas e time-outs, sacrificando completude por eficiência.</p>
<p>Terceiro, expressividade reduzida pode forçar representações menos naturais. Um programador habituado a indexação arbitrária pode achar restrições afins frustrantes. No contexto do MLIR, isto é mitigado pelo fato de que affine é um nível de abstração entre muitos. Código pode ser gerado em nível mais alto (<em>linalg</em>) e rebaixado para affine quando aplicável, ou bypassed diretamente para scf quando necessário.</p>
<p>O dialeto affine exemplifica uma filosofia importante do MLIR: restrição intencional de expressividade em troca de análise mais poderosa. Esta não é uma limitação global, mas uma escolha de design para um nível específico de abstração. O sistema de dialetos permite que diferentes partes do código operem em níveis adequados, com transformações explícitas entre níveis.</p>
</section>
</section>
<section id="módulo-4-o-pipeline-de-rebaixamento-lowering-de-loops" class="level2" data-number="20.4">
<h2 data-number="20.4" class="anchored" data-anchor-id="módulo-4-o-pipeline-de-rebaixamento-lowering-de-loops"><span class="header-section-number">20.4</span> Módulo 4: O Pipeline de Rebaixamento (Lowering) de Loops</h2>
<section id="o-princípio-do-rebaixamento-progressivo" class="level3" data-number="20.4.1">
<h3 data-number="20.4.1" class="anchored" data-anchor-id="o-princípio-do-rebaixamento-progressivo"><span class="header-section-number">20.4.1</span> O Princípio do Rebaixamento Progressivo</h3>
<p>O rebaixamento progressivo é a espinha dorsal da arquitetura do MLIR. A ideia central é que código não deve ser transformado diretamente de abstração máxima para código de máquina, mas através de uma sequência de transformações incrementais, cada uma reduzindo o nível de abstração por um degrau controlado. Cada nível intermediário serve propósitos específicos.</p>
<p>Este princípio resolve múltiplos problemas. Primeiro, modularidade de transformações. Cada passe de rebaixamento foca em um aspecto específico da transformação (por exemplo, eliminar estruturas affine, ou eliminar controle estruturado) sem precisar considerar todo o pipeline. Segundo, preservação de oportunidades de otimização. Otimizações aplicam-se mais naturalmente a certos níveis de abstração: loop unrolling é mais simples em scf que em cf, enquanto instruction scheduling é mais efetivo em cf que em scf. Rebaixamento progressivo permite aplicar otimizações no nível mais adequado.</p>
<p>Terceiro, retargeting facilitado. Diferentes arquiteturas podem requerer rebaixamento até diferentes níveis. Uma GPU pode beneficiar-se de manter estrutura de loops mais alta para mapeamento para hierarquia de threads, enquanto uma CPU pode preferir rebaixamento completo para CFG para permitir scheduling de instruções agressivo. O pipeline modular permite customização por target.</p>
</section>
<section id="a-cascata-affine-scf-cf" class="level3" data-number="20.4.2">
<h3 data-number="20.4.2" class="anchored" data-anchor-id="a-cascata-affine-scf-cf"><span class="header-section-number">20.4.2</span> A Cascata: Affine → SCF → CF</h3>
<p>O pipeline típico para compilação de loops procede através de três níveis distintos. No nível affine, loops são representados com restrições matemáticas e análise de dependência está disponível. Transformações polyhedral como tiling, interchange e fusion são aplicadas neste nível porque requerem a capacidade de raciocinar sobre conjuntos de iterações e dependências de forma matematicamente precisa.</p>
<p>O passe <code>--lower-affine</code> transforma affine para scf. Esta transformação é relativamente direta: affine.for com bounds afins é traduzido para scf.for com bounds computados através de operações aritméticas. Affine.load e affine.store são traduzidos para memref.load e memref.store, com índices computados através de operações arith. O aspecto decisivo é que esta transformação perde a informação de affinidade: após rebaixamento, o compilador não pode mais provar que bounds são afins ou que dependências são analisáveis. Esta perda é intencional: se análise polyhedral já foi realizada e transformações aplicadas, não há razão para preservar restrições affine. O código resultante scf é mais geral e próximo de representações imperativas convencionais.</p>
<p>O próximo passo, scf para cf através de <code>--convert-scf-to-cf</code>, é mais profundo. Um scf.for é transformado em um conjunto de blocos básicos conectados por branches. Tipicamente, isto envolve um bloco de cabeçalho (header) que verifica condição de loop, um bloco de corpo contendo as operações do loop body, e um bloco de saída (exit). Branches condicionais conectam estes blocos, e block arguments são usados para threading de valores através de iterações.</p>
<p>A complexidade surge do tratamento de loop-carried values. Um scf.for com loop-carried values recebe valores iniciais como operandos e yielda valores atualizados a cada iteração. No rebaixamento para cf, isto é implementado através de block arguments para o bloco de cabeçalho: a primeira entrada (antes do loop) passa valores iniciais, e o branch do corpo de volta para cabeçalho passa valores atualizados. O bloco de saída recebe valores finais via outro branch. Esta mecânica preserva SSA, mas obscurece a estrutura de loop: em cf, o loop não é uma operação hierárquica, mas emerge da topologia do CFG.</p>
<p>Uma transformação similar ocorre para scf.if. A condicional é transformada em cf.cond_br (conditional branch) para blocos then e else separados, que eventualmente convergem em um bloco de merge. Se scf.if produzia resultados, o bloco de merge recebe estes valores como block arguments, com cada branch passando seu resultado yieldado. Novamente, a estrutura hierárquica é flattened para topologia de grafo.</p>
</section>
<section id="perda-de-informação-e-suas-implicações" class="level3" data-number="20.4.3">
<h3 data-number="20.4.3" class="anchored" data-anchor-id="perda-de-informação-e-suas-implicações"><span class="header-section-number">20.4.3</span> Perda de Informação e Suas Implicações</h3>
<p>Cada passo de rebaixamento perde informação semântica de alto nível. Affine → scf perde a propriedade de que bounds e índices são expressões lineares, impossibilitando análise polyhedral subsequente. SCF → cf perde a estrutura hierárquica de loops e condicionais, impossibilitando otimizações que dependem de reconhecer estes padrões (como loop fusion ou vectorização ingênua).</p>
<p>Esta perda não é um bug, mas feature. Informação de alto nível é preservada enquanto útil para otimizações, e descartada quando não mais necessária. Após aplicar todas transformações polyhedral, preservar restrições affine apenas complicaria passes subsequentes. Após aplicar otimizações conscientes de estrutura de loop, expor o CFG flat habilita otimizações de baixo nível como instruction scheduling e register allocation que operam melhor sobre representação não estruturada.</p>
<p>O dialeto cf merece atenção especial. Ele é o “assembly” do MLIR, o nível mais baixo antes de tradução para <strong>LLVM</strong> IR ou código de máquina. Operações cf.br e cf.cond_br mapeiam quase diretamente para instruções de branch de hardware. Blocos básicos em cf correspondem a blocos básicos de CFG tradicional. Neste nível, toda abstração de alto nível foi eliminada: não há loops, apenas branches para trás; não há condicionais estruturados, apenas branches condicionais.</p>
<p>A existência de cf como nível distinto (em vez de rebaixar diretamente de scf para <strong>LLVM</strong>) tem justificativas. Primeiro, cf permite otimizações específicas de controle de fluxo (como block merging ou dead block elimination) independentes de <strong>LLVM</strong>. Segundo, cf serve como ponto de abstração uniforme: diferentes dialetos de alto nível (scf, affine, ou dialetos domain-specific) podem ser rebaixados para cf, que então serve como interface comum para geração de código. Terceiro, em contextos onde <strong>LLVM</strong> não é o target (como certos aceleradores ou interpretadores), cf pode ser traduzido diretamente sem passar por <strong>LLVM</strong>.</p>
<p>O pipeline affine → scf → cf ilustra perfeitamente a filosofia MLIR de rebaixamento progressivo: não um salto monolítico, mas uma escada de transformações onde cada degrau é compreensível e justificável individualmente.</p>
</section>
</section>
<section id="módulo-5-passes-de-otimização-e-geração-de-llvm" class="level2" data-number="20.5">
<h2 data-number="20.5" class="anchored" data-anchor-id="módulo-5-passes-de-otimização-e-geração-de-llvm"><span class="header-section-number">20.5</span> Módulo 5: Passes de Otimização e Geração de <strong>LLVM</strong></h2>
<section id="infraestrutura-de-passes-análise-e-transformação" class="level3" data-number="20.5.1">
<h3 data-number="20.5.1" class="anchored" data-anchor-id="infraestrutura-de-passes-análise-e-transformação"><span class="header-section-number">20.5.1</span> Infraestrutura de Passes: Análise e Transformação</h3>
<p>Um passe de compilador é uma unidade modular de transformação ou análise sobre IR. A infraestrutura de passes do MLIR segue a tradição estabelecida por <strong>LLVM</strong>, mas generaliza conceitos para operar sobre a estrutura multi-dialeto do MLIR. A distinção fundamental é entre passes de análise (analysis passes) e passes de transformação (transform passes).</p>
<p>Um analysis pass examina o IR e computa informações sem modificá-lo. Exemplos incluem análise de dominância (quais blocos dominam quais), análise de liveness (quais valores estão “vivos” em cada ponto), ou análise de dependência (quais operações dependem de quais). Resultados de análises são armazenados em estruturas de dados que passes subsequentes podem consultar. A infraestrutura garante que análises são invalidadas apropriadamente quando transformações modificam o IR, requerendo recomputação quando necessário.</p>
<p>Um transform pass modifica o IR. Transformações variam de simples (eliminar blocos mortos) a complexas (reestruturar loops para tiling). Passes de transformação frequentemente dependem de análises: antes de aplicar uma transformação, consultam análises para verificar legalidade ou estimar benefício. A separação entre análise e transformação promove modularidade: análises podem ser reutilizadas por múltiplas transformações, e transformações podem ser compostas sabendo que dependências são gerenciadas automaticamente pela infraestrutura.</p>
<p>O MLIR estende este modelo para operar sobre operações arbitrárias, não apenas funções. Um passe pode operar sobre func.func (como passes <strong>LLVM</strong> tradicionais), mas também sobre operações module (o programa inteiro), ou sobre operações específicas de dialetos domain-specific. Esta generalidade permite que passes sejam escritos para qualquer nível de abstração, consistente com a filosofia multi-level.</p>
</section>
<section id="teoria-de-inlining-expansão-vs-sobrecarga" class="level3" data-number="20.5.2">
<h3 data-number="20.5.2" class="anchored" data-anchor-id="teoria-de-inlining-expansão-vs-sobrecarga"><span class="header-section-number">20.5.2</span> Teoria de Inlining: Expansão vs Sobrecarga</h3>
<p>Inlining é a transformação que substitui uma chamada de função pelo corpo da função chamada, eliminando a sobrecarga de chamada. Esta otimização tem trade-offs complexos que ilustram desafios gerais em compilação.</p>
<p>Os benefícios de inlining são múltiplos. Primeiro, elimina sobrecarga direta de call: salvar registradores, setup de stack frame, branch para função, e retorno. Em código com funções pequenas chamadas frequentemente, esta sobrecarga pode dominar tempo de execução. Segundo, expõe oportunidades de otimização interprocedural. Após inline, operações da função chamada tornam-se parte do contexto do caller, permitindo que otimizações como constant propagation e dead code elimination atravessem fronteiras de função. Terceiro, habilita especialização: se uma função é chamada com argumentos constantes conhecidos, inline seguido de constant folding pode eliminar lógica condicional não executada.</p>
<p>Os custos de inlining são igualmente significativos. Primeiro, aumento de tamanho de código. Cada call site se torna uma cópia do corpo da função. Para funções grandes ou muitos call sites, isto pode explodir o tamanho do código, degradando performance por pressure em instruction cache. Segundo, compilação mais lenta. Mais código implica mais trabalho para passes subsequentes. Terceiro, dificuldade de debugging. Stack traces tornam-se menos informativos quando funções são inlined agressivamente.</p>
<p>Heurísticas de inlining tentam balancear estes trade-offs. Fatores considerados incluem tamanho da função (funções pequenas são candidatas preferenciais), número de call sites (inlining de função com muitos callers tem custo multiplicado), temperatura de código (código hot se beneficia mais de eliminação de sobrecarga), e análise de benefício específico (se inlining exporá constant folding significativo, pode valer a pena mesmo para funções grandes).</p>
<p>O passe <code>--inline</code> do MLIR implementa heurísticas configuráveis. Por padrão, funções pequenas são inlined agressivamente, e funções marcadas com atributos específicos (como inline ou noinline) têm comportamento forçado. A implementação respeita a abstração de dialetos: inlining opera genericamente sobre func.func, mas mecanismos de inlining podem ser customizados para dialetos específicos que definem suas próprias noções de callable operations.</p>
</section>
<section id="a-ponte-para-llvm-dialeto-llvm-e-tradução" class="level3" data-number="20.5.3">
<h3 data-number="20.5.3" class="anchored" data-anchor-id="a-ponte-para-llvm-dialeto-llvm-e-tradução"><span class="header-section-number">20.5.3</span> A Ponte para <strong>LLVM</strong>: Dialeto <strong>LLVM</strong> e Tradução</h3>
<p>O dialeto llvm do MLIR é um mapeamento isomórfico da representação <strong>LLVM</strong> IR para estrutura MLIR. Cada instrução <strong>LLVM</strong> corresponde a uma operação no dialeto llvm, e tipos <strong>LLVM</strong> são representados como tipos MLIR. Por exemplo, a instrução <strong>LLVM</strong> add corresponde à operação llvm.add, e o tipo <strong>LLVM</strong> i32 é representado como o tipo MLIR !llvm.i32.</p>
<p>A existência deste dialeto pode parecer redundante: por que não traduzir diretamente de dialetos MLIR de alto nível para <strong>LLVM</strong> IR textual? A resposta está na modularidade e no reuso de infraestrutura. O dialeto llvm permite que código <strong>LLVM</strong>-like seja manipulado usando ferramentas MLIR padrão. Passes de análise e transformação escritos para MLIR podem operar sobre dialeto llvm, e código MLIR pode integrar fragments de código llvm livremente.</p>
<p>Mais importante, o dialeto llvm serve como target uniforme para rebaixamento. Dialetos de alto nível são progressivamente rebaixados através de níveis intermediários, convergindo eventualmente para dialeto llvm. Passes de conversão como <code>--convert-func-to-llvm</code>, <code>--convert-arith-to-llvm</code>, e <code>--convert-cf-to-llvm</code> implementam mapeamentos de dialetos MLIR padrão para dialeto llvm. Estes passes são compostos sequencialmente para transformar um programa MLIR completo em programa equivalente no dialeto llvm.</p>
<p>Uma vez que todo o programa está no dialeto llvm, a ferramenta mlir-translate realiza tradução mecânica para <strong>LLVM</strong> IR textual (formato .ll). Esta tradução é trivial porque dialeto llvm e <strong>LLVM</strong> IR são isomórficos por design. O <strong>LLVM</strong> IR resultante pode ser processado por ferramentas <strong>LLVM</strong> padrão: otimizações adicionais via opt, geração de código via llc, ou linking via lld.</p>
<p>Este design em duas fases (MLIR → dialeto llvm → <strong>LLVM</strong> IR) tem vantagens arquiteturais. Primeiro, desacopla MLIR de detalhes de <strong>LLVM</strong>. Se <strong>LLVM</strong> mudar, apenas mlir-translate precisa atualização, não todos os passes de rebaixamento. Segundo, permite que MLIR opere em ambiente sem <strong>LLVM</strong>. Em plataformas onde <strong>LLVM</strong> não é target (certos embedded systems ou aceleradores customizados), dialetos podem ser rebaixados para representações nativas sem passar por llvm. Terceiro, facilita testing e debugging. Código pode ser inspecionado no nível de dialeto llvm usando ferramentas MLIR antes de tradução final.</p>
<p>A existência de dialeto llvm exemplifica a filosofia MLIR de interfaces uniformes entre níveis de abstração. Não há tratamento especial para <strong>LLVM</strong>: é apenas mais um dialeto, embora um com importância particular como target final comum.</p>
</section>
</section>
<section id="módulo-6-abstrações-de-alto-nível-dialeto-linalg" class="level2" data-number="20.6">
<h2 data-number="20.6" class="anchored" data-anchor-id="módulo-6-abstrações-de-alto-nível-dialeto-linalg"><span class="header-section-number">20.6</span> Módulo 6: Abstrações de Alto Nível (Dialeto Linalg)</h2>
<section id="a-necessidade-de-abstração-matemática" class="level3" data-number="20.6.1">
<h3 data-number="20.6.1" class="anchored" data-anchor-id="a-necessidade-de-abstração-matemática"><span class="header-section-number">20.6.1</span> A Necessidade de Abstração Matemática</h3>
<p>Os dialetos affine e scf, apesar de poderosos, operam em um nível de abstração fundamentalmente imperativo. Eles modelam como computação é realizada: através de loops iterando sobre índices, carregando valores de memória, computando resultados, e armazenando de volta. Esta perspectiva é adequada para geração de código eficiente, mas obscurece o que está sendo computado em termos matemáticos.</p>
<p>Considere uma multiplicação de matrizes C = A × B. Em affine ou scf, isto é expresso como três loops aninhados iterando sobre linhas de A, colunas de B, e dimensão de contração, com loads, multiplicações e acumulações explícitas. Esta representação é verbose e obscurece padrões de alto nível. Pior, vincula prematuramente escolhas de implementação: a ordem dos loops determina padrão de acesso à memória, e mudá-la requer reescrita não trivial do código.</p>
<p>Para domínios como machine learning, computação científica, ou processamento de imagens, onde operações em arrays e tensores dominam a computação, esta limitação é severa. Idealmente, queremos representar a operação matemática abstratamente (multiplicação de matrizes), postergando decisões de implementação (ordem de loops, tiling, vectorização) para passes de transformação. Esta separação de “o quê” e “como” é o objetivo do dialeto <em>linalg</em>.</p>
</section>
<section id="dialeto-linalg-modelando-operações-estruturadas" class="level3" data-number="20.6.2">
<h3 data-number="20.6.2" class="anchored" data-anchor-id="dialeto-linalg-modelando-operações-estruturadas"><span class="header-section-number">20.6.2</span> Dialeto Linalg: Modelando Operações Estruturadas</h3>
<p>O dialeto <em>linalg</em> introduz operações que representam computações estruturadas sobre arrays (memrefs) ou tensores. A operação fundamental é <em>linalg</em>.generic, uma abstração poderosa que pode representar virtualmente qualquer padrão de computação structured.</p>
<p>Um <em>linalg</em>.generic especifica três componentes centrais. Primeiro, iterator types descrevem a natureza de cada dimensão de iteração. Um iterator type pode ser parallel (iterações independentes) ou reduction (acumulação através de iterações). Por exemplo, multiplicação de matrizes tem duas dimensões parallel (linhas de saída, colunas de saída) e uma dimensão reduction (dimensão de contração).</p>
<p>Segundo, indexing maps especificam como índices de iteração mapeiam para índices de acessos de memória. Estes mapas são afins, permitindo padrões como broadcast (replicar valores), transpose (permutar dimensões), ou strided access. Por exemplo, na multiplicação de matrizes, o map para A é affine_map&lt;(i, j, k) -&gt; (i, k)&gt; (linha i de A, iterar sobre k), para B é affine_map&lt;(i, j, k) -&gt; (k, j)&gt; (iterar sobre k, coluna j de B), e para C é affine_map&lt;(i, j, k) -&gt; (i, j)&gt; (célula (i, j) de C).</p>
<p>Terceiro, a body region especifica o cálculo por-elemento. Esta region recebe valores carregados (um por operando de entrada, baseado em indexing maps) como block arguments e deve yieldar valores a serem armazenados (um por operando de saída). Para multiplicação de matrizes, o corpo é algo como multiply-add: %c = arith.mulf %a, %b; %result = arith.addf %c_prev, %c; <em>linalg</em>.yield %result.</p>
<p>Esta estrutura é incrivelmente expressiva. A mesma abstração <em>linalg</em>.generic pode representar operações element-wise (como adição de vetores), reduções (como soma de todos elementos), contrações tensoriais complexas, e patterns custom. A chave é que a operação especifica a estrutura matemática, não a implementação. Não há loops explícitos, não há decisão sobre ordem de iteração, não há commitment para layout de memória específico.</p>
<p>Além de <em>linalg</em>.generic, o dialeto define operações nomeadas para padrões comuns. Linalg.matmul encapsula multiplicação de matrizes, <em>linalg</em>.conv convoluções, <em>linalg</em>.fill preenchimento de arrays, etc. Estas operações nomeadas são açúcar sintático sobre <em>linalg</em>.generic: cada uma tem semântica equivalente a um <em>linalg</em>.generic específico. A vantagem é concisão e reconhecimento fácil de padrões comuns para otimizações especializadas.</p>
</section>
<section id="separação-de-interesses-e-portabilidade" class="level3" data-number="20.6.3">
<h3 data-number="20.6.3" class="anchored" data-anchor-id="separação-de-interesses-e-portabilidade"><span class="header-section-number">20.6.3</span> Separação de Interesses e Portabilidade</h3>
<p>O poder do <em>linalg</em> está na separação de interesses. A operação especifica o quê computar, mas não como. Decisões de implementação são responsabilidade de passes de transformação e rebaixamento. Esta separação traz múltiplos benefícios.</p>
<p>Primeiro, portabilidade. A mesma operação <em>linalg</em> pode ser rebaixada para CPU, GPU, ou aceleradores customizados, com passes de rebaixamento escolhendo estratégias apropriadas para cada arquitetura. Para CPU, pode ser rebaixado para loops scf com tiling para localidade de cache. Para GPU, pode ser rebaixado para dialeto gpu com mapeamento para hierarquia de threads. Para TPU, pode ser mapeado para operações customizadas daquele hardware.</p>
<p>Segundo, composabilidade de transformações. Antes de rebaixamento, transformações estruturais podem ser aplicadas à operação <em>linalg</em>. Fusion (fundir múltiplas operações em uma para eliminar armazenamento intermediário), tiling (bloquear para processar chunks menores), padding (adicionar elementos para alinhar dimensões), todas podem ser expressas como reescritas de operações <em>linalg</em>. Estas transformações operam no nível matemático, não requerendo manipulação de loops explícitos.</p>
<p>Terceiro, análise simplificada. Um passe de otimização pode reconhecer <em>linalg</em>.matmul e aplicar estratégias especializadas (como uso de bibliotecas BLAS otimizadas), sem precisar pattern-match três loops aninhados e verificar que implementam multiplicação de matrizes. A abstração torna análise de alto nível trivial.</p>
<p>O dialeto <em>linalg</em> ilustra uma tendência importante em design de compiladores modernos: ascensão a abstrações declarativas. Em vez de programar como executar, especifica-se o que executar, delegando otimização ao compilador. Esta abordagem é especialmente potente para domínios com padrões computacionais recorrentes e diversidade de targets de hardware, características centrais de machine learning e computação científica.</p>
</section>
</section>
<section id="módulo-7-rebaixamento-do-linalg-e-transformações-estruturais" class="level2" data-number="20.7">
<h2 data-number="20.7" class="anchored" data-anchor-id="módulo-7-rebaixamento-do-linalg-e-transformações-estruturais"><span class="header-section-number">20.7</span> Módulo 7: Rebaixamento do Linalg e Transformações Estruturais</h2>
<section id="geração-de-loops-de-especificação-a-implementação" class="level3" data-number="20.7.1">
<h3 data-number="20.7.1" class="anchored" data-anchor-id="geração-de-loops-de-especificação-a-implementação"><span class="header-section-number">20.7.1</span> Geração de Loops: De Especificação a Implementação</h3>
<p>O passe <code>--convert-_linalg_-to-loops</code> realiza uma transformação fundamental: traduz operações <em>linalg</em>.generic (especificações declarativas de computação) em código imperativo com loops explícitos (tipicamente scf.for). Este processo é essencialmente síntese de código a partir de especificação de alto nível.</p>
<p>Para cada operação <em>linalg</em>.generic, o passe analisa os três componentes (iterator types, indexing maps, body) e gera estrutura de loops correspondente. O número de loops aninhados corresponde ao número de dimensões de iteração. A ordem dos loops pode ser escolhida heuristicamente ou especificada por atributo: tipicamente, dimensões parallel são processadas em loops externos, e dimensões reduction em loops internos, mas esta escolha pode ser alterada para otimização.</p>
<p>Para cada iteração dos loops, índices de loop são usados em conjunto com indexing maps para computar índices de acesso à memória. Os mapas afins especificados no <em>linalg</em>.generic são aplicados aos índices de loop para determinar quais elementos de cada operando carregar. O body do <em>linalg</em>.generic é instanciado dentro do loop mais interno, com loads de memref.load fornecendo valores de entrada e stores de memref.store consumindo valores de saída.</p>
<p>O tratamento de dimensões reduction requer atenção especial. Uma dimensão reduction implica acumulação: um valor é inicializado (tipicamente carregado de memória) antes do loop, atualizado em cada iteração através do body, e armazenado após o loop. O passe gera automaticamente esta estrutura: loads de valores acumuladores antes do loop reduction, loop-carried values em scf.for carregando acumulador atualizado através de iterações, e stores finais após conclusão.</p>
<p>O resultado é código imperativo equivalente ao <em>linalg</em>.generic original, mas agora expresso em termos de construções de loop explícitas. Este código está pronto para otimizações subsequentes que operam em nível de loop (como unrolling ou vectorização) ou para rebaixamento adicional para cf e eventualmente código de máquina.</p>
</section>
<section id="transformações-estruturais-tiling-como-exemplo" class="level3" data-number="20.7.2">
<h3 data-number="20.7.2" class="anchored" data-anchor-id="transformações-estruturais-tiling-como-exemplo"><span class="header-section-number">20.7.2</span> Transformações Estruturais: Tiling como Exemplo</h3>
<p>Antes de rebaixamento para loops, operações <em>linalg</em> frequentemente passam por transformações estruturais. Tiling é uma transformação particularmente importante para exploração de hierarquia de memória. A ideia é bloquear loops para processar o cálculo em tiles (chunks) que cabem em níveis específicos de cache, melhorando localidade temporal e espacial.</p>
<p>Para uma operação <em>linalg</em>.generic, tiling envolve dividir cada dimensão de iteração em dois níveis: um outer loop iterando sobre tiles, e um inner loop processando dentro de cada tile. O tamanho de tiles é um parâmetro (especificado como atributo ou default): tiles pequenos cabem em L1 cache, tiles maiores em L2, etc. A escolha de tamanho de tile é crítica para performance e frequentemente determinada por auto-tuning.</p>
<p>A transformação de tiling reescreve o <em>linalg</em>.generic em uma versão tiled: os indexing maps são ajustados para refletir estrutura de dois níveis, e o resultado é frequentemente nested <em>linalg</em>.generic operations ou scf.for wrapping <em>linalg</em>.generic. Após tiling, rebaixamento para loops gera estrutura de loops aninhados com blocking explícito.</p>
<p>Tiling é apenas uma de muitas transformações estruturais aplicáveis em nível <em>linalg</em>. Fusion combina múltiplas operações em uma para eliminar armazenamento intermediário: se C = A + B e D = C * E, fusion pode gerar diretamente D = (A + B) * E, eliminando materialização de C. Interchange troca ordem de dimensões de iteração, alterando padrão de acesso à memória. Padding adiciona elementos para alinhar dimensões a múltiplos convenientes para vectorização.</p>
<p>Todas estas transformações operam no nível de abstração de <em>linalg</em>, manipulando operações estruturadas. Após transformações, rebaixamento para loops gera código otimizado automaticamente. Este pipeline (transformações estruturais → rebaixamento) implementa separação de interesses: estratégia de alto nível é decidida em nível <em>linalg</em>, detalhes de implementação emergem do rebaixamento.</p>
</section>
<section id="implicações-para-portabilidade-e-auto-tuning" class="level3" data-number="20.7.3">
<h3 data-number="20.7.3" class="anchored" data-anchor-id="implicações-para-portabilidade-e-auto-tuning"><span class="header-section-number">20.7.3</span> Implicações para Portabilidade e Auto-Tuning</h3>
<p>A arquitetura <em>linalg</em> tem implicações profundas para portabilidade entre arquiteturas. A mesma operação <em>linalg</em> pode ser transformada e rebaixada de formas radicalmente diferentes para diferentes targets. Para CPU, estratégia típica é tiling para cache locality seguido de vectorização. Para GPU, tiling para mapeamento a hierarquia de threads (blocks e threads), frequentemente sem vectorização explícita. Para aceleradores de machine learning, mapeamento direto para operações tensoriais nativas.</p>
<p>Estas escolhas não são hard-coded no dialeto <em>linalg</em>, mas implementadas em passes de transformação e rebaixamento específicos de target. Um compilador pode ter múltiplos backends: um pipeline <em>linalg</em> → scf → cf → <strong>LLVM</strong> para CPU, outro <em>linalg</em> → gpu → NVVM para NVIDIA GPUs, outro <em>linalg</em> → target-specific-dialect para aceleradores customizados. Todos compartilham representação <em>linalg</em> comum em stages iniciais, divergindo apenas quando target-specific escolhas são necessárias.</p>
<p>Esta arquitetura facilita auto-tuning: um sistema pode gerar múltiplas versões de código (variando tamanhos de tile, ordem de loops, etc.), executar em hardware real, e selecionar a versão mais rápida. O espaço de busca é estruturado por transformações <em>linalg</em>: em vez de explorar todo espaço de programas possíveis, explora-se espaço de transformações aplicáveis a operação <em>linalg</em> específica. Esta restrição torna busca tratável enquanto ainda cobrindo variações importantes.</p>
<p>O dialeto <em>linalg</em> e seu ecossistema de transformações representam maturação de técnicas de compilação polyhedral e otimização de loops, empacotadas em forma acessível e integrada a uma infraestrutura moderna de compiladores. Sua importância cresce à medida que machine learning e computação científica dominam workloads computacionais, e diversidade de hardware exige portabilidade sem sacrificar performance.</p>
</section>
</section>
<section id="módulo-8-alvos-de-aceleração-gpu-e-metaprogramação-drr" class="level2" data-number="20.8">
<h2 data-number="20.8" class="anchored" data-anchor-id="módulo-8-alvos-de-aceleração-gpu-e-metaprogramação-drr"><span class="header-section-number">20.8</span> Módulo 8: Alvos de Aceleração (GPU) e Metaprogramação (DRR)</h2>
<section id="mapeamento-de-gpu-hierarquia-de-execução-em-ir" class="level3" data-number="20.8.1">
<h3 data-number="20.8.1" class="anchored" data-anchor-id="mapeamento-de-gpu-hierarquia-de-execução-em-ir"><span class="header-section-number">20.8.1</span> Mapeamento de GPU: Hierarquia de Execução em IR</h3>
<p>Programação de GPU apresenta desafios únicos devido à arquitetura hierárquica de execução. Uma GPU organiza computação em grids de thread blocks, com cada block contendo múltiplas threads executando SIMT (Single Instruction, Multiple Thread). Esta hierarquia deve ser exposta no IR para permitir geração de código eficiente.</p>
<p>O dialeto gpu do MLIR fornece abstrações para esta hierarquia. A operação gpu.launch especifica dimensões de grid e block, estabelecendo contexto de execução paralela. Dentro da region de gpu.launch, operações como gpu.block_id, gpu.thread_id, e gpu.grid_dim fornecem acesso a identificadores de execução. Código dentro de gpu.launch é conceptualmente executado por todas as threads na configuração especificada, com identificadores determinando comportamento específico de cada thread.</p>
<p>Um aspecto importante é que gpu.launch encapsula kernel: o corpo é código de device (executado na GPU), distinto de código host (executado na CPU). Esta distinção é fundamental porque device code tem restrições (não pode alocar memória arbitrariamente, não pode chamar funções host arbitrárias) e capacidades especiais (acesso a memória compartilhada, sincronização via barreiras).</p>
<p>A operação gpu.func define funções de device que podem ser chamadas de dentro de kernels. Estas funções têm atributo especial marcando-as como device-side e restringindo o que podem fazer. O passe <code>--gpu-kernel-outlining</code> extrai código de gpu.launch para gpu.func separadas, implementando separação explícita entre host e device. Após outlining, host code contém apenas invocações de kernel, enquanto device code está isolado em gpu.func.</p>
</section>
<section id="mapeamento-de-linalg-para-gpu" class="level3" data-number="20.8.2">
<h3 data-number="20.8.2" class="anchored" data-anchor-id="mapeamento-de-linalg-para-gpu"><span class="header-section-number">20.8.2</span> Mapeamento de Linalg para GPU</h3>
<p>Uma aplicação importante do dialeto gpu é como target para rebaixamento de <em>linalg</em>. Operações <em>linalg</em> com dimensões parallel mapeiam naturalmente para execução paralela em GPU. O processo envolve múltiplos passos.</p>
<p>Primeiro, uma operação <em>linalg</em> é analisada para identificar dimensões parallel adequadas para paralelização. Segundo, um passe de transformação reescreve a operação para estrutura explícita de paralelização, tipicamente usando scf.parallel (um variant de scf.for para loops paralelos) ou diretamente injetando operações gpu. Terceiro, passes de mapeamento especificam como dimensões de iteração mapeiam para dimensões de grid e block, balanceando workload entre threads.</p>
<p>Quarto, rebaixamento para dialeto gpu gera operações gpu.launch com configuração apropriada e corpo contendo lógica de computação. Quinto, outlining separa kernel de código host. Finalmente, rebaixamento adicional para dialeto específico de vendor (como NVVM para NVIDIA ou ROCDL para AMD) e então para PTX ou GCN assembly completa o pipeline.</p>
<p>Este pipeline multi-stage permite flexibilidade: diferentes estratégias de mapeamento podem ser experimentadas em nível de <em>linalg</em> ou scf, antes de commitment para representação GPU específica. Auto-tuning pode explorar espaço de configurações de grid/block para otimizar occupancy e minimizar divergência.</p>
</section>
<section id="tablegen-e-drr-metaprogramação-para-passes" class="level3" data-number="20.8.3">
<h3 data-number="20.8.3" class="anchored" data-anchor-id="tablegen-e-drr-metaprogramação-para-passes"><span class="header-section-number">20.8.3</span> TableGen e DRR: Metaprogramação para Passes</h3>
<p>Até aqui, discutimos passes de transformação como se fossem código C++ direto. Na prática, escrever passes manualmente é tedioso e propenso a erros. Matching de padrões no IR, verificação de condições, e geração de IR replacement envolvem boilerplate substancial. Metaprogramação oferece solução: descrever transformações declarativamente, e gerar código de pass automaticamente.</p>
<p>TableGen é um sistema de metaprogramação usado extensivamente em <strong>LLVM</strong> e MLIR. Ele processa arquivos de especificação (.td) escritos em linguagem declarativa e gera código C++. No contexto MLIR, TableGen é usado para definir dialetos (operações, tipos, atributos), mas também para definir regras de reescrita.</p>
<p>DRR (Declarative Rewrite Rules) é um framework construído sobre TableGen para especificar transformações de IR através de padrões. Uma regra DRR consiste em um padrão de matching (pattern) que especifica estrutura de IR a ser reconhecida, e um padrão de replacement que especifica IR a ser gerado quando match ocorre. Opcionalmente, constraints podem especificar condições adicionais para aplicabilidade da regra.</p>
<p>A sintaxe típica de uma regra DRR é:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode llvm code-with-copy"><code class="sourceCode llvm"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>def : Pat</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  (OpA $operand),</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  (OpB $operand)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>&gt;<span class="co">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Esta regra especifica que qualquer instância de OpA deve ser substituída por OpB com mesmo operando. Regras mais complexas podem envolver múltiplas operações, constraints sobre tipos ou valores, e computação de novos valores no replacement.</p>
<p>Por exemplo, a regra de identidade aritmética x + 0 = x seria:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode llvm code-with-copy"><code class="sourceCode llvm"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>def : Pat</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  (arith_AddIOp $x, (arith_ConstantOp <span class="dv">0</span>)),</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  (replaceWithValue $x)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>&gt;<span class="co">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A regra de strength reduction x * 2 = x + x seria:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode llvm code-with-copy"><code class="sourceCode llvm"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>def : Pat</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  (arith_MulIOp $x, (arith_ConstantOp <span class="dv">2</span>)),</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  (arith_AddIOp $x, $x)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>&gt;<span class="co">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>DRR compila estas especificações para código C++ que implementa passes de reescrita. O código gerado manipula estruturas de dados IR, verifica tipos, e aplica transformações corretamente. O desenvolvedor evita escrever este boilerplate, focando na lógica de alto nível da transformação.</p>
</section>
<section id="vantagens-e-limitações-da-metaprogramação" class="level3" data-number="20.8.4">
<h3 data-number="20.8.4" class="anchored" data-anchor-id="vantagens-e-limitações-da-metaprogramação"><span class="header-section-number">20.8.4</span> Vantagens e Limitações da Metaprogramação</h3>
<p>As vantagens de DRR são significativas. Primeiro, produtividade: especificar transformações declarativamente é muito mais rápido que escrever código C++ manualmente. Segundo, corretude: o código gerado é menos propenso a bugs que código manual, pois padrões comuns (como verificação de tipos) são tratados automaticamente. Terceiro, manutenibilidade: regras declarativas são mais fáceis de entender e modificar que código imperativo.</p>
<p>As limitações também existem. Primeiro, expressividade: transformações complexas que requerem análise não-local ou computação elaborada podem ser difíceis ou impossíveis de expressar em DRR, requerendo código C++ manual. Segundo, debugging: quando código gerado tem bugs ou comportamento inesperado, debugging pode ser mais difícil que para código manual. Terceiro, curva de aprendizado: TableGen tem sintaxe própria que requer familiarização.</p>
<p>Na prática, MLIR usa combinação de passes escritos em C++ diretamente e passes gerados via DRR. Passes simples de canonicalização são candidatos ideais para DRR. Passes complexos de transformação estrutural são tipicamente C++ manual, possivelmente usando DRR para sub-partes.</p>
<p>A existência de DRR ilustra maturidade do MLIR: não apenas fornece IR flexível, mas também ferramentas para construir passes sobre essa IR eficientemente. Esta investida em developer experience é crítica para adoção e extensibilidade do sistema.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/frankalcantara\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./19-mlir-sintaxe.html" class="pagination-link" aria-label="**MLIR** 101: Nosso Primeiro Exemplo e Sintaxe Básica">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title"><strong>MLIR</strong> 101: Nosso Primeiro Exemplo e Sintaxe Básica</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./21-mlir-arch.html" class="pagination-link" aria-label="**MLIR: Uma Análise Exaustiva dos Passes e do Abaixamento Multi-Nível na Engenharia Moderna de Compiladores**">
        <span class="nav-page-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title"><strong>MLIR: Uma Análise Exaustiva dos Passes e do Abaixamento Multi-Nível na Engenharia Moderna de Compiladores</strong></span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright © 2025 Frank de Alcantara</p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/frankalcantara/linguagens-formais/edit/main/20-mlir-plano.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/frankalcantara/linguagens-formais/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>