[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RobotZero",
    "section": "",
    "text": "This is a robotic technology research and development project. Our goal is not just to assemble robots. We intend to understand what we are doing and to push the development of automation, simulation, and robotics technologies forward a bit.\nProjects:\n\nLine Follower Robot:\n\nRoboTZeroNano v2024\nLine Follower Simulator\n\n\nAuralFocus:\n\nAudio-based 3D Positioning System\nAuralFocus Simulator",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction RoboTZero</span>"
    ]
  },
  {
    "objectID": "installation-guide.html",
    "href": "installation-guide.html",
    "title": "2  Development Environment Installation Guide",
    "section": "",
    "text": "3 Introduction\nThis guide provides comprehensive instructions for setting up the complete development environment for the RoboTZero project. All instructions are tailored for Ubuntu 24.04 LTS running on WSL2 (Windows Subsystem for Linux) on Windows 11.\nThe RoboTZero project combines:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#installing-wsl2-on-windows-11",
    "href": "installation-guide.html#installing-wsl2-on-windows-11",
    "title": "2  Development Environment Installation Guide",
    "section": "4.1 Installing WSL2 on Windows 11",
    "text": "4.1 Installing WSL2 on Windows 11\nIf you haven’t installed WSL2 yet, follow these steps:\n\n4.1.1 Enable WSL2 (PowerShell as Administrator)\n# Enable WSL feature\ndism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n\n# Enable Virtual Machine Platform\ndism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\n\n# Restart your computer\nAfter restarting, open PowerShell as Administrator again:\n# Set WSL2 as default version\nwsl --set-default-version 2\n\n# Install Ubuntu 24.04\nwsl --install -d Ubuntu-24.04\n\n# Verify installation\nwsl --list --verbose",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#initial-ubuntu-configuration",
    "href": "installation-guide.html#initial-ubuntu-configuration",
    "title": "2  Development Environment Installation Guide",
    "section": "4.2 Initial Ubuntu Configuration",
    "text": "4.2 Initial Ubuntu Configuration\nOpen your Ubuntu terminal from Windows Start Menu:\n# Update package lists\nsudo apt update && sudo apt upgrade -y\n\n# Install essential build tools\nsudo apt install -y build-essential curl wget git vim nano",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#wsl2-performance-optimization",
    "href": "installation-guide.html#wsl2-performance-optimization",
    "title": "2  Development Environment Installation Guide",
    "section": "4.3 WSL2 Performance Optimization",
    "text": "4.3 WSL2 Performance Optimization\nCreate or edit .wslconfig in your Windows user directory (C:\\Users\\YourUsername\\.wslconfig):\n[wsl2]\nmemory=8GB\nprocessors=4\nswap=2GB\nlocalhostForwarding=true\nRestart WSL2 to apply changes:\n# In PowerShell\nwsl --shutdown",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#git-configuration",
    "href": "installation-guide.html#git-configuration",
    "title": "2  Development Environment Installation Guide",
    "section": "5.1 Git Configuration",
    "text": "5.1 Git Configuration\n# Install Git (if not already installed)\nsudo apt install -y git\n\n# Configure your identity\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n\n# Configure default branch name\ngit config --global init.defaultBranch main\n\n# Enable credential helper\ngit config --global credential.helper store\n\n# Improve performance on WSL2\ngit config --global core.filemode false\ngit config --global core.autocrlf input\n\n# Verify configuration\ngit config --list",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#ssh-key-setup-for-github",
    "href": "installation-guide.html#ssh-key-setup-for-github",
    "title": "2  Development Environment Installation Guide",
    "section": "5.2 SSH Key Setup for GitHub",
    "text": "5.2 SSH Key Setup for GitHub\n# Generate SSH key\nssh-keygen -t ed25519 -C \"your.email@example.com\"\n\n# Start SSH agent\neval \"$(ssh-agent -s)\"\n\n# Add key to agent\nssh-add ~/.ssh/id_ed25519\n\n# Display public key (copy this to GitHub)\ncat ~/.ssh/id_ed25519.pub\nAdd the public key to GitHub: 1. Go to GitHub → Settings → SSH and GPG keys 2. Click “New SSH key” 3. Paste your public key and save\nTest the connection:\nssh -T git@github.com",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#visual-studio-code",
    "href": "installation-guide.html#visual-studio-code",
    "title": "2  Development Environment Installation Guide",
    "section": "5.3 Visual Studio Code",
    "text": "5.3 Visual Studio Code\n\n5.3.1 Install VSCode on Windows\nDownload and install from: https://code.visualstudio.com/\n\n\n5.3.2 Install WSL Extension\n\nOpen VSCode on Windows\nInstall “WSL” extension by Microsoft\nPress Ctrl+Shift+P and select “WSL: Connect to WSL”\n\n\n\n5.3.3 Essential Extensions\nInstall these extensions in VSCode (WSL mode):\n# From Ubuntu terminal, open VSCode in WSL\ncode .\nInstall these extensions:\n\nGeneral:\n\nWSL (ms-vscode-remote.remote-wsl)\nGitLens (eamodio.gitlens)\nError Lens (usernamehw.errorlens)\n\nC/C++:\n\nC/C++ (ms-vscode.cpptools)\nC/C++ Extension Pack (ms-vscode.cpptools-extension-pack)\nCMake (twxs.cmake)\nCMake Tools (ms-vscode.cmake-tools)\n\nPlatformIO:\n\nPlatformIO IDE (platformio.platformio-ide)\n\nWeb Development:\n\nSvelte for VS Code (svelte.svelte-vscode)\nESLint (dbaeumer.vscode-eslint)\nPrettier (esbenp.prettier-vscode)\n\nDocumentation:\n\nQuarto (quarto.quarto)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#gcc-and-clang-compilers",
    "href": "installation-guide.html#gcc-and-clang-compilers",
    "title": "2  Development Environment Installation Guide",
    "section": "6.1 GCC and Clang Compilers",
    "text": "6.1 GCC and Clang Compilers\n# Install GCC and G++\nsudo apt install -y gcc g++\n\n# Install Clang and LLVM\nsudo apt install -y clang llvm lld\n\n# Install additional tools\nsudo apt install -y clang-format clang-tidy\n\n# Verify installations\ngcc --version\ng++ --version\nclang --version\nclang++ --version\nExpected output for Ubuntu 24.04: - GCC: 13.x or later - Clang: 18.x or later",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#cmake-build-system",
    "href": "installation-guide.html#cmake-build-system",
    "title": "2  Development Environment Installation Guide",
    "section": "6.2 CMake Build System",
    "text": "6.2 CMake Build System\n# Install CMake\nsudo apt install -y cmake cmake-curses-gui\n\n# Verify installation\ncmake --version\nShould be CMake 3.28 or later.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#additional-c-libraries",
    "href": "installation-guide.html#additional-c-libraries",
    "title": "2  Development Environment Installation Guide",
    "section": "6.3 Additional C++ Libraries",
    "text": "6.3 Additional C++ Libraries\n# Install common development libraries\nsudo apt install -y \\\n    libboost-all-dev \\\n    libeigen3-dev \\\n    pkg-config \\\n    ninja-build\n\n# Verify Eigen installation\ndpkg -L libeigen3-dev | grep eigen3",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#install-node.js-via-nvm",
    "href": "installation-guide.html#install-node.js-via-nvm",
    "title": "2  Development Environment Installation Guide",
    "section": "7.1 Install Node.js via nvm",
    "text": "7.1 Install Node.js via nvm\nUsing nvm (Node Version Manager) allows you to easily switch Node.js versions:\n# Install nvm\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n# Reload shell configuration\nsource ~/.bashrc\n\n# Install Node.js LTS\nnvm install --lts\n\n# Set default version\nnvm alias default node\n\n# Verify installation\nnode --version\nnpm --version\nExpected versions: - Node.js: 20.x LTS - npm: 10.x",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#configure-npm",
    "href": "installation-guide.html#configure-npm",
    "title": "2  Development Environment Installation Guide",
    "section": "7.2 Configure npm",
    "text": "7.2 Configure npm\n# Set global install directory to avoid permission issues\nmkdir -p ~/.npm-global\nnpm config set prefix '~/.npm-global'\n\n# Add to PATH (add this to ~/.bashrc)\necho 'export PATH=~/.npm-global/bin:$PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n\n# Update npm to latest\nnpm install -g npm@latest",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#essential-npm-global-packages",
    "href": "installation-guide.html#essential-npm-global-packages",
    "title": "2  Development Environment Installation Guide",
    "section": "7.3 Essential npm Global Packages",
    "text": "7.3 Essential npm Global Packages\n# Install global tools\nnpm install -g \\\n    vite \\\n    eslint \\\n    prettier \\\n    typescript\n\n# Verify installations\nvite --version\neslint --version\nprettier --version\ntsc --version",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#initialize-svelte-project-test",
    "href": "installation-guide.html#initialize-svelte-project-test",
    "title": "2  Development Environment Installation Guide",
    "section": "8.1 Initialize Svelte Project (Test)",
    "text": "8.1 Initialize Svelte Project (Test)\nLet’s verify Svelte setup by creating a test project:\n# Create test directory\nmkdir -p ~/test-svelte\ncd ~/test-svelte\n\n# Create Svelte project\nnpm create vite@latest my-svelte-app -- --template svelte\n\n# Navigate and install\ncd my-svelte-app\nnpm install\n\n# Test development server\nnpm run dev\nAccess the dev server from Windows browser at http://localhost:5173\n\n\n\n\n\n\nWSL2 Port Forwarding\n\n\n\nWSL2 automatically forwards ports to Windows. You can access the dev server from Windows using localhost.\n\n\nClean up test project:\ncd ~\nrm -rf ~/test-svelte",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#install-emscripten-sdk",
    "href": "installation-guide.html#install-emscripten-sdk",
    "title": "2  Development Environment Installation Guide",
    "section": "9.1 Install Emscripten SDK",
    "text": "9.1 Install Emscripten SDK\n# Create directory for tools\nmkdir -p ~/tools\ncd ~/tools\n\n# Clone Emscripten SDK\ngit clone https://github.com/emscripten-core/emsdk.git\ncd emsdk\n\n# Install latest version\n./emsdk install latest\n\n# Activate latest version\n./emsdk activate latest\n\n# Add to shell configuration\necho 'source ~/tools/emsdk/emsdk_env.sh &gt; /dev/null 2&gt;&1' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n\n# Verify installation\nemcc --version\nem++ --version\nExpected output: Emscripten 3.1.50 or later",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#test-emscripten",
    "href": "installation-guide.html#test-emscripten",
    "title": "2  Development Environment Installation Guide",
    "section": "9.2 Test Emscripten",
    "text": "9.2 Test Emscripten\n# Create test file\ncat &gt; hello.cpp &lt;&lt; 'EOF'\n#include &lt;iostream&gt;\nint main() {\n    std::cout &lt;&lt; \"Hello WebAssembly!\" &lt;&lt; std::endl;\n    return 0;\n}\nEOF\n\n# Compile to WebAssembly\nem++ hello.cpp -o hello.html\n\n# Clean up\nrm hello.cpp hello.html hello.js hello.wasm",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#install-platformio-core-cli",
    "href": "installation-guide.html#install-platformio-core-cli",
    "title": "2  Development Environment Installation Guide",
    "section": "10.1 Install PlatformIO Core (CLI)",
    "text": "10.1 Install PlatformIO Core (CLI)\n# Install Python and pip if not present\nsudo apt install -y python3 python3-pip python3-venv\n\n# Install PlatformIO\npip3 install --user platformio\n\n# Add to PATH\necho 'export PATH=$PATH:~/.local/bin' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n\n# Verify installation\npio --version\nplatformio --version",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#install-platformio-in-vscode",
    "href": "installation-guide.html#install-platformio-in-vscode",
    "title": "2  Development Environment Installation Guide",
    "section": "10.2 Install PlatformIO in VSCode",
    "text": "10.2 Install PlatformIO in VSCode\nThe PlatformIO IDE extension should already be installed (see VSCode extensions section).\nConfigure PlatformIO:\n\nOpen VSCode in WSL\nPress Ctrl+Shift+P\nType “PlatformIO: Home”\nWait for PlatformIO to initialize",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#usb-device-access-in-wsl2",
    "href": "installation-guide.html#usb-device-access-in-wsl2",
    "title": "2  Development Environment Installation Guide",
    "section": "10.3 USB Device Access in WSL2",
    "text": "10.3 USB Device Access in WSL2\nWSL2 requires special configuration to access USB devices (Arduino/ESP32 boards).\n\n10.3.1 Install usbipd on Windows\nDownload and install from: https://github.com/dorssel/usbipd-win/releases\nOr use winget (PowerShell as Administrator):\nwinget install --interactive --exact dorssel.usbipd-win\n\n\n10.3.2 Setup USB Forwarding in WSL2\nIn Ubuntu WSL2:\n# Install USB tools\nsudo apt install -y linux-tools-generic hwdata\nsudo update-alternatives --install /usr/local/bin/usbip usbip /usr/lib/linux-tools/*-generic/usbip 20\n\n# Add user to dialout group (for serial port access)\nsudo usermod -a -G dialout $USER\n\n# Log out and log back in for group changes to take effect\n\n\n10.3.3 Connecting USB Devices\nOn Windows (PowerShell as Administrator):\n# List USB devices\nusbipd list\n\n# Bind a device (replace &lt;BUSID&gt; with your device ID)\nusbipd bind --busid &lt;BUSID&gt;\n\n# Attach to WSL\nusbipd attach --wsl --busid &lt;BUSID&gt;\nIn Ubuntu WSL2:\n# Verify device is visible\nlsusb\n\n# Check serial ports\nls -l /dev/ttyUSB* /dev/ttyACM*\n\n\n\n\n\n\nUSB Device Persistence\n\n\n\nUSB devices must be attached each time you restart WSL2 or reconnect the device.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#test-platformio-installation",
    "href": "installation-guide.html#test-platformio-installation",
    "title": "2  Development Environment Installation Guide",
    "section": "10.4 Test PlatformIO Installation",
    "text": "10.4 Test PlatformIO Installation\n# Create test project\nmkdir -p ~/test-pio\ncd ~/test-pio\n\n# Initialize Arduino Uno project\npio project init --board uno\n\n# Create simple blink program\ncat &gt; src/main.cpp &lt;&lt; 'EOF'\n#include &lt;Arduino.h&gt;\n\nvoid setup() {\n    pinMode(LED_BUILTIN, OUTPUT);\n}\n\nvoid loop() {\n    digitalWrite(LED_BUILTIN, HIGH);\n    delay(1000);\n    digitalWrite(LED_BUILTIN, LOW);\n    delay(1000);\n}\nEOF\n\n# Build project\npio run\n\n# Clean up\ncd ~\nrm -rf ~/test-pio",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#common-platformio-boards",
    "href": "installation-guide.html#common-platformio-boards",
    "title": "2  Development Environment Installation Guide",
    "section": "10.5 Common PlatformIO Boards",
    "text": "10.5 Common PlatformIO Boards\nInstall frameworks for common boards:\n# ESP32\npio platform install espressif32\n\n# Arduino\npio platform install atmelavr\n\n# ESP8266\npio platform install espressif8266\n\n# List installed platforms\npio platform list",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#box2d-physics-engine",
    "href": "installation-guide.html#box2d-physics-engine",
    "title": "2  Development Environment Installation Guide",
    "section": "11.1 Box2D (Physics Engine)",
    "text": "11.1 Box2D (Physics Engine)\nFor the Line Follower Simulator:\n# Install dependencies\nsudo apt install -y libgl1-mesa-dev libx11-dev\n\n# Clone Box2D\ncd ~/tools\ngit clone https://github.com/erincatto/box2d.git\ncd box2d\n\n# Build for native (testing)\nmkdir build-native\ncd build-native\ncmake -DCMAKE_BUILD_TYPE=Release \\\n      -DBOX2D_BUILD_UNIT_TESTS=OFF \\\n      -DBOX2D_BUILD_TESTBED=OFF ..\nmake -j$(nproc)\n\n# The library will be in build-native/src/libbox2d.a\nFor WebAssembly build (when needed):\ncd ~/tools/box2d\nmkdir build-wasm\ncd build-wasm\nemcmake cmake -DCMAKE_BUILD_TYPE=Release \\\n              -DBOX2D_BUILD_UNIT_TESTS=OFF \\\n              -DBOX2D_BUILD_TESTBED=OFF ..\nemmake make -j$(nproc)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#quarto-documentation",
    "href": "installation-guide.html#quarto-documentation",
    "title": "2  Development Environment Installation Guide",
    "section": "11.2 Quarto (Documentation)",
    "text": "11.2 Quarto (Documentation)\nFor rendering documentation and reports:\n# Download and install Quarto\ncd ~/tools\nwget https://github.com/quarto-dev/quarto-cli/releases/download/v1.4.549/quarto-1.4.549-linux-amd64.deb\nsudo dpkg -i quarto-1.4.549-linux-amd64.deb\n\n# Install Quarto dependencies\nsudo apt install -y pandoc\n\n# Verify installation\nquarto --version\n\n# Clean up\nrm quarto-1.4.549-linux-amd64.deb\nTest Quarto:\n# Create test document\nmkdir -p ~/test-quarto\ncd ~/test-quarto\n\ncat &gt; test.qmd &lt;&lt; 'EOF'\n---\ntitle: \"Test Document\"\nformat: html\n---\n\n# Hello Quarto\n\nThis is a test document.\nEOF\n\n# Render to HTML\nquarto render test.qmd\n\n# Clean up\ncd ~\nrm -rf ~/test-quarto",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#clone-repository",
    "href": "installation-guide.html#clone-repository",
    "title": "2  Development Environment Installation Guide",
    "section": "12.1 Clone Repository",
    "text": "12.1 Clone Repository\n# Navigate to workspace\nmkdir -p ~/projects\ncd ~/projects\n\n# Clone repository\ngit clone git@github.com:frankalcantara/RoboTZero.git\ncd RoboTZero",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#setup-line-follower-simulator",
    "href": "installation-guide.html#setup-line-follower-simulator",
    "title": "2  Development Environment Installation Guide",
    "section": "12.2 Setup Line Follower Simulator",
    "text": "12.2 Setup Line Follower Simulator\ncd ~/projects/RoboTZero/LineFollower/simulator\n\n# Install Node.js dependencies\nnpm install\n\n# Download external C++ libraries\ncd cpp/external\n\n# Clone Box2D\ngit clone --depth 1 https://github.com/erincatto/box2d.git\n\n# Clone Eigen\ngit clone --depth 1 https://gitlab.com/libeigen/eigen.git\n\n# Return to simulator root\ncd ../..",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#build-webassembly-module",
    "href": "installation-guide.html#build-webassembly-module",
    "title": "2  Development Environment Installation Guide",
    "section": "12.3 Build WebAssembly Module",
    "text": "12.3 Build WebAssembly Module\n# Ensure Emscripten is activated\nsource ~/tools/emsdk/emsdk_env.sh\n\n# Build Box2D for WASM\ncd cpp/external/box2d\nmkdir -p build\ncd build\nemcmake cmake -DCMAKE_BUILD_TYPE=Release \\\n              -DBOX2D_BUILD_UNIT_TESTS=OFF \\\n              -DBOX2D_BUILD_TESTBED=OFF ..\nemmake make -j$(nproc)\n\n# Return to simulator root\ncd ../../../..\n\n# Build simulator WASM\nnpm run build:wasm",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#run-development-server",
    "href": "installation-guide.html#run-development-server",
    "title": "2  Development Environment Installation Guide",
    "section": "12.4 Run Development Server",
    "text": "12.4 Run Development Server\ncd ~/projects/RoboTZero/LineFollower/simulator\n\n# Start development server\nnpm run dev\nAccess the simulator at http://localhost:3000 from your Windows browser.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#common-issues-and-solutions",
    "href": "installation-guide.html#common-issues-and-solutions",
    "title": "2  Development Environment Installation Guide",
    "section": "13.1 Common Issues and Solutions",
    "text": "13.1 Common Issues and Solutions\n\n13.1.1 WSL2 Network Issues\nIf you can’t access localhost from Windows:\n# Get WSL2 IP address\nip addr show eth0 | grep inet\n\n# Use this IP from Windows browser instead of localhost\n\n\n13.1.2 Permission Issues\n# Fix file permissions\nsudo chown -R $USER:$USER ~/projects\n\n# Fix npm permissions\nsudo chown -R $USER:$USER ~/.npm\n\n\n13.1.3 USB Device Not Detected\n# Check if usbip kernel module is loaded\nlsmod | grep usbip\n\n# If not loaded, install kernel modules\nsudo apt install linux-tools-generic\n\n\n13.1.4 PlatformIO Upload Fails\n# Check serial port permissions\nls -l /dev/ttyUSB0  # or ttyACM0\n\n# Add user to dialout group\nsudo usermod -a -G dialout $USER\n\n# Log out and log back in\n\n\n13.1.5 Emscripten Not Found\n# Manually activate Emscripten\nsource ~/tools/emsdk/emsdk_env.sh\n\n# Verify\nwhich emcc\n\n\n13.1.6 VSCode Can’t Find Compiler\n\nOpen Command Palette (Ctrl+Shift+P)\nType “C/C++: Edit Configurations (UI)”\nSet compiler path: /usr/bin/g++ or /usr/bin/clang++\nSet IntelliSense mode: linux-gcc-x64",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#performance-optimization",
    "href": "installation-guide.html#performance-optimization",
    "title": "2  Development Environment Installation Guide",
    "section": "13.2 Performance Optimization",
    "text": "13.2 Performance Optimization\n\n13.2.1 WSL2 Memory Management\nCreate .wslconfig in Windows user directory:\n[wsl2]\nmemory=8GB\nprocessors=4\nswap=2GB\nlocalhostForwarding=true\nguiApplications=true\n\n\n13.2.2 Faster npm Installs\n# Use faster registry mirror (optional)\nnpm config set registry https://registry.npmmirror.com\n\n# Or stick with default\nnpm config set registry https://registry.npmjs.org/\n\n\n13.2.3 Faster Builds\n# Use all CPU cores for make\necho 'export MAKEFLAGS=\"-j$(nproc)\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#verification-script",
    "href": "installation-guide.html#verification-script",
    "title": "2  Development Environment Installation Guide",
    "section": "14.1 Verification Script",
    "text": "14.1 Verification Script\nSave this script to verify all installations:\ncat &gt; ~/verify-install.sh &lt;&lt; 'EOF'\n#!/bin/bash\n\necho \"=== RoboTZero Environment Verification ===\"\necho\n\n# Function to check command\ncheck_command() {\n    if command -v $1 &&gt; /dev/null; then\n        echo \"✓ $1: $(command -v $1)\"\n        $1 --version 2&gt;&1 | head -n 1\n    else\n        echo \"✗ $1: NOT FOUND\"\n    fi\n    echo\n}\n\n# Check all tools\ncheck_command git\ncheck_command gcc\ncheck_command g++\ncheck_command clang\ncheck_command clang++\ncheck_command cmake\ncheck_command node\ncheck_command npm\ncheck_command emcc\ncheck_command pio\ncheck_command quarto\ncheck_command code\n\necho \"=== Checking Groups ===\"\ngroups | grep dialout && echo \"✓ User in dialout group\" || echo \"✗ User NOT in dialout group\"\necho\n\necho \"=== Checking USB Tools ===\"\ncommand -v usbip &&gt; /dev/null && echo \"✓ usbip installed\" || echo \"✗ usbip NOT installed\"\necho\n\necho \"=== Environment Variables ===\"\necho \"PATH includes npm global: $(echo $PATH | grep -q '.npm-global' && echo '✓' || echo '✗')\"\necho \"PATH includes PlatformIO: $(echo $PATH | grep -q '.local/bin' && echo '✓' || echo '✗')\"\necho\n\necho \"=== Verification Complete ===\"\nEOF\n\nchmod +x ~/verify-install.sh\nRun the verification:\n~/verify-install.sh",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#daily-workflow-commands",
    "href": "installation-guide.html#daily-workflow-commands",
    "title": "2  Development Environment Installation Guide",
    "section": "15.1 Daily Workflow Commands",
    "text": "15.1 Daily Workflow Commands\n# Start WSL2 from Windows\nwsl\n\n# Activate Emscripten (if needed for WASM development)\nsource ~/tools/emsdk/emsdk_env.sh\n\n# Navigate to project\ncd ~/projects/RoboTZero\n\n# Update code\ngit pull\n\n# Start simulator development server\ncd LineFollower/simulator\nnpm run dev\n\n# Open VSCode in WSL\ncode .",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#useful-aliases",
    "href": "installation-guide.html#useful-aliases",
    "title": "2  Development Environment Installation Guide",
    "section": "15.2 Useful Aliases",
    "text": "15.2 Useful Aliases\nAdd these to ~/.bashrc for convenience:\n# Add to ~/.bashrc\ncat &gt;&gt; ~/.bashrc &lt;&lt; 'EOF'\n\n# RoboTZero aliases\nalias robotzero='cd ~/projects/RoboTZero'\nalias sim='cd ~/projects/RoboTZero/LineFollower/simulator'\nalias emsdk-activate='source ~/tools/emsdk/emsdk_env.sh'\nalias pio-update='pio upgrade && pio platform update'\nalias npm-clean='rm -rf node_modules package-lock.json && npm install'\n\n# Git aliases\nalias gs='git status'\nalias gp='git pull'\nalias gc='git commit'\nalias ga='git add'\n\nEOF\n\n# Reload\nsource ~/.bashrc",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#official-documentation",
    "href": "installation-guide.html#official-documentation",
    "title": "2  Development Environment Installation Guide",
    "section": "16.1 Official Documentation",
    "text": "16.1 Official Documentation\n\nWSL2: https://docs.microsoft.com/en-us/windows/wsl/\nUbuntu: https://ubuntu.com/wsl\nNode.js: https://nodejs.org/docs/\nSvelte: https://svelte.dev/docs\nEmscripten: https://emscripten.org/docs/\nPlatformIO: https://docs.platformio.org/\nCMake: https://cmake.org/documentation/\nQuarto: https://quarto.org/docs/",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "installation-guide.html#community-support",
    "href": "installation-guide.html#community-support",
    "title": "2  Development Environment Installation Guide",
    "section": "16.2 Community Support",
    "text": "16.2 Community Support\n\nRoboTZero Issues: https://github.com/frankalcantara/RoboTZero/issues\nStack Overflow: Tag questions with wsl2, platformio, svelte, etc.\nPlatformIO Community: https://community.platformio.org/",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Development Environment Installation Guide</span>"
    ]
  },
  {
    "objectID": "oper.html",
    "href": "oper.html",
    "title": "4  Line Following Robot Operation",
    "section": "",
    "text": "4.1 Operating Procedure",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Line Following Robot Operation</span>"
    ]
  },
  {
    "objectID": "oper.html#operating-procedure",
    "href": "oper.html#operating-procedure",
    "title": "4  Line Following Robot Operation",
    "section": "",
    "text": "4.1.1 Initial Setup\n\nPlace the robot near the course\nPower on the robot\nWait for initial setup delay (600ms)\n\nStatus LED will be on during this period\nMotors will be inactive\n\nAfter delay, LED turns off and robot is ready for calibration\n\n\n\n4.1.2 Calibration Process\n\nPress the start button for first calibration phase\n\nLED will turn on\n\nThe calibration process:\n\nTakes 400 samples from each sensor\n30ms delay between samples (total ~12 seconds)\nEstablishes minimum and maximum values for each sensor\n\nAfter calibration completes:\n\nLED turns off\nRobot waits for second button press\n\n\n\n\n4.1.3 Operation Start\n\nPlace robot on the track\nPress start button again to begin operation\n\nLED turns on\nRobot starts line following operation\n\nInitial operating parameters:\n\nSpeed mode begins at BASE_FAST (115)\nPID control active with default parameters\nNormal operating mode engaged\n\n\n\n\n4.1.4 During Operation\nThe robot recognizes three marker patterns: 1. Finish line marker (both sensors) - Updates lap count - Triggers stop sequence on second detection 2. Speed mode marker (left sensor only) - Toggles between normal and precision mode - In precision mode: SPEED_SLOW - In normal mode: BASE_FAST 3. Intersection marker (both sensors) - Logged but no special action taken\n\n\n4.1.5 Stop Sequence\nThe robot will stop automatically when: 1. Second finish line is detected 2. Stop sequence activates: - Speed reduces to SPEED_BRAKE - After 50ms deceleration - Final stop after 300ms - Motors power off\n\n\n4.1.6 Data Retrieval (Debug Mode Only)\nIf DEBUG_LEVEL &gt; 0: 1. When robot stops, flash memory is marked as ready 2. LED displays transmission pattern: - Alternates between slow blink (1000ms) and fast blink (300ms) - Pattern switches every 3000ms 3. Data can be retrieved through serial interface 4. After successful transmission: - Log ready flag is cleared - LED pattern stops\n\n\n4.1.7 Error Recovery\nIf line is lost: 1. Robot uses last valid position 2. Position is forced to extreme (-100 or 100) based on last direction 3. PID controller attempts to recover 4. Robot continues operation if line is found\n\n\n4.1.8 Operating Modes\nTwo base operating speeds: 1. Normal Mode (BASE_FAST): - Base speed of 115 - Curve speed reduction active - Boost after curves (if not in precision mode)\n\nPrecision Mode:\n\nActivated by left marker\nUses SPEED_SLOW\nDisables boost feature\nMore conservative operation\n\n\nDebug Operating Modes (if DEBUG_LEVEL &gt; 0): 1. Analysis Mode (DEBUG_LEVEL = 1): - 5 laps - Conservative speeds - Full data logging\n\nSpeed Mode (DEBUG_LEVEL = 2):\n\n3 laps\nMaximum performance\nFull data logging",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Line Following Robot Operation</span>"
    ]
  },
  {
    "objectID": "block.html",
    "href": "block.html",
    "title": "5  RobotZero Modules Description",
    "section": "",
    "text": "5.1 Configuration Layer",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>RobotZero Modules Description</span>"
    ]
  },
  {
    "objectID": "block.html#configuration-layer",
    "href": "block.html#configuration-layer",
    "title": "5  RobotZero Modules Description",
    "section": "",
    "text": "5.1.1 config.h\nThe configuration hub of the system, this module defines all crucial parameters including pin assignments, speed settings, and control constants. A notable feature is its use of conditional compilation (#if DEBUG_LEVEL &gt; 0) to ensure zero overhead in normal operation mode, demonstrating our commitment to efficiency.\n\n\n5.1.2 globals.h\nManages global state variables that need to be accessed across different modules. While global variables are generally discouraged, here they serve a crucial role in maintaining real-time performance by avoiding function call overhead for frequently accessed states.\n\n\n5.1.3 debug.h\nImplements a debug message system that stores strings in Flash memory instead of RAM, using PROGMEM for optimal memory usage. This approach ensures that debug capabilities don’t impact the robot’s limited RAM resources.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>RobotZero Modules Description</span>"
    ]
  },
  {
    "objectID": "block.html#hardware-interface-layer",
    "href": "block.html#hardware-interface-layer",
    "title": "5  RobotZero Modules Description",
    "section": "5.2 Hardware Interface Layer",
    "text": "5.2 Hardware Interface Layer\n\n5.2.1 Sensors\nManages six line sensors and two marker sensors through a calibration-based approach. The unique feature here is the weighted average calculation that provides precise positional data. The system maintains both raw and processed values, enabling real-time adjustments while preserving original readings for analysis.\n\n\n5.2.2 MotorsDrivers\nImplements motor control using PWM, with a key feature being its ability to handle both forward and reverse motion through a single interface. The module includes built-in protection against invalid PWM values, ensuring safe operation even under software errors.\n\n\n5.2.3 Peripherals\nHandles external interfaces including button input and LED status indication. Notable is its debounce implementation that maintains responsiveness while ensuring reliable button detection, essential for both operation and calibration phases.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>RobotZero Modules Description</span>"
    ]
  },
  {
    "objectID": "block.html#control-layer",
    "href": "block.html#control-layer",
    "title": "5  RobotZero Modules Description",
    "section": "5.3 Control Layer",
    "text": "5.3 Control Layer",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>RobotZero Modules Description</span>"
    ]
  },
  {
    "objectID": "block.html#debug-layer",
    "href": "block.html#debug-layer",
    "title": "5  RobotZero Modules Description",
    "section": "6.1 Debug Layer",
    "text": "6.1 Debug Layer\n\n6.1.1 Logger\nImplements a logging system using circular buffers to maintain performance. A key feature is its ability to write to flash memory only during straight-line sections, ensuring logging doesn’t interfere with critical control operations.\n\n\n6.1.2 FlashManager\nHandles flash memory operations with built-in error checking and recovery mechanisms. Notable is its page-aligned writing system that maximizes flash memory lifespan while ensuring data integrity.\n\n\n6.1.3 FlashReader\nManages data retrieval through a structured protocol, including checksums for data validation. The module implements a multi-marker system to ensure reliable data transmission even under noisy serial connections.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>RobotZero Modules Description</span>"
    ]
  },
  {
    "objectID": "block.html#main-control",
    "href": "block.html#main-control",
    "title": "5  RobotZero Modules Description",
    "section": "6.2 Main Control",
    "text": "6.2 Main Control\n\n6.2.1 main.cpp\nThe core control loop implementing PID-based line following. A significant feature is its non-blocking setup sequence that maintains system responsiveness during initialization and calibration. The module seamlessly integrates debug features when compiled with DEBUG_LEVEL &gt; 0 while maintaining optimal performance in normal operation.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>RobotZero Modules Description</span>"
    ]
  },
  {
    "objectID": "config_layer.html",
    "href": "config_layer.html",
    "title": "6  Configuration Layer",
    "section": "",
    "text": "6.1 Configuration Values (config.h)\nThe config.h file is structured into logical sections, each handling specific aspects of the robot’s configuration. Let’s examine each section in detail:",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Configuration Layer</span>"
    ]
  },
  {
    "objectID": "config_layer.html#configuration-values-config.h",
    "href": "config_layer.html#configuration-values-config.h",
    "title": "6  Configuration Layer",
    "section": "",
    "text": "6.1.1 Debug Configuration\nThis section controls the debugging features of the system. The DEBUG_LEVEL setting determines the robot’s operating mode and what features are compiled into the final binary.\n// Set to 1 for analysis mode, 2 for speed mode, or 0 for normal operation\n#ifndef DEBUG_LEVEL\n#define DEBUG_LEVEL 0\n#endif\n\n#if DEBUG_LEVEL &gt; 0\n#include \"DataStructures.h\"  // Include debug-related structures\n\n// Debug configuration\nstatic constexpr uint8_t DEBUG_LAPS_MODE1 = 5;    // Analysis mode laps\nstatic constexpr uint8_t DEBUG_LAPS_MODE2 = 3;    // Speed mode laps\n\n// Logging parameters\nstatic constexpr uint16_t SAMPLE_RATE_STRAIGHT = 50;   // Sampling in straight lines\nstatic constexpr uint16_t SAMPLE_RATE_CURVE = 20;      // Sampling in curves\nstatic constexpr uint16_t LOG_BUFFER_SIZE = 64;        // Circular buffer size\n\n// Flash memory parameters\nstatic constexpr uint32_t FLASH_LOG_START = 0x1000;    // Log start address\nstatic constexpr uint16_t FLASH_PAGE_SIZE = 256;       // Flash page size\nstatic constexpr uint32_t FLASH_CONTROL_BYTE = 0x0800; // Control byte location\nstatic constexpr uint8_t FLASH_LOG_READY = 0xAA;       // Log ready indicator\n#endif\nThe debug configuration implements a conditional compilation system that ensures optimal performance in normal operation. When DEBUG_LEVEL is set to 0, all debugging code is completely excluded from the final binary, resulting in no runtime overhead. Setting DEBUG_LEVEL to 1 activates the analysis mode, where the robot operates at moderate speeds and collects comprehensive data about its performance, including position errors, motor speeds, and PID corrections, completing 5 laps for detailed analysis. In speed mode, activated with DEBUG_LEVEL 2, the robot performs 3 laps at maximum speed while still collecting performance data, allowing for optimization of high-speed behaviour. The system adjusts its sampling rate based on track conditions - sampling more frequently in curves where behaviour is more dynamic, and at a lower rate in straight sections to conserve memory. All collected data is stored in a structured format in flash memory, organized to maximize data integrity and facilitate post-run analysis.\nThe flash memory organization is carefully structured to maximize efficiency and reliability. The logging system begins storing data at address 0x1000 (FLASH_LOG_START), providing ample space for system data in lower memory addresses. Each page of flash memory is 256 bytes (FLASH_PAGE_SIZE), allowing efficient writing operations that balance between memory usage and write cycles. A control byte located at address 0x0800 (FLASH_CONTROL_BYTE) serves as a state indicator for the logging system. When this byte contains the value 0xAA (FLASH_LOG_READY), it signals that valid performance data is available for retrieval, ensuring proper synchronization between data logging and retrieval operations.\n\n\n6.1.2 Pin Configuration\nDefines all hardware connections, centralizing pin assignments for easy modification and hardware revision control.\n// Only modify if changing physical robot connections\nstatic const uint8_t PIN_START_BUTTON = 11;      // Start/calibrate button\nstatic const uint8_t PIN_STATUS_LED = 13;        // Status LED\nstatic const uint8_t PIN_MOTOR_LEFT_FWD = 7;     // Left Motor Forward\nstatic const uint8_t PIN_MOTOR_LEFT_REV = 4;     // Left Motor Reverse\nstatic const uint8_t PIN_MOTOR_LEFT_PWM = 3;     // Left Motor Speed\nstatic const uint8_t PIN_MOTOR_RIGHT_FWD = 8;    // Right Motor Forward\nstatic const uint8_t PIN_MOTOR_RIGHT_REV = 9;    // Right Motor Reverse\nstatic const uint8_t PIN_MOTOR_RIGHT_PWM = 10;   // Right Motor Speed\n\n// Sensor pins\nstatic const uint8_t PIN_LINE_LEFT_EDGE = A6;    // Leftmost sensor\nstatic const uint8_t PIN_LINE_LEFT_MID = A5;\nstatic const uint8_t PIN_LINE_CENTER_LEFT = A4;\nstatic const uint8_t PIN_LINE_CENTER_RIGHT = A3;\nstatic const uint8_t PIN_LINE_RIGHT_MID = A2;\nstatic const uint8_t PIN_LINE_RIGHT_EDGE = A1;   // Rightmost sensor\nstatic const uint8_t PIN_MARKER_LEFT = A7;       // Left marker\nstatic const uint8_t PIN_MARKER_RIGHT = A0;      // Right marker\nThe pin configuration employs a systematic approach to hardware interface management. Each pin assignment is thoroughly documented with clear comments indicating its purpose, from motor control signals to sensor inputs, making hardware modifications and debugging straightforward. Related pins are logically grouped together - motor control pins are clustered by function (forward, reverse, and PWM for each motor), while sensor pins are arranged according to their physical layout on the robot (from left edge to right edge). The use of static const declarations for pin assignments not only makes the code more readable but also allows the compiler to optimize memory usage by storing these values in program memory rather than RAM. This approach maintains flexibility for hardware modifications while ensuring efficient runtime performance, as these values are resolved at compile time rather than being calculated during program execution.\n\n\n6.1.3 Speed Parameters\nDefines the various speed levels used by the robot, providing a comprehensive speed control system.\n// Base speeds - do not modify without thorough testing\nstatic constexpr uint8_t SPEED_STOP = 0;       // Stopped\nstatic constexpr uint8_t SPEED_STARTUP = 80;   // Initial movement\nstatic constexpr uint8_t SPEED_TURN = 100;     // Turn speed\nstatic constexpr uint8_t SPEED_BRAKE = 120;    // Braking speed\nstatic constexpr uint8_t SPEED_CRUISE = 140;   // Medium speed\nstatic constexpr uint8_t SPEED_SLOW = 160;     // Precision mode\nstatic constexpr uint8_t SPEED_FAST = 180;     // High speed\nstatic constexpr uint8_t SPEED_BOOST = 200;    // Boost speed\nstatic constexpr uint8_t SPEED_MAX = 220;      // Maximum speed\n\n// Speed control parameters\nstatic constexpr uint8_t ACCELERATION_STEP = 25;   // Speed increase step\nstatic constexpr uint8_t BRAKE_STEP = 60;         // Speed decrease step\nstatic constexpr uint8_t TURN_SPEED = 120;        // Curve speed\nstatic constexpr uint8_t TURN_THRESHOLD = 45;     // Curve detection\nstatic constexpr uint8_t STRAIGHT_THRESHOLD = 20;  // Straight line detection\nstatic constexpr uint8_t BOOST_DURATION = 10;     // Boost time\nstatic constexpr uint8_t BOOST_INCREMENT = 20;    // Boost step\nThese speed constants and control parameters are extensively used throughout the codebase. The CourseMarkers class uses them to determine appropriate speeds for different track sections, with TURN_THRESHOLD and STRAIGHT_THRESHOLD helping identify track geometry. In the main control loop, these values drive the PID controller’s response, with ACCELERATION_STEP and BRAKE_STEP ensuring smooth speed transitions. When DEBUG_LEVEL is greater than 0, the ProfileManager modifies these base values according to the current operating mode, allowing for different performance profiles while maintaining the same core control logic.\n\n\n6.1.4 Control Parameters\nDefines the PID controller and sensor processing parameters.\n// PID Control Parameters\nstatic constexpr float K_PROPORTIONAL_DEFAULT = 5.0f;\nstatic constexpr float K_DERIVATIVE_DEFAULT = 600.0f;\nstatic constexpr float FILTER_COEFFICIENT_DEFAULT = 0.6f;\n\n// Sensor Parameters\nstatic const uint8_t NUM_SENSORES = 6;\nstatic constexpr int16_t SENSOR_MAX_VALUE = 1023;\nstatic constexpr int16_t SENSOR_MIN_VALUE = 0;\nstatic constexpr int16_t SENSOR_THRESHOLD = 120;\n\n// Sensor Weights\nstatic constexpr float SENSOR_WEIGHT_S1 = -2.5f;  // Far left\nstatic constexpr float SENSOR_WEIGHT_S2 = -1.2f;  // Left\nstatic constexpr float SENSOR_WEIGHT_S3 = -0.6f;  // Center-left\nstatic constexpr float SENSOR_WEIGHT_S4 = 0.6f;   // Center-right\nstatic constexpr float SENSOR_WEIGHT_S5 = 1.2f;   // Right\nstatic constexpr float SENSOR_WEIGHT_S6 = 2.5f;   // Far right\nThe control system parameters represent the core of the robot’s line-following behaviour. The PID controller uses carefully tuned constants, with a proportional gain (K_PROPORTIONAL_DEFAULT) of 5.0 providing immediate response to position errors, while the high derivative gain (K_DERIVATIVE_DEFAULT) of 600.0 helps predict and dampen oscillations. A filter coefficient of 0.6 balances between noise reduction and response time in the derivative calculation.\nThe sensor array consists of six sensors (NUM_SENSORES), each providing analog readings from 0 to 1023 (SENSOR_MIN_VALUE to SENSOR_MAX_VALUE). A threshold value of 120 helps distinguish between line and background surface conditions. The sensor weights are particularly crucial, implementing a distributed sensing system where outer sensors (±2.5) have greater influence than inner ones (±0.6), creating a non-linear response that enhances stability in straight lines while maintaining sensitivity to curves. These weights are asymmetrical around the center point, allowing the robot to detect and respond to position changes with increasing urgency as it deviates further from the line. When processed together in the main control loop, these parameters enable the robot to maintain precise line following while adapting to various track conditions and geometries.\n\n\n6.1.5 Timing Parameters\nThe timing parameters control various time-dependent aspects of the robot’s operation, each carefully tuned for optimal performance:\n// Delays and Timings\nstatic const uint16_t SETUP_DELAY = 600;           // Initial setup\nstatic const uint16_t CALIBRATION_SAMPLES = 400;   // Calibration precision\nstatic const uint8_t CALIBRATION_DELAY = 30;       // Sample interval\nstatic const uint16_t STOP_DELAY = 300;            // Final stop timing\nstatic const uint16_t DEBOUNCE_DELAY = 50;         // Button debounce\nstatic constexpr uint16_t MARKER_READ_INTERVAL = 2; // Marker reading interval\nEach timing parameter serves a specific purpose in the system:\n\nSETUP_DELAY (600ms): Allows system stabilization after power-up\nCALIBRATION_SAMPLES (400) and CALIBRATION_DELAY (30ms): Controls sensor calibration timing\nSTOP_DELAY (300ms): Controls gradual deceleration sequence\nDEBOUNCE_DELAY (50ms): Ensures reliable button operation\nMARKER_READ_INTERVAL (2ms): Controls the frequency of marker sensor readings\n\nThe MARKER_READ_INTERVAL parameter is particularly crucial for the CourseMarkers system. It ensures consistent and efficient marker detection by establishing a fixed interval between marker sensor readings. This 2ms interval was chosen to balance between: Detection reliability (frequent enough to not miss markers); Processing efficiency (not reading unnecessarily often) and System responsiveness (minimal delay in marker detection).",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Configuration Layer</span>"
    ]
  },
  {
    "objectID": "config_layer.html#global-variables-management-globals.h",
    "href": "config_layer.html#global-variables-management-globals.h",
    "title": "6  Configuration Layer",
    "section": "6.2 Global Variables Management (globals.h)",
    "text": "6.2 Global Variables Management (globals.h)\nThe globals.h file represents a strategic decision in RobotZero’s architecture, implementing a carefully selected set of global variables that require system-wide access. While global variables are generally discouraged in software development, their use here is justified by the real-time nature of the system and the Arduino Nano’s (Arduino 2024) limited resources.\n#ifndef GLOBALS_H\n#define GLOBALS_H\n\n// Global control variables\nextern int currentSpeed;             // Base speed\nextern bool isRobotStopped;          // Robot stopped state\nextern bool isStopSequenceActive;    // Stopping sequence active\nextern int lapCount;                 // End marker counter\nextern bool isPrecisionMode;         // Slow mode active\n\n#endif // GLOBALS_H\nThe currentSpeed variable serves as the base speed reference for the entire system. It is modified by various components including the CourseMarkers class during turns, the main control loop during PID corrections, and the ProfileManager when operating in debug modes. By maintaining this as a global variable, we avoid the overhead of function calls and parameter passing in time-critical control loops.\nThe robot’s state is tracked through three critical boolean flags. isRobotStopped indicates when the robot has completed its run or encountered a stop condition, allowing all components to safely cease operations. isStopSequenceActive manages the controlled deceleration process, triggered when the robot reaches its final lap, ensuring smooth and precise stopping. The isPrecisionMode flag enables the system to switch between normal and precision operation modes, affecting speed calculations and control parameters throughout the system.\nThe lapCount variable keeps track of completed laps, crucial for both normal operation and debugging modes. In normal mode, it triggers the stop sequence after one lap, while in debug modes (controlled by DEBUG_LEVEL), it follows the specified number of laps (5 for analysis mode, 3 for speed mode).\nAll these variables are declared as external (extern) in the header file, with their actual definitions residing in main.cpp. This approach maintains proper encapsulation while allowing necessary access across the system. Each variable is initialized at system startup and modified only in specific, well-defined circumstances, ensuring predictable behaviour despite their global nature.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Configuration Layer</span>"
    ]
  },
  {
    "objectID": "config_layer.html#debug-system-configuration-debug.h",
    "href": "config_layer.html#debug-system-configuration-debug.h",
    "title": "6  Configuration Layer",
    "section": "6.3 Debug System Configuration (debug.h)",
    "text": "6.3 Debug System Configuration (debug.h)\nThe debug.h file implements an efficient debugging system that provides comprehensive diagnostic information without compromising the robot’s performance. The system’s most notable feature is its use of Flash memory for string storage, preserving valuable RAM for critical operations.\n#ifndef DEBUG_H\n#define DEBUG_H\n\n#include \"config.h\"\n#include &lt;avr/pgmspace.h&gt;\n\n// Store debug messages in Flash memory instead of RAM\nconst char DEBUG_BASE[] PROGMEM = \"Base: \";\nconst char DEBUG_ERROR[] PROGMEM = \" Error: \";\nconst char DEBUG_CORRECTION[] PROGMEM = \" Correction: \";\nconst char DEBUG_GEOMETRY[] PROGMEM = \"Geometry: \";\nconst char DEBUG_RIGHT_MARKER[] PROGMEM = \"rightMarkerDetected: \";\nconst char DEBUG_LEFT_MARKER[] PROGMEM = \" leftMarkerDetected: \";\nconst char DEBUG_A0[] PROGMEM = \" A0: \";\nconst char DEBUG_A7[] PROGMEM = \" A7: \";\nconst char DEBUG_SLOW_MODE[] PROGMEM = \"Slow mode activated\";\nconst char DEBUG_FAST_MODE[] PROGMEM = \"Fast mode activated\";\nconst char DEBUG_INTERSECTION[] PROGMEM = \"Intersection detected\";\nconst char DEBUG_SETUP_START[] PROGMEM = \"Starting setup\";\nconst char DEBUG_SETUP_COMPLETE[] PROGMEM = \"Setup completed\";\nThese string constants are stored in program memory using the PROGMEM attribute. This approach saves precious RAM space on the Arduino Nano (Arduino 2024), which only has 2KB available. To facilitate reading these stored strings, the system implements a helper function:\n// Helper function to print strings from Flash\ninline void debugPrintFlash(const char* str) {\n    char c;\n    while ((c = pgm_read_byte(str++))) {\n        Serial.write(c);\n    }\n}\nThe system provides a set of debugging macros that are completely eliminated when debugging is disabled. These macros are defined based on the DEBUG_LEVEL configuration:\n// Debug macros - only active when DEBUG_LEVEL &gt; 0\n#if DEBUG_LEVEL &gt; 0\n#define DEBUG_BEGIN(x) Serial.begin(x)\n#define DEBUG_PRINT(x) debugPrintFlash(x)\n#define DEBUG_PRINTLN(x) do { debugPrintFlash(x); Serial.println(); } while(0)\n#define DEBUG_PRINT_VAL(x) Serial.print(x)\n#define DEBUG_PRINTLN_VAL(x) Serial.println(x)\n#else\n#define DEBUG_BEGIN(x)\n#define DEBUG_PRINT(x)\n#define DEBUG_PRINTLN(x)\n#define DEBUG_PRINT_VAL(x)\n#define DEBUG_PRINTLN_VAL(x)\n#endif\nWhen DEBUG_LEVEL is 0, these macros expand to nothing, ensuring zero overhead in the compiled code. When debugging is enabled, they provide different printing capabilities: DEBUG_PRINT and DEBUG_PRINTLN handle Flash-stored strings, while DEBUG_PRINT_VAL and DEBUG_PRINTLN_VAL handle direct value output. The do-while construct in DEBUG_PRINTLN ensures proper behaviour when the macro is used in if-else statements.\nIn practice, these macros are used throughout the codebase to provide diagnostic information. For example, during sensor readings:\nDEBUG_PRINT(\"rightMarkerDetected: \");\nDEBUG_PRINT_VAL(rightMarkerDetected);\nDEBUG_PRINT(\" leftMarkerDetected: \");\nDEBUG_PRINT_VAL(leftMarkerDetected);\nDEBUG_PRINTLN(\"\");\nThe system outputs debug information at 115200 baud when enabled, allowing real-time monitoring of the robot’s behaviour while maintaining efficient execution.\n\n\n\n\nArduino. 2024. “Arduino Nano (@ArduinoNano).” 2024. https://docs.arduino.cc/hardware/nano/.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Configuration Layer</span>"
    ]
  },
  {
    "objectID": "control_layer.html",
    "href": "control_layer.html",
    "title": "7  Control Layer Implementation",
    "section": "",
    "text": "8 CourseMarkers Implementation\nThe CourseMarkers class represents a control component implementing track feature detection and robot behaviour management through an optimized state-based approach. This implementation focuses on efficient timing control, reliable marker detection, and seamless integration with both the debug system and main control loop.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Control Layer Implementation</span>"
    ]
  },
  {
    "objectID": "control_layer.html#core-architecture",
    "href": "control_layer.html#core-architecture",
    "title": "7  Control Layer Implementation",
    "section": "8.1 Core Architecture",
    "text": "8.1 Core Architecture\nclass CourseMarkers {\nprivate:\n    // Timing control\n    static uint32_t lastReadTime;\n    static const uint16_t MARKER_READ_INTERVAL = 2;  // 2ms read interval\n    \n    // State tracking\n    static int speed;\n    static int lastMarkerState;\n    static int previousMarkerState;\n    static int oldMarkerState;\n    static int currentMarkerState;\n    static int16_t leftMarkerDetected;   \n    static int16_t rightMarkerDetected;  \n\n    // Motion control\n    static bool isTurning;\n    static bool isExitingTurn;\n    static uint8_t boostCountdown;\n\n    // Timing control\n    static Timer stopTimer;\n    static Timer slowdownTimer;\n};\nThe implementation utilizes a set of static members to maintain system state while minimizing memory usage. Key innovations include:\n\nTime-Controlled Operation: The system implements a precise timing mechanism that regulates marker reading frequency:\nvoid readCourseMarkers() {\n    uint32_t currentTime = millis();\n    if (currentTime - lastReadTime &lt; MARKER_READ_INTERVAL) {\n        return;\n    }\n    lastReadTime = currentTime;\n\n    // Optimized marker reading\n    bool leftDetected = analogRead(PIN_MARKER_LEFT) &lt;= MARKER_DETECTION_THRESHOLD;\n    bool rightDetected = analogRead(PIN_MARKER_RIGHT) &lt;= MARKER_DETECTION_THRESHOLD;\n    currentMarkerState = (leftDetected &lt;&lt; 1) | rightDetected;\n\n    digitalWrite(PIN_STATUS_LED, leftDetected || rightDetected);\n}\nThis time-controlled approach ensures consistent sampling intervals while preventing unnecessary processor load. The 2ms interval was chosen based on empirical testing to balance between reliable detection and system performance.\nState Machine Implementation: The system maintains a three-level state history (current, previous, and old) enabling pattern recognition:\nswitch (currentMarkerState) {\ncase 0: // No markers\n    if (lastMarkerState == 2 && previousMarkerState == 0) {\n        handleFinishLine();\n    }\n    else if (lastMarkerState == 1 && previousMarkerState == 0) {\n        handleSpeedMode();\n    }\n    else if (lastMarkerState == 3 || previousMarkerState == 3 || \n             oldMarkerState == 3) {\n        handleIntersection();\n    }\n    break;\n}\n\nThe state machine processes four distinct states: - State 0: No markers detected; - State 1: Left marker only; - State 2: Right marker only; - State 3: Both markers detected.\n\nSpeed Control System: Implements an optimized decision tree for rapid response:\nint CourseMarkers::speedControl(int error) {\n    // Early curve detection\n    bool curve_detected = abs(error) &gt; TURN_THRESHOLD;\n    if (curve_detected) {\n        isTurning = true;\n        isExitingTurn = false;\n        return TURN_SPEED;\n    }\n\n    bool straight_detected = abs(error) &lt; STRAIGHT_THRESHOLD;\n    int target_speed;\n\n    if (straight_detected) {\n        if (isTurning) {\n            isExitingTurn = true;\n            boostCountdown = BOOST_DURATION;\n        }\n        isTurning = false;\n        target_speed = isPrecisionMode ? SPEED_SLOW : BASE_FAST;\n    }\n    else {\n        target_speed = map(abs(error),\n            STRAIGHT_THRESHOLD,\n            TURN_THRESHOLD,\n            (isPrecisionMode ? SPEED_SLOW : BASE_FAST),\n            TURN_SPEED);\n    }\n\n    // Boost control\n    if (isExitingTurn && boostCountdown &gt; 0 && !isPrecisionMode) {\n        target_speed = min(255, target_speed + BOOST_INCREMENT);\n        boostCountdown--;\n    }\n\n    // Speed adjustment\n    int step = (target_speed &gt; currentSpeed) ? ACCELERATION_STEP : BRAKE_STEP;\n    if (abs(target_speed - currentSpeed) &lt;= step) {\n        currentSpeed = target_speed;\n    }\n    else {\n        currentSpeed += (target_speed &gt; currentSpeed) ? step : -step;\n    }\n\n    return constrain(currentSpeed, TURN_SPEED, \n                    (isPrecisionMode ? SPEED_SLOW : BASE_FAST));\n}\nDebug Integration: When DEBUG_LEVEL &gt; 0, the system integrates with the logging framework:\nvoid handleFinishLine() {\n    lapCount++;\n    if (lapCount == 2 && !isStopSequenceActive) {\n        isStopSequenceActive = true;\n        slowdownTimer.Start(50);\n        stopTimer.Start(STOP_DELAY);\n#if DEBUG_LEVEL &gt; 0\n        FlashManager::setLogReady();\n#endif\n    }\n}\nEvent Handling: The system implements specialized handlers for different track features:\n\nhandleFinishLine(): Manages lap counting and stop sequence;\nhandleSpeedMode(): Controls precision/speed mode transitions;\nhandleIntersection(): Logs intersection detection.\n\n\n\n8.1.1 State Management\nThe state management system operates through a decision tree (Figure 1), processing marker states in the processMarkerSignals method. The decision process begins with a read operation that captures the current state of both markers, encoding them into a single value through binary manipulation: the right marker contributes the least significant bit (1), while the left marker sets the second bit (2), resulting in four possible states (0: no markers, 1: left only, 2: right only, 3: both markers).\n\n\n\nCourse Markers, decision tree diagram.\n\n\nBefore entering the main decision logic, the system performs a critical optimization check: if the current state matches the last state (lastMarkerState == currentMarkerState), the method returns immediately, preventing unnecessary processing cycles. This early-return mechanism significantly reduces CPU load during steady-state operation when no markers are being detected.\nUpon detecting a state change, the system enters its primary decision sequence. The root decision node examines the current state, with special emphasis on the ‘no markers’ state (0). When in state 0, the system traverses a carefully ordered sequence of pattern checks, each designed to identify specific track features through state history analysis. The sequence is deliberately ordered by priority: finish line detection takes precedence, followed by speed mode transitions, and finally intersection detection.\nThe finish line check looks for a specific pattern: a right marker only (state 2) followed by no markers, with the previous state also being no markers (lastMarkerState == 2 && previousMarkerState == 0). This three-state sequence definitively identifies the finish line pattern while rejecting spurious signals. When detected, handleFinishLine() executes, incrementing the lap counter and potentially initiating the stopping sequence.\nIf the finish line pattern isn’t matched, the system checks for speed mode transitions by looking for a left marker only (state 1) followed by a history of no markers (previousMarkerState == 0). This pattern triggers a complete mode transition through handleSpeedMode(), which orchestrates a comprehensive state reset. The speed mode handler not only toggles between precision and normal operation but also ensures a clean transition by resetting all motion-related states:\nvoid handleSpeedMode() {\n    isPrecisionMode = !isPrecisionMode;\n    currentSpeed = isPrecisionMode ? SPEED_SLOW : BASE_FAST;\n    isTurning = false;\n    isExitingTurn = false;\n    boostCountdown = 0;\n}\nThe final check in the decision sequence examines whether any of the three previous states indicated both markers were detected (state 3). This more permissive check allows for intersection detection regardless of the exact sequence of marker readings, accommodating various approach angles and speeds. The handleIntersection() call logs the event but maintains current robot behaviour, as intersections don’t require specific responses in the current implementation.\nAfter processing through the decision tree, the system executes its state history update, shifting each state one position in the history chain (oldMarkerState = previousMarkerState; previousMarkerState = lastMarkerState; lastMarkerState = currentMarkerState). This shift operation maintains the continuous state history required for pattern detection while minimizing memory usage through reuse of existing variables.\nThe process concludes with a check of the stopping sequence flags. When active, the stop sequence implements a two-phase deceleration: first reducing speed to SPEED_BRAKE if the slowdown timer hasn’t expired, then bringing the robot to a complete stop once the stop timer completes. This gradual stopping process ensures smooth deceleration while maintaining control throughout the stopping sequence.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Control Layer Implementation</span>"
    ]
  },
  {
    "objectID": "control_layer.html#integration-with-debug-layer",
    "href": "control_layer.html#integration-with-debug-layer",
    "title": "7  Control Layer Implementation",
    "section": "8.2 Integration with Debug Layer",
    "text": "8.2 Integration with Debug Layer\nWhen operating in debug mode (DEBUG_LEVEL &gt; 0), the system provides comprehensive data collection:\n\nEvent Logging:\n\nState transitions\nSpeed mode changes\nIntersection detections\nFinish line crossings\n\nPerformance Monitoring:\n\nSpeed adjustments\nTurn detection\nBoost activation\n\nStop Sequence Management:\nif (isStopSequenceActive && !isRobotStopped) {\n    if (!slowdownTimer.Expired() && currentSpeed &gt; SPEED_BRAKE) {\n        currentSpeed = SPEED_BRAKE;\n    }\n    else if (stopTimer.Expired()) {\n        currentSpeed = 0;\n        MotorDriver::setMotorsPower(0, 0);\n        isRobotStopped = true;\n    }\n}",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Control Layer Implementation</span>"
    ]
  },
  {
    "objectID": "control_layer.html#timing-considerations",
    "href": "control_layer.html#timing-considerations",
    "title": "7  Control Layer Implementation",
    "section": "8.3 Timing Considerations",
    "text": "8.3 Timing Considerations\nThe timing system implementation represents a critical aspect of RobotZero’s control architecture, orchestrating multiple time-sensitive operations through carefully calibrated intervals. At its core, the marker detection system operates on a fixed 2ms sampling interval, implemented through a time-difference check at the start of each reading cycle. This precise timing ensures consistent marker detection while preventing excessive sensor polling that could impact system performance. The sampling rate was determined through empirical testing to balance between reliable detection and system overhead.\nWhen the robot initiates its stopping sequence, the system employs a two-phase timing approach. Initially, a 50ms slowdown period allows for controlled deceleration to SPEED_BRAKE, providing a smooth transition from full speed. After this initial brake phase, a longer STOP_DELAY interval guides the robot to a complete stop, preventing abrupt movements that could affect positioning accuracy. These timing values work in concert with the speed adjustment system, which uses `ACCELERATION_STEP` and `BRAKE_STEP` to control velocity changes. The step values create a gradual acceleration and deceleration profile, protecting the motors while maintaining precise control over the robot’s movement.\nPost-curve speed management introduces another timing element through the boost system. When exiting a curve, the boostCountdown timer activates for a configurable duration (`BOOST_DURATION`), during which the robot can temporarily exceed its normal speed limits. This boost phase is carefully timed to maximize straight-line performance while ensuring the robot maintains stability as it transitions from curved to straight sections. The timing parameters across these systems are interdependent; for example, the marker reading interval must be fast enough to detect course features even at maximum boost speed, while the acceleration steps must be calibrated to work effectively within the boost duration window.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Control Layer Implementation</span>"
    ]
  },
  {
    "objectID": "control_layer.html#profilemanager-implementation",
    "href": "control_layer.html#profilemanager-implementation",
    "title": "7  Control Layer Implementation",
    "section": "8.4 ProfileManager Implementation",
    "text": "8.4 ProfileManager Implementation\nThe ProfileManager serves as RobotZero’s configuration system for different operating modes, providing two distinct profiles: one optimized for analysis and another for high-speed performance. This implementation is entirely conditional, only compiled when DEBUG_LEVEL is greater than 0, ensuring zero overhead during normal operation.\nclass ProfileManager {\npublic:\n    // Initialize profile manager\n    static void initialize(DebugMode mode);\n\n    // Get current debug mode\n    static DebugMode getCurrentMode();\n\n    // Get speed value based on original speed constant\n    static uint8_t getSpeedValue(uint8_t defaultSpeed);\n\n    // Get PID parameters\n    static float getKP(float defaultValue);\n    static float getKD(float defaultValue);\n    static float getFilterCoefficient(float defaultValue);\n\n    // Get acceleration parameters\n    static uint8_t getAccelerationStep();\n    static uint8_t getBrakeStep();\n    static uint8_t getTurnSpeed();\n    static uint8_t getTurnThreshold();\n    static uint8_t getStraightThreshold();\n    static uint8_t getBoostDuration();\n    static uint8_t getBoostIncrement();\n\nprivate:\n    static DebugMode currentMode;\n    static const SpeedProfile* activeProfile;\n\n    static const SpeedProfile ANALYSIS_PROFILE;\n    static const SpeedProfile SPEED_PROFILE;\n\n    static void setActiveProfile(DebugMode mode);\n    static uint8_t validateSpeed(uint8_t speed);\n};\nThe system is built around two predefined profiles, each optimized for specific purposes:\nconst SpeedProfile ProfileManager::ANALYSIS_PROFILE = {\n    // Speed settings - Conservative for analysis\n    .speedStop = 0,\n    .speedStartup = 60,    // Slower startup\n    .speedTurn = 80,       // Careful turns\n    .speedBrake = 90,      // Gentle braking\n    .speedCruise = 100,    // Moderate cruising\n    .speedSlow = 120,      // Moderate slow speed\n    .speedFast = 140,      // Moderate fast speed\n    .speedBoost = 160,     // Moderate boost\n    .speedMax = 180,       // Limited top speed\n\n    // Control parameters - Smooth operation\n    .accelerationStep = 15, // Gentle acceleration\n    .brakeStep = 40,       // Moderate braking\n    .turnSpeed = 80,       // Conservative turns\n    .turnThreshold = 50,   // Earlier turn detection\n    .straightThreshold = 25, // Stricter straight detection\n    .boostDuration = 8,    // Short boost\n    .boostIncrement = 15,  // Gentle boost\n\n    // PID parameters - Stable control\n    .kProportional = 4.0f,\n    .kDerivative = 500.0f,\n    .filterCoefficient = 0.5f\n};\n\nconst SpeedProfile ProfileManager::SPEED_PROFILE = {\n    // Speed settings - Aggressive for performance\n    .speedStop = 0,\n    .speedStartup = 100,   // Quick startup\n    .speedTurn = 120,      // Fast turns\n    .speedBrake = 140,     // Strong braking\n    .speedCruise = 160,    // Fast cruising\n    .speedSlow = 180,      // Fast slow mode\n    .speedFast = 200,      // High speed\n    .speedBoost = 220,     // Strong boost\n    .speedMax = 255,       // Maximum speed\n\n    // Control parameters - Performance focused\n    .accelerationStep = 35, // Quick acceleration\n    .brakeStep = 70,       // Strong braking\n    .turnSpeed = 140,      // Fast turns\n    .turnThreshold = 40,   // Later turn detection\n    .straightThreshold = 15, // Quicker straight detection\n    .boostDuration = 12,   // Longer boost\n    .boostIncrement = 25,  // Strong boost\n\n    // PID parameters - Aggressive control\n    .kProportional = 6.0f,\n    .kDerivative = 700.0f,\n    .filterCoefficient = 0.7f\n};\n\nImplementation Note:\nTODO: These variables should be transferred to macros or constexpr’s in the configuration layer, maintaining the system’s design principles of compile-time optimization and centralized configuration.\n\nThe translation between default values and profile-specific values is handled through the getSpeedValue method:\nuint8_t ProfileManager::getSpeedValue(uint8_t defaultSpeed) {\n    if (activeProfile == nullptr) {\n        return defaultSpeed;\n    }\n\n    // Map original speed constants to profile values\n    if (defaultSpeed == SPEED_STOP) return activeProfile-&gt;speedStop;\n    if (defaultSpeed == SPEED_STARTUP) return activeProfile-&gt;speedStartup;\n    if (defaultSpeed == SPEED_TURN) return activeProfile-&gt;speedTurn;\n    if (defaultSpeed == SPEED_BRAKE) return activeProfile-&gt;speedBrake;\n    if (defaultSpeed == SPEED_CRUISE) return activeProfile-&gt;speedCruise;\n    if (defaultSpeed == SPEED_SLOW) return activeProfile-&gt;speedSlow;\n    if (defaultSpeed == SPEED_FAST) return activeProfile-&gt;speedFast;\n    if (defaultSpeed == SPEED_BOOST) return activeProfile-&gt;speedBoost;\n    if (defaultSpeed == SPEED_MAX) return activeProfile-&gt;speedMax;\n\n    return validateSpeed(defaultSpeed);\n}\nThe Analysis Profile is designed for development and testing, with conservative speeds and gentle transitions. It prioritizes stability and predictability over raw speed, making it ideal for collecting performance data and tuning control parameters. All speed values are reduced, acceleration is gentler, and the PID parameters are tuned for stability.\nThe Speed Profile, in contrast, is optimized for maximum performance. It uses aggressive speed settings, quick transitions, and more responsive control parameters. The PID constants are increased for faster response, and the thresholds are adjusted to maintain control at higher speeds. These profiles have not yet been tested in competition conditions.\nThe ProfileManager ensures smooth operation by validating all speed values and providing fallback behaviour when no profile is active. When DEBUG_LEVEL is 0, the entire ProfileManager code is excluded from compilation, maintaining the efficiency of the production code.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Control Layer Implementation</span>"
    ]
  },
  {
    "objectID": "testing_guide.html",
    "href": "testing_guide.html",
    "title": "8  Testing Guide",
    "section": "",
    "text": "8.1 RobotZero - Arduino Nano - 2024\nThis document describes five independent test programs designed to verify the proper functioning of different components in your line following robot. Each test is a separate project that must be uploaded individually to your Arduino Nano. This modular approach allows for focused testing of each component without interference from other systems.\nIMPORTANT: Do not attempt to combine these tests into a single program. Each test should be uploaded separately to ensure accurate results.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Testing Guide</span>"
    ]
  },
  {
    "objectID": "testing_guide.html#robotzero---arduino-nano---2024",
    "href": "testing_guide.html#robotzero---arduino-nano---2024",
    "title": "8  Testing Guide",
    "section": "",
    "text": "8.1.1 Test Programs\n\n8.1.1.1 Line Sensors Test\nPurpose: Verify the proper functioning of the line sensors array.\nSetup: 1. Upload the line-sensor-test program to your Arduino Nano; 2. Open Serial Monitor (9600 baud); 3. Place your robot on a test surface with your line.\nTest Procedure: 1. Move the robot slowly across the line; 2. The LED will blink briefly each time a sensor transitions from low to high; 3. The Serial Monitor will display which sensor detected the transition and its reading; 4. Test each sensor by ensuring the line crosses all sensors.\nExpected Results: - LED should blink when sensors cross the line; - Serial Monitor should show sensor readings; - All sensors should detect the line when crossed; - Readings should change significantly between line and surface.\nTroubleshooting: - If a sensor never triggers, check its connections; - If readings are inconsistent, check sensor height from surface; - If LED doesn’t blink, verify LED pin connection; - If no serial output, check baud rate settings.\n\n\n8.1.1.2 Marker Sensors Test\nPurpose: Verify the proper functioning of the course marker sensors.\nSetup: 1. Upload the marker-sensor-test program; 2. Open Serial Monitor (9600 baud); 3. Prepare test markers (either actual course markers or test material).\nTest Procedure: 1. Move the robot over each marker; 2. Observe LED behaviour and Serial Monitor output; 3. Test both left and right marker sensors; 4. Try different marker positions and angles.\nExpected Results: - LED should blink when marker is detected; - Serial Monitor should show which sensor detected the marker; - Both left and right sensors should work independently; - Readings should be consistent for similar marker positions.\nTroubleshooting:- If markers aren't detected, adjustMARKER_THRESHOLD value; - Check sensor height if detection is inconsistent; - Verify sensor connections if one side isn’t working; - Test with different marker materials if detection is poor.\n\n\n8.1.1.3 Motors Test\nPurpose: Verify proper motor function and movement patterns.\nSetup: 1. Upload the motor-test program; 2. Place robot on elevated surface or testing stand; 3. Ensure adequate space for movement; 4. Keep USB cable clear of wheels.\nTest Procedure: The robot will automatically perform this sequence: 1. Move forward. 2. Stop. 3. Turn right. 4. Stop. 5. Turn left. 6. Stop. 7. Complete full turn. 8. Stop. 9. Move backward. 10. Stop. 11. Led blinking for 5 seconds. 12. Maximum speed running in straight line for 3s. 13. Stop.\nExpected Results: - Motors should run smoothly in all directions; - Robot should stop completely between movements; - Turns should be consistent; - Motor speed should be steady.\nTroubleshooting: - If motors don’t turn, check connections; - For uneven movement, verify wheel attachment; - If speed seems wrong, adjust MOTOR_SPEED constant; - For erratic behaviour, check battery voltage.\n\n\n8.1.1.4 Button and LED Test\nPurpose: Verify button operation and LED signalling.\nSetup: 1. Upload the button-led-test program. 2. Open Serial Monitor (9600 baud).\nTest Procedure: 1. Press button to cycle through LED modes: - Mode 0: LED off; - Mode 1: LED constantly on; - Mode 2: Slow blink (1 Hz); - Mode 3: Fast blink (5 Hz). 2. Test multiple button presses. 3. Observe LED behaviour in each mode.\nExpected Results: - Button should register each press cleanly; - LED should change modes with each press; - Serial Monitor should show mode changes; - LED patterns should be clear and consistent.\nTroubleshooting: - If button seems unresponsive, check debounce timing; - For LED issues, verify PIN_STATUS_LED connection; - If modes skip, adjust DEBOUNCE_DELAY; - Check button wiring if no response.\n\n\n8.1.1.5 Line Sensor Calibration Test\nPurpose: Calibrate line sensors and establish proper thresholds.\nSetup: 1. Upload the line-calibration-test program. 2. Open Serial Monitor (9600 baud). 3. Prepare test surface with line.\nTest Procedure: 1. Place robot on testing surface. 2. Press button to start calibration. 3. During the 3-second calibration period: - Move robot over the line multiple times; - Cover all sensors; - Move at different angles. 4. Observe final calibration values.\nExpected Results: - LED blinks rapidly during calibration. - Serial Monitor shows min/max values for each sensor. - Clear difference between line and surface readings. - Consistent readings across all sensors.\nTroubleshooting: - If ranges are too narrow, check sensor height. - For inconsistent readings, clean sensors. - If calibration fails, adjust CALIBRATION_TIME. - Verify surface and line contrast if readings are close.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Testing Guide</span>"
    ]
  },
  {
    "objectID": "testing_guide.html#general-tips",
    "href": "testing_guide.html#general-tips",
    "title": "8  Testing Guide",
    "section": "8.2 General Tips",
    "text": "8.2 General Tips\n\nAlways check battery voltage before testing.\nClean sensors before beginning tests.\nUse a well-lit testing area.\nKeep test surface clean and free of debris.\nDocument unusual readings for future reference.\nTest one component at a time.\nVerify USB connection if Serial Monitor shows no data.\n\nThese tests should be performed in sequence when building a new robot or after any major modifications. Keep a log of typical values and behaviors for your specific robot - this will help identify issues in the future.\nRegular testing using these programs can help identify problems before they affect robot performance in competition. If any test fails, resolve the issue before moving to the next test.",
    "crumbs": [
      "Line Follower",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Testing Guide</span>"
    ]
  },
  {
    "objectID": "archSim.html",
    "href": "archSim.html",
    "title": "9  Line Follower Simulator Architecture",
    "section": "",
    "text": "9.1 Overview\nSimulation and optimization system for line follower robots that runs entirely in a web browser. The project is completely static, hosted on GitHub Pages, allowing users to create tracks, configure robots, run realistic physical simulations, and find optimal configurations through optimization algorithms.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#project-objectives",
    "href": "archSim.html#project-objectives",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.2 Project Objectives",
    "text": "9.2 Project Objectives\n\nEnable visual creation and editing of complex tracks with curves, straights, and artifacts\nSimulate realistic robot physics considering mass, friction, temperature, pressure, and other environmental variables\nFind optimal control configurations for maximum efficiency in each track section\nVisualize competition in 3D with playback controls\nSave and share projects, tracks, and robot configurations\nFunction completely offline after initial loading",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#three-layer-architecture",
    "href": "archSim.html#three-layer-architecture",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.3 Three-Layer Architecture",
    "text": "9.3 Three-Layer Architecture\n\n9.3.1 Layer 1: User Interface\nTechnology: JavaScript/Svelte\nRationale: Svelte compiles components to optimized vanilla JavaScript with no runtime overhead, offering efficient reactivity through simple assignments, ideal for updating the UI with continuous simulation data.\nResponsibilities: - Visual track editor with curve and segment manipulation - Robot and simulation parameter configuration panels - Animation playback controls (play, pause, timeline, speed) - Saved project management and export/import interface - Optimization results visualization and convergence graphs\nState Management: - Svelte Stores for global state shared between components - Local reactive state in each component - Automatic synchronization with IndexedDB for persistence\n\n\n9.3.2 Layer 2: Simulation and Optimization\nTechnology: C++ compiled to WebAssembly via Emscripten\nRationale: Near-native performance (80-95%) for intensive physics and optimization calculations, with full control over memory allocation and predictable execution.\n\n9.3.2.1 Physics Module\nLibrary: Box2D (official WebAssembly port)\nRationale: Complete 2D rigid body physics engine with collision detection and stable numerical integration, eliminating the need to implement subtle stability details.\nImplementation: - Dynamic robot model with two independent motors (differential drive) - Kinematics calculations considering mass, inertia, and geometry - Friction simulation between wheels and surface - Collision detection with track edges - Infrared sensor system simulating analog line reading\nEnvironmental Factors: - Temperature: affects friction and motor response - Atmospheric pressure: influences air density and drag - Robot weight: determines inertia and grip - Friction coefficient: varies by surface type\n\n\n9.3.2.2 Mathematics Module\nLibrary: Eigen\nRationale: Header-only linear algebra library that works perfectly with Emscripten, offering optimized matrix operations and solvers essential for optimization algorithms.\nUsage: - Vector and matrix operations for kinematic calculations - Linear system solvers - Geometric transformation calculations\n\n\n9.3.2.3 Optimization Module\nStrategy: Artifact-Based Hierarchical Decomposition\nRationale: Instead of optimizing the entire track as a complex global problem, the system decomposes the track into known geometric primitives (artifacts) and applies analytical or semi-analytical solutions specific to each type. This approach drastically reduces the search space, provides provably optimal solutions for known cases, and enables interpretability of applied strategies.\n\n9.3.2.3.1 Phase 1: Pattern Recognition\nPattern Recognizer: Analyzes track geometry and identifies known artifacts.\nArtifacts Supported in Library: - Simple straight: linear segment without curvature - Circular curve: circle arc with constant radius - Straight-curve-straight transition: common sequence in racing tracks - S-Curve: two consecutive curves in opposite directions - Chicane: rapid sequence of alternating curves - Hairpin: tight 180-degree turn - Spiral: curve with continuously varying radius\nRecognition Process: 1. Scan track segments sequentially 2. Attempt pattern matching from most specific to most generic 3. When a match is found, mark segments as part of the artifact 4. Unrecognized segments are marked as “complex artifacts” for numerical optimization\n\n\n9.3.2.3.2 Phase 2: Analytical Strategy Library\nEach artifact in the library has a specific optimization strategy based on established physical principles and control theory.\nStraight: - Strategy: accelerate to maximum robot velocity and maintain - Instantaneous calculation, trivially optimal solution\nCircular Curve: - Maximum velocity: v_max = sqrt(μ * g * R) where μ is friction coefficient, g gravity, R radius - Racing line: enter wide, cut apex (innermost point), exit wide to maximize effective radius - Analytical solution based on classical vehicle dynamics\nStraight-Curve-Straight Transition: - Braking distance: d = (v_initial² - v_curve²) / (2 * a_max) - Braking start point calculated analytically - Strategy: brake as late as possible before curve, cut apex, accelerate as early as possible on exit - Based on optimal racing line theory\nS-Curve and Chicane: - Smoothed trajectory to minimize abrupt direction changes - Modulated velocity to maintain grip in transitions - Uses Bézier splines or clothoids for smooth transitions\nHairpin: - Very reduced velocity at apex - Wide entry, late apex, accelerate on exit - Calculation based on robot’s minimum turning radius\nSpiral: - Velocity inversely proportional to local curvature - Racing line follows varying radius - Calculation by integration along curve\n\n\n9.3.2.3.3 Phase 3: Transition Optimization\nReduced Problem: For N artifacts, optimize only N-1 transition velocities between consecutive artifacts.\nApproach: - Intelligent initialization using physical estimates - Optimization by numerical (finite differences) or analytical gradient if available - Problem typically with 5-15 variables (much smaller than global optimization) - Fast convergence due to reduced search space\nAlgorithm: 1. Calculate optimal local strategy for each artifact assuming initial transition velocities 2. Optimize transition velocities to minimize total time 3. Recalculate local strategies with optimized velocities 4. Iterate until convergence (typically 3-5 iterations)\n\n\n9.3.2.3.4 Phase 4: Complex Artifact Optimization\nFor geometries that do not fit known patterns, apply advanced numerical optimization techniques only locally to that artifact.\nAvailable Techniques:\nGradient-Based Optimization: - L-BFGS: quasi-Newton method without Hessian requirement, fast convergence - Gradient Descent with momentum: for cases with noisy objective function - Automatic Differentiation via CppAD: computes exact gradients without approximations - Finite Differences: numerical approximation when automatic differentiation is not applicable\nModel Predictive Control (MPC): - Repeatedly solves finite-horizon optimization problem - Suitable for artifacts with complex constraints or variable geometry - Allows incorporation of future state prediction - Used in modern automotive control and mobile robotics systems\nSequential Quadratic Programming (SQP): - For nonlinear problems with equality and inequality constraints - Approximates problem locally by quadratic program - Superlinear convergence when close to solution\nDirect Collocation: - Discretizes trajectory into control points - Transforms optimal control problem into nonlinear parameter optimization - Effective for complex trajectories with multiple constraints\nShooting Methods: - Integrates dynamics equations forward with candidate controls - Adjusts controls to satisfy boundary conditions - Single shooting (simple) or Multiple shooting (more robust)\nFallback - Stochastic Algorithms: Only when deterministic methods fail due to multiple local minima: - Particle Swarm Optimization (PSO): generally faster than GA - Genetic Algorithm: robust but computationally expensive - Simulated Annealing: for highly non-convex search spaces\n\n\n9.3.2.3.5 Optimizable Parameters\nArtifact Level: - Entry and exit velocities - Braking/acceleration start points - Trajectory (racing line) for curves - Maneuver aggressiveness\nGlobal Level: - PID controller gains (Kp, Ki, Kd) via established tuning methods (Ziegler-Nichols, Cohen-Coon) - Maximum robot velocity in different environmental conditions - Safety margins (minimum distance from edges)\n\n\n9.3.2.3.6 Objective Function\nPrimary: Total time to complete track\nSecondary (weighted): - Trajectory smoothness: penalizes abrupt accelerations and oscillations - Energy consumption: integral of power along path - Safety margin: penalizes excessive proximity to edges - Mechanical wear: penalizes maneuvers that stress components\n\n\n9.3.2.3.7 Advantages of Artifact-Based Approach\nComputational Efficiency: - 80-95% reduction in number of variables to optimize - Analytical solutions are instantaneous (microseconds) - Numerical optimization applied only where necessary\nInterpretability: - User sees specific strategy applied to each artifact - Detailed feedback: “In this 8m radius curve, limited by grip to 1.2 m/s” - Educational value about vehicle dynamics and racing strategies\nRobustness: - Analytical solutions are provably optimal within physical constraints - No risk of convergence to poor local minima in known artifacts - Deterministic and reproducible results\nScalability: - Artifact library can grow incrementally - Advanced users can contribute new artifacts - Each artifact is independent testable module\n\n\n\n9.3.2.4 Operating Modes\nBatch Mode (Optimization): - Executes thousands of complete simulations without visualization - Returns only final results (fitness, time, parameters) - Optimized for maximum execution speed - Runs in Web Worker to not block interface\nStep Mode (Visualization): - Advances simulation incrementally synchronized with animation - Returns complete state at each step (position, velocity, sensors) - Generates complete state log for later playback - Allows fine control of simulation rate\n\n\n\n9.3.3 Layer 3: 3D Visualization\nTechnology: Three.js\nRationale: Mature and performant library for 3D rendering in browser with extensive ecosystem and documentation.\nScene Components: - Track surface (plane or textured mesh) - Black line as extruded geometry or texture - 3D robot model (simple geometry with orientation indicator) - Sensor visualization (rays or cones showing detection) - Configurable camera (free perspective or following robot) - Lighting and shadows for visual depth\nPlayback System: - Simulation runs independently generating complete state log - Animation reproduces log synchronized with browser clock time - Controls: play, pause, stop, timeline scrubbing - Adjustable speed (slow motion, real-time, accelerated) - Optimized storage via keyframes with interpolation\nPerformance Optimization: - Instanced rendering for repetitive track elements - Texture atlases to reduce draw calls - Object pooling to avoid creation/destruction - Frustum culling and occlusion culling",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#communication-between-components",
    "href": "archSim.html#communication-between-components",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.4 Communication Between Components",
    "text": "9.4 Communication Between Components\n\n9.4.1 JavaScript ↔︎ WebAssembly Binding\nTechnology: Embind (provided by Emscripten)\nStructure:\nSvelte Interface (JS)\n       ↕\n   Embind API\n       ↕\nCore Engine (C++ WASM)\nExposed Types: - RobotConfig: complete robot configuration - TrackSegment: track segment definition - SimulationState: instantaneous simulation state - OptimizationResult: optimization process results\nTransfer Optimization: - Shared memory via TypedArrays for frequent data - JSON serialization for sporadic configurations - Reusable buffers to avoid repeated allocations\n\n\n9.4.2 Asynchronous Execution\nWeb Workers: - Long optimization operations run in dedicated workers - Interface remains responsive during intensive processing - Communication via postMessage with serializable data - Progress callbacks for progress bar updates",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#persistence-and-sharing",
    "href": "archSim.html#persistence-and-sharing",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.5 Persistence and Sharing",
    "text": "9.5 Persistence and Sharing\n\n9.5.1 Local Storage\nTechnology: IndexedDB via Dexie.js\nRationale: Dexie.js provides simplified IndexedDB wrapper with Promise-based API and advanced query capabilities.\nSchemas:\nprojects: \"++id, name, modified\"\ntracks: \"++id, name, created\"\nrobots: \"++id, name, created\"\nsimulations: \"++id, projectId, timestamp\"\nCapacity: - 50MB to several GB depending on browser - Sufficient for hundreds of complex projects\nCompaction Strategy: - Simulation logs stored as keyframes - Gzip compression for large data - Automatic cleanup of old data (optional)\n\n\n9.5.2 File Format\nExtension: .lfsim (structured JSON)\nStructure:\n{\n  \"version\": \"1.0\",\n  \"metadata\": {\n    \"name\": \"string\",\n    \"author\": \"string\",\n    \"created\": \"timestamp\",\n    \"modified\": \"timestamp\"\n  },\n  \"track\": {\n    \"width\": \"number\",\n    \"height\": \"number\",\n    \"segments\": [...]\n  },\n  \"robot\": {\n    \"mass\": \"number\",\n    \"wheelbase\": \"number\",\n    \"sensors\": {...},\n    \"pid\": {...}\n  },\n  \"simulation\": {\n    \"parameters\": {...},\n    \"results\": {...}\n  }\n}\n\n\n9.5.3 URL Sharing\nTechnology: Pako (gzip compression)\nProcess: 1. Serialize project to JSON 2. Compress with gzip (Pako) 3. Encode in Base64 4. Include in URL query parameter\nPractical Limit: - URLs up to ~2KB work in all browsers - URLs up to ~8KB work in most cases - Large projects require file export",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#complete-technology-stack",
    "href": "archSim.html#complete-technology-stack",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.6 Complete Technology Stack",
    "text": "9.6 Complete Technology Stack\n\n9.6.1 Frontend\nRuntime: - Svelte: Reactive UI framework - JavaScript/TypeScript: Primary language - Three.js: 3D rendering - Dexie.js: IndexedDB wrapper - Pako: Gzip compression\nBuild Tools: - Vite: Modern bundler with native WASM support - TypeScript (optional): Static typing - ESLint: JavaScript code linting - Prettier: Code formatting\n\n\n9.6.2 Core Engine\nLanguage: C++17\nLibraries: - Box2D: 2D physics engine - Eigen: Linear algebra (header-only) - Emscripten: Toolchain for WASM - CppAD (optional): Automatic differentiation for gradient-based optimization - NLopt (optional): Nonlinear optimization algorithm library\nBuild Tools: - CMake: Build system - Emscripten SDK (emsdk): C++ → WASM compiler\nCompilation Flags:\n-O3                          # Maximum optimization\n-s WASM=1                    # Generate WebAssembly\n-s MODULARIZE=1              # ES6 module\n-s ALLOW_MEMORY_GROWTH=1     # Dynamic memory\n-s INITIAL_MEMORY=16MB       # Initial memory\n-s MAXIMUM_MEMORY=512MB      # Memory limit\n--bind                       # Enable Embind\n\n\n9.6.3 Deployment\nHosting: GitHub Pages\nCI/CD: GitHub Actions\nPipeline: 1. Compile C++ to WASM via Emscripten 2. Bundle JavaScript/Svelte via Vite 3. Optimize assets (images, fonts) 4. Deploy to gh-pages branch\nRequirements: - Public repository or GitHub Pro - GitHub Actions enabled - GitHub Pages configuration pointing to gh-pages branch",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#directory-structure",
    "href": "archSim.html#directory-structure",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.7 Directory Structure",
    "text": "9.7 Directory Structure\nline-follower-simulator/\n├── README.md\n├── ARCHITECTURE.md\n├── package.json\n├── vite.config.js\n├── tsconfig.json (optional)\n│\n├── .github/\n│   └── workflows/\n│       └── deploy.yml\n│\n├── public/\n│   ├── assets/\n│   └── favicon.ico\n│\n├── src/\n│   ├── lib/\n│   │   ├── components/       # Svelte components\n│   │   │   ├── TrackEditor.svelte\n│   │   │   ├── RobotConfig.svelte\n│   │   │   ├── SimulationView.svelte\n│   │   │   └── Viewer3D.svelte\n│   │   │\n│   │   ├── stores/          # Svelte stores\n│   │   │   ├── project.js\n│   │   │   ├── simulation.js\n│   │   │   └── ui.js\n│   │   │\n│   │   ├── storage/         # Persistence\n│   │   │   ├── database.js\n│   │   │   ├── serializer.js\n│   │   │   └── url-encoder.js\n│   │   │\n│   │   └── three/          # 3D visualization\n│   │       ├── scene.js\n│   │       ├── robot.js\n│   │       └── track.js\n│   │\n│   ├── workers/\n│   │   └── optimization.worker.js\n│   │\n│   ├── App.svelte\n│   └── main.js\n│\n├── cpp/\n│   ├── CMakeLists.txt\n│   ├── include/\n│   │   ├── simulator.hpp\n│   │   ├── optimizer.hpp\n│   │   ├── physics.hpp\n│   │   ├── pattern_recognizer.hpp\n│   │   ├── artifacts/\n│   │   │   ├── artifact_base.hpp\n│   │   │   ├── straight.hpp\n│   │   │   ├── circular_curve.hpp\n│   │   │   ├── s_curve.hpp\n│   │   │   ├── chicane.hpp\n│   │   │   ├── hairpin.hpp\n│   │   │   ├── spiral.hpp\n│   │   │   └── complex.hpp\n│   │   └── optimizers/\n│   │       ├── gradient_descent.hpp\n│   │       ├── lbfgs.hpp\n│   │       ├── mpc.hpp\n│   │       └── direct_collocation.hpp\n│   │\n│   ├── src/\n│   │   ├── simulator.cpp\n│   │   ├── optimizer.cpp\n│   │   ├── physics.cpp\n│   │   ├── pattern_recognizer.cpp\n│   │   ├── artifacts/\n│   │   │   ├── straight.cpp\n│   │   │   ├── circular_curve.cpp\n│   │   │   ├── s_curve.cpp\n│   │   │   ├── chicane.cpp\n│   │   │   ├── hairpin.cpp\n│   │   │   ├── spiral.cpp\n│   │   │   └── complex.cpp\n│   │   ├── optimizers/\n│   │   │   ├── gradient_descent.cpp\n│   │   │   ├── lbfgs.cpp\n│   │   │   ├── mpc.cpp\n│   │   │   └── direct_collocation.cpp\n│   │   └── bindings.cpp\n│   │\n│   └── external/\n│       ├── box2d/\n│       ├── eigen/\n│       └── cppad/           # Automatic differentiation (optional)\n│\n└── dist/                   # Build output (generated)\n    ├── index.html\n    ├── assets/\n    ├── simulator.js\n    └── simulator.wasm",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#development-plan-in-phases",
    "href": "archSim.html#development-plan-in-phases",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.8 Development Plan in Phases",
    "text": "9.8 Development Plan in Phases\n\n9.8.1 Phase 1: Foundation and Basic Simulation\nObjective: Create functional system with abstract control model\nComponents: 1. Basic Svelte interface - Simple track editor (straight lines and curves) - Robot parameter configuration panel - Basic 2D visualization of simulation state\n\nPhysical simulator in C++/WASM\n\nRobot kinematic model\nSimulated sensor system\nConfigurable PID controller\nStable numerical integration\n\n3D visualization with Three.js\n\nBasic scene with track and robot\nCamera controls\nRecorded simulation playback\n\nBasic persistence\n\nSave/load projects in IndexedDB\nExport/import .lfsim files\n\n\nDeliverable: Functional simulator where users can create tracks, configure robots, and visualize simulations.\nEstimated Duration: 2-3 months\n\n\n9.8.2 Phase 2: Artifact-Based Optimization\nObjective: Implement hierarchical optimization system with artifact decomposition\nComponents: 1. Pattern Recognition System - Pattern Recognizer to identify geometric artifacts - Complete implementation in C++ - Visualization of track decomposition into artifacts - Interface to adjust recognition tolerances\n\nArtifact Library\n\nImplement basic artifacts: straight, circular curve, straight-curve-straight transition\nAnalytical solutions for each artifact type\nPhysics-based strategies (racing line, maximum velocity in curves)\nExtensible system to add new artifacts\n\nTransition Optimizer\n\nImplement numerical gradient via finite differences\nOptimization of velocities between consecutive artifacts\nIntelligent initialization using physical heuristics\nVisualization of convergence and impact of each transition\n\nAdvanced Optimizers for Complex Artifacts\n\nL-BFGS for efficient optimization with many variables\nAutomatic differentiation via CppAD (optional)\nFallback to stochastic methods when necessary\nPerformance metrics comparing different methods\n\nOptimization Interface\n\nVisualization of decomposition into identified artifacts\nArtifact-specific feedback (limitations, applied strategy)\nReal-time progress control\nComparison of results between different configurations\nSensitivity analysis (how changes affect performance)\n\nSimulation Improvements\n\nEnvironmental factors (temperature, friction) integrated into analytical formulas\nSensor noise for realistic simulation\nMore detailed motor models\nAutomatic PID tuning using established methods (Ziegler-Nichols)\n\nSharing\n\nGeneration of URLs with compressed projects\nExport optimized strategies as detailed report\nCommunity project gallery with strategy analyses\n\n\nDeliverable: Complete optimization system that decomposes tracks into artifacts, applies analytical solutions where possible, and optimizes numerically only when necessary. Users can visualize and understand strategies applied to each track section.\nEstimated Duration: 3-4 months\n\n\n9.8.3 Phase 3: Arduino Emulation (Future)\nObjective: Enable execution of real Arduino code in simulation\nPossible Approaches:\nOption A - High-Level Interpreter: - Create interpreter for Arduino API subset - Support essential functions (pinMode, analogRead, analogWrite, etc.) - Real-time code parsing and execution - Instrumentation for visual debugging\nOption B - Complete Emulation: - Integrate AVR emulator (SimAVR or similar) - Load and execute compiled code (.hex) - Precise synchronization with physical simulation - Absolute fidelity with real hardware\nDecision: Will be made after validation of phases 1 and 2 with real users, considering demand and available resources.\nDeliverable: System allowing development and testing of real Arduino code in simulator.\nEstimated Duration: 3-6 months (depending on approach)",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#performance-considerations",
    "href": "archSim.html#performance-considerations",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.9 Performance Considerations",
    "text": "9.9 Performance Considerations\n\n9.9.1 Performance Targets\nSimulation: - Batch mode: 1000+ simulations/second (optimization) - Step mode: 60 FPS with stable physics\nRendering: - Constant 60 FPS on modern hardware - Minimum 30 FPS on older hardware - Graceful quality degradation if necessary\nLoading: - Initial download: &lt;5 MB - Initialization time: &lt;2 seconds - Project loading: &lt;500 ms\n\n\n9.9.2 Planned Optimizations\nC++ WASM: - Compilation with -O3 and link-time optimization - SIMD for vector operations when available - Memory pools to avoid repeated allocations - Profile-guided optimization in hot paths\nThree.js: - Geometry instancing for repeated elements - Texture atlases to reduce draw calls - Object pooling to avoid creation/destruction - Frustum culling and occlusion culling\nJavaScript: - Code splitting for on-demand loading - Tree shaking to eliminate unused code - Gzip/brotli compression of assets - Service Worker for offline cache",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#testing-and-quality",
    "href": "archSim.html#testing-and-quality",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.10 Testing and Quality",
    "text": "9.10 Testing and Quality\n\n9.10.1 Testing Strategy\nUnit Tests: - Mathematical and physical functions in C++ - Isolated Svelte components - Serialization/deserialization functions\nIntegration: - JavaScript ↔︎ WASM communication - Complete persistence pipeline - Recorded simulation playback\nE2E: - Complete user flows (create, simulate, save) - Cross-browser compatibility - Performance on different hardware\n\n\n9.10.2 Tools\n\nVitest: JavaScript unit tests\nGoogle Test: C++ unit tests\nPlaywright: E2E tests\nLighthouse: Performance audit",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#system-requirements",
    "href": "archSim.html#system-requirements",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.11 System Requirements",
    "text": "9.11 System Requirements\n\n9.11.1 Supported Browsers\n\nChrome/Edge 90+\nFirefox 88+\nSafari 14+\nModern mobile browsers (limited functionality)\n\n\n\n9.11.2 Hardware Requirements\nMinimum: - CPU: Dual-core 2.0 GHz - RAM: 4 GB - GPU: WebGL 2.0 support\nRecommended: - CPU: Quad-core 3.0 GHz+ - RAM: 8 GB+ - GPU: Dedicated with WebGL 2.0 support",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#licensing",
    "href": "archSim.html#licensing",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.12 Licensing",
    "text": "9.12 Licensing\nOwn Code: To be defined (MIT or GPL suggested)\nDependencies: - Svelte: MIT License - Three.js: MIT License - Box2D: MIT License - Eigen: MPL2 License - Emscripten: MIT/LLVM License - Dexie.js: Apache License 2.0 - Pako: MIT License",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "archSim.html#technical-references",
    "href": "archSim.html#technical-references",
    "title": "9  Line Follower Simulator Architecture",
    "section": "9.13 Technical References",
    "text": "9.13 Technical References\n\n9.13.1 Documentation\n\nSvelte: https://svelte.dev/docs\nThree.js: https://threejs.org/docs\nEmscripten: https://emscripten.org/docs\nBox2D: https://box2d.org/documentation\nEigen: https://eigen.tuxfamily.org/dox\nDexie.js: https://dexie.org\n\n\n\n9.13.2 Learning Resources\n\nWebAssembly: https://webassembly.org\nGenetic Algorithms: “An Introduction to Genetic Algorithms” - Mitchell (1998)\nPID Controllers: “PID Controllers” - Åström & Hägglund (1995)\nMobile Robotics: “Introduction to Autonomous Mobile Robots” - Siegwart et al. (2011)\n\n\nDocument Version: 1.0\nLast Updated: 2025-11-04\nStatus: Architecture defined, awaiting implementation start",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Line Follower Simulator Architecture</span>"
    ]
  },
  {
    "objectID": "optLineFollower1.html",
    "href": "optLineFollower1.html",
    "title": "10  Optimization Methods for Line Follower Simulation",
    "section": "",
    "text": "10.1 Introduction: Understanding the Optimization Challenge\nWhen we design a line follower robot, we face a fascinating challenge that sits at the intersection of physics, control theory, and computational optimization. Imagine you are standing at the starting line of a racetrack with a complex path ahead, full of sharp turns, gentle curves, and long straightaways. Your goal is to complete this course in the minimum possible time while staying on the track. But here is the twist: you must decide beforehand exactly how fast to go at every point, when to brake, and how aggressively to steer through each corner.\nThis is precisely the challenge our optimization algorithms must solve, but with an added layer of complexity. The robot must follow a black line using sensors that can only see a small area directly beneath it, and it must make control decisions based on limited information while obeying the laws of physics that govern its motion. The optimization problem becomes finding the best configuration of control parameters, such as the gains of a PID controller, the maximum velocities in different track sections, and the racing line through curves, all while considering constraints like maximum acceleration, adhesion limits, and the requirement to stay on the track.\nThe beauty of this problem is that there is no single best approach. Different methods excel in different scenarios, and understanding when to apply each technique is as important as understanding how they work. Let us explore each method in detail, building your intuition about their strengths, weaknesses, and ideal use cases.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimization Methods for Line Follower Simulation</span>"
    ]
  },
  {
    "objectID": "optLineFollower1.html#method-1-analytical-solutions-based-on-physics",
    "href": "optLineFollower1.html#method-1-analytical-solutions-based-on-physics",
    "title": "10  Optimization Methods for Line Follower Simulation",
    "section": "10.2 Method 1: Analytical Solutions Based on Physics",
    "text": "10.2 Method 1: Analytical Solutions Based on Physics\n\n10.2.1 The Core Concept\nAnalytical solutions represent the most elegant approach to optimization when they are available. Instead of searching through countless possible configurations, we derive the optimal solution directly from the physical principles that govern the system. Think of this as solving a puzzle where you can see the complete picture and work backward from the answer, rather than trying random pieces until something fits.\nFor our line follower, certain track features have well-established optimal strategies that can be calculated using equations from vehicle dynamics and classical mechanics. These solutions are not approximations or estimates; they are mathematically proven to be optimal under the given constraints.\n\n\n10.2.2 How It Works in Practice\nConsider the simplest case: a straight section of track. The optimal strategy is obvious and can be expressed in a simple rule. The robot should accelerate at its maximum rate until it reaches its top speed, maintain that speed throughout the straight section, and then begin braking at the last possible moment before the next curve. The mathematics here are straightforward applications of kinematics.\nFor circular curves, the situation becomes more interesting but remains analytically solvable. The maximum speed through a curve is limited by the lateral acceleration the robot can sustain without losing traction. This relationship is captured by the elegant formula: v_max equals the square root of the product of the friction coefficient, gravitational acceleration, and curve radius. This equation tells us immediately what the speed limit is for any given curve without needing to run simulations or search through possibilities.\nThe concept of the racing line adds another layer of sophistication to curve optimization. Professional race car drivers know that the fastest path through a corner is not to follow the inside edge. Instead, the optimal trajectory enters the turn from the outside, cuts across to touch the inside at the apex, and then drifts back to the outside on exit. This line maximizes the effective radius of the turn, allowing higher speeds throughout. The geometry of this racing line can be calculated analytically using principles from differential geometry and calculus of variations.\nWhen we connect multiple track features, we can calculate transition points analytically. For instance, the point where braking should begin before a curve depends on the entry speed, the safe speed for the curve, and the maximum deceleration. This is a simple application of kinematic equations, yet it provides an exact answer without any iterative search.\n\n\n10.2.3 Strengths and Ideal Applications\nThe primary advantage of analytical solutions is their computational efficiency. Calculating the optimal speed for a circular curve using the friction-limited formula takes microseconds, whereas numerical optimization might require thousands of simulation runs taking seconds or minutes to converge to a similar answer. Moreover, analytical solutions are guaranteed to be optimal within their domain of applicability. There is no risk of converging to a suboptimal local minimum or missing the true optimum due to an inadequate search.\nAnalytical solutions also provide deep insight into the system behavior. When you know that speed is proportional to the square root of the radius, you immediately understand that doubling the curve radius allows about forty percent more speed, not double the speed. This kind of scaling relationship helps in understanding which track modifications would have the most significant impact on performance.\nThese solutions are ideal for track segments with simple, well-defined geometry. Straight sections, circular arcs, and standard transitions like clothoid curves all fall into this category. They are also perfect for establishing baseline performance and initial guesses for more complex optimization procedures.\n\n\n10.2.4 Limitations and When They Fall Short\nThe challenge with analytical solutions is that they require the problem to have a specific mathematical structure. Real tracks often contain sections that do not fit standard geometric templates. A curve with continuously varying radius, an S-turn with asymmetric geometry, or a section where the optimal line requires trading off between multiple competing objectives may not yield to analytical methods.\nFurthermore, analytical solutions typically assume simplified physics. The friction-limited speed formula assumes constant friction coefficient and perfectly circular motion. Real systems have weight transfer effects, tire slip angles, and dynamic load variations that complicate the picture. While these effects can sometimes be incorporated into more sophisticated analytical models, there comes a point where the analytical approach becomes so complex that numerical methods are more practical.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimization Methods for Line Follower Simulation</span>"
    ]
  },
  {
    "objectID": "optLineFollower1.html#method-2-gradient-based-optimization",
    "href": "optLineFollower1.html#method-2-gradient-based-optimization",
    "title": "10  Optimization Methods for Line Follower Simulation",
    "section": "10.3 Method 2: Gradient-Based Optimization",
    "text": "10.3 Method 2: Gradient-Based Optimization\n\n10.3.1 The Core Concept\nGradient-based optimization represents one of the most powerful and widely used approaches in computational optimization. To understand this method, imagine you are blindfolded and standing somewhere on a hilly landscape, and your goal is to reach the lowest valley. You cannot see where you are going, but you can feel the slope of the ground beneath your feet. By always taking steps in the direction of steepest descent, you will eventually reach a valley floor.\nThis is precisely how gradient-based optimization works. The landscape represents the objective function we are trying to minimize, such as the lap time around the track. The slope at any point represents the gradient, which tells us how changes in our control parameters affect the lap time. By repeatedly stepping in the direction that most reduces our objective, we navigate toward an optimal configuration.\n\n\n10.3.2 Understanding Gradients and Derivatives\nThe gradient is a mathematical object that captures how sensitive our objective function is to changes in each parameter. If we are optimizing three parameters, such as the three PID gains, the gradient is a vector with three components. The first component tells us how much the lap time changes per unit change in the proportional gain, the second corresponds to the integral gain, and the third to the derivative gain.\nComputing this gradient is the key technical challenge in gradient-based methods. There are three main approaches, each with its own trade-offs.\nThe first approach is analytical differentiation. If we can write down the entire simulation as a mathematical expression, we can use calculus to derive formulas for the gradients. This gives us exact gradients at minimal computational cost, but it requires that our simulation be differentiable and expressible in closed form, which is rarely possible for complex physical simulations.\nThe second approach is automatic differentiation, which is a remarkable technology that deserves detailed explanation. Modern automatic differentiation libraries can take your simulation code and automatically instrument it to compute exact gradients. The way this works is both elegant and subtle. During the forward pass of your simulation, the automatic differentiation system records a computational graph that captures every arithmetic operation and function call. Then, during a backward pass, it uses the chain rule from calculus to propagate derivatives backward through this graph, ultimately computing the gradient of the final output with respect to all inputs. The beauty of automatic differentiation is that it provides exact gradients with computational cost that is only a small multiple of the forward simulation cost, typically two to five times slower.\nThe third approach is numerical differentiation using finite differences. This is the simplest to implement but the most computationally expensive. To estimate the gradient numerically, you evaluate the objective function at your current parameter values, then perturb each parameter slightly and re-evaluate the objective. The gradient component for each parameter is approximated by the change in objective divided by the perturbation size. If you have ten parameters, this requires eleven objective evaluations to compute one gradient, which means eleven complete simulations of the robot going around the track.\n\n\n10.3.3 Optimization Algorithms Using Gradients\nOnce we have a method for computing gradients, we can apply various optimization algorithms. The simplest is gradient descent, where we repeatedly take steps proportional to the negative gradient. This is like following the slope of the hill directly downward. The step size, often called the learning rate, is a critical parameter. Too large, and we might overshoot the minimum and diverge. Too small, and convergence is painfully slow.\nMore sophisticated variants improve upon basic gradient descent. Gradient descent with momentum adds a velocity term that smooths out the trajectory and helps avoid getting stuck in flat regions. The idea is borrowed from physics: a ball rolling down a hill has momentum that carries it through flat spots and shallow local minima.\nThe L-BFGS algorithm represents a major leap in sophistication. BFGS stands for Broyden, Fletcher, Goldfarb, and Shanno, the four researchers who independently developed this method. L-BFGS is the limited-memory variant suitable for large-scale problems. The key insight behind BFGS methods is to approximate the curvature of the objective function, not just its slope. By building up an approximation of the second derivative information through successive gradient evaluations, L-BFGS can take more intelligent steps that account for how the gradient itself is changing. This leads to much faster convergence, often requiring orders of magnitude fewer iterations than simple gradient descent.\nNewton’s method and its variants go even further by explicitly computing or approximating the Hessian matrix, which contains all second derivatives of the objective function. When the Hessian is available, Newton’s method can converge in very few iterations by taking steps that account for the full local curvature of the objective landscape. However, computing the Hessian for high-dimensional problems is often prohibitively expensive, which is why quasi-Newton methods like L-BFGS that approximate the Hessian are more commonly used in practice.\n\n\n10.3.4 Strengths and Ideal Applications\nThe primary strength of gradient-based methods is their efficiency in high-dimensional spaces. While a brute-force grid search becomes intractable beyond a handful of dimensions, gradient-based methods can optimize hundreds or thousands of parameters efficiently. This is because they use the local gradient information to make informed decisions about which direction to search, rather than exploring the space blindly.\nAnother major advantage is the speed of convergence once the algorithm is in the neighborhood of a minimum. Gradient-based methods typically exhibit linear or superlinear convergence, meaning that each iteration brings an exponential reduction in the distance to the optimum. For smooth, well-behaved objective functions, this can lead to high-precision solutions in remarkably few iterations.\nGradient-based optimization is ideal when your objective function is smooth and differentiable, when you have a reasonably good initial guess that puts you in the basin of attraction of a good local minimum, and when the computational cost of evaluating gradients is acceptable relative to the objective function evaluation.\n\n\n10.3.5 Limitations and Pitfalls\nThe most significant limitation of gradient-based methods is their local nature. These algorithms will converge to a local minimum, which may not be the global minimum. Imagine a landscape with multiple valleys. Gradient descent will lead you to the bottom of whichever valley you start in, but cannot tell you if there is a deeper valley elsewhere. For complex track geometries, the lap time as a function of control parameters may have many local minima corresponding to qualitatively different driving strategies.\nGradient-based methods also struggle with non-smooth objective functions. If your objective has discontinuities, sharp corners, or noisy evaluations, the gradient may not be well-defined or may be misleading. This can occur in our line follower simulation if the robot occasionally fails to complete the lap, causing a discrete jump in the objective function.\nAnother practical challenge is the need for careful tuning of hyperparameters, particularly step sizes and convergence criteria. Getting these wrong can lead to slow convergence, numerical instability, or premature termination.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimization Methods for Line Follower Simulation</span>"
    ]
  },
  {
    "objectID": "optLineFollower1.html#method-3-model-predictive-control-mpc",
    "href": "optLineFollower1.html#method-3-model-predictive-control-mpc",
    "title": "10  Optimization Methods for Line Follower Simulation",
    "section": "10.4 Method 3: Model Predictive Control (MPC)",
    "text": "10.4 Method 3: Model Predictive Control (MPC)\n\n10.4.1 The Core Concept\nModel Predictive Control represents a paradigm shift in how we think about the optimization problem. Rather than computing an optimal strategy for the entire track beforehand, MPC solves a sequence of shorter optimization problems repeatedly as the robot progresses around the track. This is analogous to how humans actually drive: we look ahead a certain distance, plan the best course through the visible section, execute the first part of that plan, and then look ahead again from our new position and replan.\nThe magic of MPC is that it transforms a difficult global optimization problem into a series of smaller, more manageable local optimization problems. While finding the optimal control strategy for an entire complex track might be intractable, finding the optimal control sequence for the next two seconds of driving is much more feasible.\n\n\n10.4.2 How MPC Works: The Receding Horizon\nThe operation of MPC follows a simple but powerful cycle. At each time step, the controller looks ahead over a prediction horizon, which might be two or three seconds into the future. Using a mathematical model of the robot’s dynamics, it predicts what would happen under different control sequences over this horizon. The controller then solves an optimization problem to find the control sequence that minimizes a cost function over the prediction horizon while satisfying all constraints.\nHere is the crucial twist that makes MPC practical: even though the controller computes an optimal control sequence for the entire prediction horizon, it only applies the first control action from that sequence. At the next time step, the controller measures the new state, shifts the prediction horizon forward in time, and resolves the optimization problem with updated information. This is why it is called a receding horizon approach; the optimization window continually slides forward as the robot moves.\nTo make this concrete, imagine our robot approaching a series of curves. At time t equals zero, the MPC controller looks ahead and sees two seconds of track containing a right turn followed by a slight left. It computes the optimal control sequence for navigating this section. However, it only applies the control action for the next tenth of a second. At time t equals one-tenth of a second, the robot has moved slightly forward, and the controller now sees a slightly different two-second window ahead. It recomputes the optimal control for this new window and applies only the first action again. This process repeats continually.\n\n\n10.4.3 Formulating the MPC Problem\nThe optimization problem that MPC solves at each time step has a specific mathematical structure. We are looking for a sequence of control inputs, which for our differential drive robot might be the left and right motor velocities at each future time step. The objective function typically includes terms that penalize deviation from the desired path, excessive control effort, and large accelerations. We might write something like: minimize the sum over all future time steps in the horizon of weighted squared errors from the line, plus weighted squared motor commands, plus weighted squared changes in motor commands.\nCritically, this optimization must respect constraints. The motor velocities cannot exceed their physical limits. The lateral acceleration must stay within friction bounds to prevent skidding. The robot must remain within track boundaries. These constraints are encoded as inequality constraints in the optimization problem.\nThe prediction model is the heart of MPC. This model describes how the robot’s state evolves in response to control inputs. For a differential drive robot, the model includes the kinematic equations that relate wheel velocities to the robot’s position and orientation, plus dynamic equations that account for inertia and friction. The quality of this model directly affects the performance of MPC. If the model accurately captures the robot’s behavior, MPC can make excellent predictions and choose controls that work well in reality. If the model is inaccurate, the predictions will be wrong and performance will suffer.\n\n\n10.4.4 Solving the MPC Optimization Problem\nAt each time step, MPC must solve a constrained nonlinear optimization problem, and it must do so quickly enough to keep up with real-time control. This is a significant computational challenge. The optimization problem typically has tens to hundreds of variables, representing the control inputs at each future time step in the horizon, and many constraints from physical limits and safety requirements.\nSeveral specialized algorithms have been developed for efficiently solving MPC problems. Sequential Quadratic Programming is a popular choice. SQP works by repeatedly approximating the nonlinear problem with a quadratic program, solving that simpler problem, and updating the approximation. Interior point methods are another common approach, particularly for problems with many inequality constraints. These methods navigate through the interior of the feasible region rather than along its boundary.\nFor linear systems with quadratic costs and linear constraints, a special case called Linear MPC, the optimization reduces to a convex quadratic program that can be solved very efficiently using dedicated QP solvers. However, our robot’s dynamics are nonlinear due to the trigonometric functions in the kinematic equations, so we generally must deal with nonlinear MPC and its greater computational demands.\n\n\n10.4.5 Strengths and Ideal Applications\nMPC has several compelling advantages that make it extremely popular in industrial control applications. Perhaps most importantly, MPC naturally handles constraints. Hard limits on control inputs, state variables, and safety requirements are explicitly incorporated into the optimization problem. This is in stark contrast to classical control approaches like PID, which have difficulty handling constraints systematically.\nAnother major strength is MPC’s ability to handle systems with delays and preview information. By predicting future behavior over a horizon, MPC can anticipate upcoming changes and take proactive action. For our line follower, this means the controller can see curves coming and begin adjusting its trajectory before reaching them.\nMPC is also remarkably robust to model uncertainty and disturbances. Because MPC continually re-optimizes based on new measurements, it naturally implements feedback that corrects for modeling errors and unexpected disturbances. If the robot does not move exactly as predicted, the discrepancy shows up in the next measurement and is automatically incorporated into the next optimization.\nMPC is ideal for systems where you have a reasonably good dynamic model, where constraints are important and must be respected, where the system state can be measured or estimated accurately, and where sufficient computational resources are available to solve the optimization problem in real-time.\n\n\n10.4.6 Limitations and Practical Challenges\nThe most obvious limitation of MPC is its computational demand. Solving an optimization problem at every control time step requires significant processing power. This has traditionally limited MPC to systems with relatively slow dynamics where the controller has tens or hundreds of milliseconds to compute each control action. However, advances in computing hardware and optimization algorithms have steadily expanded the range of systems where MPC is feasible.\nMPC performance depends critically on the accuracy of the prediction model. If the model poorly represents the real system, the predicted future trajectories will be wrong, and the computed controls will be suboptimal or even destabilizing. Developing and validating high-fidelity models can be a significant engineering effort.\nThe tuning of MPC controllers also requires expertise. The prediction horizon length, the weights in the objective function, and the constraint values all affect performance and must be chosen carefully. Too short a horizon and the controller becomes myopic, unable to anticipate upcoming features. Too long and the computational burden grows while the benefits diminish. The objective function weights determine the trade-off between tracking accuracy and control effort, and finding the right balance requires insight and experimentation.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimization Methods for Line Follower Simulation</span>"
    ]
  },
  {
    "objectID": "optLineFollower1.html#method-4-sequential-quadratic-programming-sqp",
    "href": "optLineFollower1.html#method-4-sequential-quadratic-programming-sqp",
    "title": "10  Optimization Methods for Line Follower Simulation",
    "section": "10.5 Method 4: Sequential Quadratic Programming (SQP)",
    "text": "10.5 Method 4: Sequential Quadratic Programming (SQP)\n\n10.5.1 The Core Concept\nSequential Quadratic Programming represents one of the most powerful techniques for solving nonlinear optimization problems with constraints. To understand SQP, we need to first appreciate what makes constrained optimization fundamentally different from unconstrained optimization and why it requires specialized methods.\nIn unconstrained optimization, we simply want to find the parameter values that minimize our objective function, with no restrictions on what values the parameters can take. But most real-world problems have constraints. For our line follower, we might want to minimize lap time subject to the constraint that the robot stays on the track, motor velocities remain within physical limits, and lateral acceleration does not exceed the friction limit. These constraints dramatically change the nature of the optimization problem.\nThe key insight behind SQP is to solve this difficult nonlinear constrained problem by repeatedly solving a simpler approximation. At each iteration, SQP constructs a quadratic approximation to the objective function and linear approximations to the constraints, creating a quadratic programming subproblem that can be solved efficiently. The solution to this subproblem provides a search direction, and the algorithm takes a step in that direction and repeats.\n\n\n10.5.2 The Mathematics of SQP: Building Intuition\nTo make this concrete, imagine we are optimizing three parameters: the three PID gains. Our objective function is the lap time, which is a nonlinear function of these gains. We also have constraints: perhaps the gains must be positive, and the sum of gains must not exceed some value to ensure stability.\nAt the current point in parameter space, SQP computes the gradient of the objective function and the gradients of the constraint functions. These tell us which directions increase or decrease the objective and constraints. SQP then builds a local quadratic model of the objective by also computing or approximating its Hessian, which describes the curvature. The constraints are approximated as linear functions based on their gradients.\nWith this local quadratic model and linear constraints, SQP formulates a quadratic program: minimize the quadratic approximation of the objective subject to the linearized constraints. This quadratic program has the wonderful property that it can be solved very efficiently using specialized QP solvers that exploit the problem structure.\nThe solution to the QP gives us a step direction. If we take this step, we expect to reduce the objective while satisfying the linearized constraints. However, because our approximations are only valid locally, taking too large a step might lead us astray. SQP therefore includes a line search or trust region mechanism to determine an appropriate step size. The algorithm evaluates the actual objective and constraints at the proposed new point and adjusts the step size if necessary to ensure progress.\n\n\n10.5.3 How SQP Handles Constraints: The Lagrange Multipliers\nA crucial aspect of SQP is how it handles constraints using the concept of Lagrange multipliers. This is a deep idea from optimization theory that deserves explanation. When a constraint is active at the optimum, meaning it holds with equality, it exerts a force that pushes the solution away from where the unconstrained optimum would be. The Lagrange multiplier quantifies the strength of this force.\nFor our line follower, imagine we are optimizing the speed through a curve subject to a constraint on maximum lateral acceleration. If this constraint is not binding, the robot could go faster without violating it, and the Lagrange multiplier is zero. But if the constraint is active, meaning the robot is at the edge of losing traction, the constraint is preventing us from going faster. The Lagrange multiplier tells us how much the lap time would improve if we could relax that constraint slightly, perhaps by having tires with better grip.\nSQP maintains estimates of the Lagrange multipliers throughout the optimization and uses them to guide the search. This allows SQP to efficiently navigate along constraint boundaries and determine which constraints are active at the optimum.\n\n\n10.5.4 Strengths and Ideal Applications\nSQP is particularly powerful for problems with significant nonlinearity in both the objective and constraints. Unlike simpler methods that treat constraints as penalties or barriers, SQP handles them as first-class elements of the optimization problem. This leads to more accurate solutions and better performance when constraints are active at the optimum.\nThe convergence properties of SQP are excellent. Near a solution satisfying certain regularity conditions, SQP exhibits superlinear convergence, meaning it achieves high precision rapidly once in the neighborhood of the optimum. This makes it one of the fastest methods for solving smooth nonlinear programs.\nSQP is ideal when you have a smooth objective and constraint functions with available derivative information, when constraints are critical to the problem and not just soft preferences, when moderate to high precision is required in the solution, and when the problem size is manageable, typically up to a few thousand variables.\n\n\n10.5.5 Limitations and Practical Considerations\nThe primary limitation of SQP is its computational cost per iteration. Forming and solving the quadratic programming subproblem, especially with many variables and constraints, can be expensive. Each iteration requires computing gradients of the objective and all constraints, forming the approximate Hessian, and solving a potentially large QP.\nLike other local optimization methods, SQP is susceptible to local minima. The algorithm will converge to a local optimum, which may not be globally optimal. The quality of the solution depends on the starting point.\nSQP also requires that certain mathematical conditions, called constraint qualifications, hold at the solution. These conditions ensure that the constraints are well-behaved and the Lagrange multipliers are well-defined. In pathological cases where these conditions fail, SQP may struggle to converge properly.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimization Methods for Line Follower Simulation</span>"
    ]
  },
  {
    "objectID": "optLineFollower1.html#method-5-direct-collocation",
    "href": "optLineFollower1.html#method-5-direct-collocation",
    "title": "10  Optimization Methods for Line Follower Simulation",
    "section": "10.6 Method 5: Direct Collocation",
    "text": "10.6 Method 5: Direct Collocation\n\n10.6.1 The Core Concept\nDirect Collocation is a fascinating approach to trajectory optimization that transforms a difficult infinite-dimensional problem into a finite-dimensional nonlinear program. To understand why this is remarkable, we need to recognize what we are really optimizing when we seek the best trajectory for our robot.\nA trajectory is a function that specifies the robot’s state and control inputs at every instant in time. Since time is continuous, a trajectory is inherently infinite-dimensional: there are infinitely many time points, and we need to specify what the robot is doing at each one. Traditional optimal control theory tries to characterize these infinite-dimensional functions using calculus of variations and the Pontryagin Maximum Principle, leading to complex boundary value problems that are difficult to solve computationally.\nDirect Collocation sidesteps this difficulty through a clever trick: instead of trying to find the entire continuous trajectory, we represent it using a finite number of discrete time points called collocation points. At these points, we directly optimize the robot’s state and control inputs. Between the collocation points, we interpolate using polynomials. This discretization transforms the infinite-dimensional problem into a large but finite-dimensional nonlinear programming problem that we can solve using standard NLP solvers.\n\n\n10.6.2 The Mechanics of Direct Collocation\nLet us walk through how Direct Collocation works for our line follower problem. We want to find the trajectory that minimizes lap time while respecting the robot’s dynamics and staying on the track.\nFirst, we divide the lap time into a sequence of time intervals. We might use twenty intervals of equal duration, or we might vary the interval lengths to concentrate more points in complex track sections. At the boundary of each interval, we have a collocation point. For twenty intervals, this gives us twenty-one collocation points from start to finish.\nAt each collocation point, we introduce decision variables representing the robot’s state at that moment. This includes position coordinates x and y, orientation angle theta, and velocities. We also introduce decision variables for the control inputs, the left and right motor velocities, at each point. For a state dimension of six and control dimension of two, and twenty intervals, we have approximately one hundred and sixty decision variables in total.\nNow comes the critical part: we must ensure that the trajectory satisfies the robot’s dynamics. The robot cannot teleport or violate the laws of physics. We enforce this using collocation constraints. Between each pair of adjacent collocation points, we use polynomial interpolation to represent the state trajectory, commonly using cubic polynomials called Hermite splines. The collocation constraint requires that the derivatives of these interpolating polynomials match the dynamics predicted by our physical model.\nMathematically, this means that at each collocation point, the time derivative of the state must equal the right-hand side of our differential equations evaluated at that state and control. For example, if our dynamics say that dx/dt equals v times cosine of theta, then we require that the derivative of our interpolating polynomial for x at each collocation point equals v times cosine of theta at that point. These constraints are called defect constraints because they measure how much our discretized trajectory defects from satisfying the true continuous dynamics.\nIn addition to dynamics constraints, we include any path constraints that must hold throughout the trajectory. For our line follower, this includes staying within track boundaries, respecting motor limits, and maintaining lateral acceleration within friction bounds. These constraints are enforced at the collocation points and assumed to be satisfied by interpolation between points.\nThe objective function is formulated as a sum over the intervals. To minimize lap time, we might sum the duration of each interval. Or for a more complex objective involving energy consumption, we would integrate the power over each interval using the collocation points.\n\n\n10.6.3 Solving the Direct Collocation Problem\nOnce formulated, the Direct Collocation problem is a large sparse nonlinear program. Sparse means that each variable appears in relatively few constraints, which is natural since each collocation point is only directly connected to its immediate neighbors through the dynamics.\nWe solve this NLP using specialized solvers like IPOPT, which stands for Interior Point OPTimizer. IPOPT is designed to exploit sparsity and can handle problems with thousands or tens of thousands of variables efficiently. The solver uses the problem’s sparse structure to compute search directions quickly and takes Newton-like steps toward the optimum.\nThe efficiency of solving Direct Collocation problems is remarkable. Despite having many variables, the sparse structure means that forming and solving the linear systems needed by the optimization algorithm is relatively fast. Modern implementations can solve trajectory optimization problems with hundreds of collocation points in seconds or less.\n\n\n10.6.4 Strengths and Ideal Applications\nDirect Collocation has several powerful advantages. First, it naturally handles state and control constraints at every point along the trajectory. Hard limits, obstacle avoidance, and other path constraints are directly incorporated into the NLP.\nSecond, Direct Collocation does not require specifying control parameterizations or guessing functional forms for the solution. The method directly optimizes the trajectory in a very general way. This flexibility often allows it to discover non-intuitive optimal strategies.\nThird, the method provides both the optimal trajectory and the optimal controls simultaneously. You do not need to separately solve for the control policy once you have the trajectory.\nFourth, Direct Collocation can handle systems with complex dynamics including differential-algebraic equations, which arise when the system has algebraic constraints in addition to differential equations.\nDirect Collocation is ideal for problems where you want to compute a single optimal trajectory for a known scenario, where the dynamics may be complex or stiff, where path constraints are important, and where you have sufficient computational resources to solve moderately large NLPs.\n\n\n10.6.5 Limitations and Practical Challenges\nThe main limitation is that Direct Collocation produces an open-loop trajectory, meaning a pre-computed sequence of controls without feedback. If the robot deviates from the planned trajectory due to disturbances or modeling errors, the pre-computed controls may no longer be optimal or even feasible. To use Direct Collocation in real systems, you typically need to combine it with a feedback controller that tracks the optimal trajectory or repeatedly re-optimize in a receding horizon fashion similar to MPC.\nThe computational cost, while reasonable for modern hardware, is still significant compared to simpler methods. Each trajectory optimization requires solving a large NLP, which may take seconds to minutes depending on problem size.\nChoosing the number and placement of collocation points requires some art. Too few points and the discretization error is large, meaning the discrete trajectory poorly approximates the true continuous dynamics. Too many points and the NLP becomes large and slow to solve without much benefit.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimization Methods for Line Follower Simulation</span>"
    ]
  },
  {
    "objectID": "optLineFollower1.html#method-6-shooting-methods",
    "href": "optLineFollower1.html#method-6-shooting-methods",
    "title": "10  Optimization Methods for Line Follower Simulation",
    "section": "10.7 Method 6: Shooting Methods",
    "text": "10.7 Method 6: Shooting Methods\n\n10.7.1 The Core Concept\nShooting methods provide an alternative approach to trajectory optimization that is conceptually simpler than Direct Collocation, though not always computationally easier. The name comes from an analogy with artillery: you aim a cannon at a target, fire, observe where the shot lands, adjust your aim, and shoot again until you hit the target.\nIn the context of optimization, shooting methods work by choosing control inputs, simulating forward through time using those controls to see where the trajectory ends up, and then adjusting the controls based on how far off the endpoint is from the desired target. Unlike Direct Collocation, which optimizes the entire trajectory simultaneously, shooting methods treat the dynamics as a black box simulator and only optimize the control inputs.\n\n\n10.7.2 Single Shooting: The Basic Approach\nIn single shooting, we parameterize the control inputs over time and treat these parameters as our optimization variables. For example, we might represent the left and right motor velocities as piecewise constant functions, with one value for each of twenty time intervals. Our optimization variables are then these forty control values.\nTo evaluate the objective function for a given set of control parameters, we simulate the robot’s motion forward in time from the initial state using the specified controls. The simulator integrates the differential equations that govern the robot’s dynamics, producing a complete state trajectory. We then evaluate how good this trajectory is: Does it complete the lap? How long did it take? Did it stay on the track? This evaluation gives us the objective function value.\nThe optimization proceeds by adjusting the control parameters to minimize the objective. This is typically done using gradient-based methods, where the gradients are computed either by finite differences (perturbing each control parameter and re-simulating) or by solving adjoint equations that efficiently compute sensitivities.\nThe beauty of single shooting is its simplicity. We only optimize the control inputs, which are typically much lower dimensional than the full state trajectory. The dynamics are satisfied automatically because we are simulating the real differential equations. We do not need to introduce the complex collocation constraints of Direct Collocation.\n\n\n10.7.3 Multiple Shooting: Enhanced Robustness\nSingle shooting has a significant drawback: it can be numerically unstable, especially for long time horizons or systems with sensitive dynamics. If the initial controls are far from optimal, the simulated trajectory might go wildly off course, making it difficult for the optimizer to get useful gradient information or make progress.\nMultiple shooting addresses this by breaking the trajectory into segments. Instead of shooting from the initial state all the way to the final time in one go, we introduce intermediate shooting points. We now optimize not just the control inputs but also the states at each shooting point. Between shooting points, we simulate forward as in single shooting.\nThe key is that we introduce matching constraints that require the end state of one shooting segment to equal the initial state of the next segment. These constraints ensure continuity of the trajectory while giving the optimizer more freedom to explore during the search.\nThe advantage of multiple shooting is improved numerical stability and convergence. Even if one segment goes awry, the others remain well-behaved because they start from independently optimized states. The optimizer can adjust the shooting point states to keep all segments in reasonable regions of state space.\n\n\n10.7.4 Strengths and Ideal Applications\nShooting methods are particularly appealing when you have a high-fidelity simulator that you trust but is too complex to express in closed form. The simulator might include detailed physics, contact dynamics, or other phenomena that are difficult to capture in explicit equations. Shooting methods treat this simulator as a black box and work with it through simulation.\nAnother advantage is that shooting methods often have fewer optimization variables than Direct Collocation, especially single shooting. If your control inputs can be parameterized compactly, you might optimize dozens of variables with shooting versus hundreds with collocation.\nShooting methods are also natural to parallelize. In multiple shooting, different segments can be simulated simultaneously on different processors, with only the matching constraints coupling them. This can lead to significant speedups on multi-core hardware.\nThese methods are ideal when you have a reliable simulation infrastructure, when the dynamics are not too unstable, when you can compute or approximate gradients efficiently, and when the problem structure makes the shooting formulation more compact than alternatives.\n\n\n10.7.5 Limitations and Practical Challenges\nThe primary limitation of single shooting is its potential instability. For long trajectories or systems with exponentially unstable dynamics, small changes in initial controls can lead to enormous changes in the final trajectory. This makes the objective function highly nonlinear and difficult to optimize.\nMultiple shooting mitigates this but at the cost of introducing additional variables and constraints, making it more similar in structure to Direct Collocation. The trade-off between simplicity and robustness must be evaluated for each problem.\nComputing gradients in shooting methods can be challenging. Finite difference approaches require one simulation per control parameter, which becomes expensive for high-dimensional control spaces. Adjoint methods provide gradients more efficiently but require deriving and implementing the adjoint equations, which can be complex for intricate simulators.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimization Methods for Line Follower Simulation</span>"
    ]
  },
  {
    "objectID": "optLineFollower1.html#method-7-stochastic-optimization-methods",
    "href": "optLineFollower1.html#method-7-stochastic-optimization-methods",
    "title": "10  Optimization Methods for Line Follower Simulation",
    "section": "10.8 Method 7: Stochastic Optimization Methods",
    "text": "10.8 Method 7: Stochastic Optimization Methods\n\n10.8.1 The Core Concept\nStochastic optimization methods represent a fundamentally different philosophy from the gradient-based approaches we have discussed so far. Instead of using local gradient information to climb systematically toward an optimum, these methods introduce randomness into the search process. This might seem counterintuitive – why would adding randomness help us find the best solution? The answer lies in the ability of stochastic methods to explore the solution space globally and escape from poor local optima.\nThink of the optimization landscape as a mountain range where we want to find the deepest valley. Gradient-based methods are like a ball rolling downhill: efficient at descending into a valley but unable to climb back out to search other valleys. Stochastic methods are more like a swarm of explorers who can jump around the landscape, occasionally making seemingly irrational moves that allow them to discover regions that purely local search would miss.\n\n\n10.8.2 Genetic Algorithms: Evolution in Action\nGenetic algorithms draw inspiration from biological evolution. The idea is to maintain a population of candidate solutions and evolve them over generations through operations analogous to natural selection, reproduction, and mutation.\nWe start by creating an initial population of candidate solutions, perhaps fifty different sets of PID gains chosen randomly. Each candidate is evaluated by simulating the robot with those parameters and measuring the lap time. This is the fitness evaluation, analogous to determining which organisms survive and reproduce in nature.\nSelection is the process of choosing which candidates get to contribute to the next generation. Better solutions, those with lower lap times, are more likely to be selected. A common approach is tournament selection, where we randomly pick a small group of candidates and select the best among them.\nCrossover is the primary reproductive operator. Two parent solutions are combined to create offspring. For example, if one parent has PID gains of one, zero point five, and zero point one, and another parent has two, zero point three, and zero point two, we might create a child by taking some genes from each parent, perhaps one, zero point three, and zero point one. The biological analogy is that offspring inherit traits from both parents.\nMutation introduces random changes to maintain diversity in the population. With some probability, each gene in each individual might be randomly perturbed. This prevents the population from converging prematurely to a local optimum and ensures that new regions of the solution space can be explored.\nOver many generations, the population evolves toward better solutions. Good traits are preserved through selection, combined in novel ways through crossover, and occasionally improved through fortunate mutations. Eventually, the algorithm converges when the population becomes dominated by very similar high-quality solutions.\n\n\n10.8.3 Particle Swarm Optimization: Collective Intelligence\nParticle Swarm Optimization takes inspiration from the social behavior of bird flocks or fish schools. Imagine a flock of birds searching for food in a landscape. Each bird has a position representing a candidate solution and a velocity representing how the bird is moving through the solution space.\nAt each iteration, every particle adjusts its velocity based on three factors. First, there is inertia: the particle wants to keep moving in the direction it was already going. Second, there is cognitive attraction: the particle is pulled toward the best position it has personally found. Third, there is social attraction: the particle is pulled toward the best position found by any particle in the swarm.\nThese three influences are combined with random weights to determine each particle’s new velocity and hence its new position. The randomness prevents the swarm from converging too quickly and maintains exploration.\nThe beauty of PSO is its simplicity and the intuitive way it balances exploration and exploitation. When the swarm is spread out and exploring, the social component draws particles toward promising regions discovered by others. As the swarm converges on a good region, the cognitive component helps individual particles fine-tune their positions.\nPSO typically requires less tuning than genetic algorithms and often converges faster. However, it can struggle with multimodal problems where there are many distinct local optima, as the strong social attraction can cause premature convergence.\n\n\n10.8.4 Simulated Annealing: Controlled Randomness\nSimulated Annealing draws its inspiration from metallurgy, specifically the process of annealing metals. When you heat metal and then cool it slowly, the atoms settle into a low-energy crystalline structure. Cool it too quickly and you get a brittle, higher-energy configuration.\nIn optimization, we maintain a single candidate solution and a temperature parameter. At each iteration, we propose a random modification to the current solution. If this modification improves the objective, we always accept it. Here is the key insight: if the modification makes the objective worse, we sometimes accept it anyway, with a probability that depends on how much worse it is and the current temperature.\nEarly in the search, the temperature is high, and we accept many uphill moves. This allows extensive exploration of the solution space. As the search progresses, we gradually reduce the temperature according to an annealing schedule. Lower temperatures mean fewer uphill moves are accepted, and the search becomes increasingly greedy, converging toward a local optimum.\nThe acceptance of uphill moves is what allows simulated annealing to escape local minima. If we are stuck in a poor valley, we can climb out with some probability and discover better regions. The cooling schedule controls the balance between exploration and exploitation.\nSimulated annealing is particularly elegant from a theoretical perspective. Under certain conditions on the cooling schedule, it can be proven that simulated annealing will find the global optimum with probability approaching one as the number of iterations approaches infinity. Of course, in practice, we cannot run infinitely many iterations, and the quality of the solution depends on choosing a good cooling schedule.\n\n\n10.8.5 Strengths and Ideal Applications\nThe primary strength of stochastic methods is their ability to handle multimodal problems where many local optima exist. Because these methods do not rely on local gradient information and incorporate randomness, they can escape poor local minima and discover globally good solutions.\nStochastic methods are also remarkably general. They make few assumptions about the objective function. It does not need to be smooth, differentiable, or even continuous. This makes them applicable to black-box optimization problems where the objective is the output of a complex simulation or even a physical experiment.\nAnother advantage is conceptual simplicity. Implementing a basic genetic algorithm or PSO requires no calculus and can be done in a few dozen lines of code. This makes them accessible and easy to get started with.\nThese methods are ideal when the objective function is non-smooth, discontinuous, or noisy, when you suspect many local minima exist and want to find a globally good solution, when gradient information is unavailable or prohibitively expensive to compute, and when you can afford to evaluate the objective function many thousands of times.\n\n\n10.8.6 Limitations and Practical Challenges\nThe most significant limitation of stochastic methods is their computational cost. These algorithms require many objective function evaluations to converge. Genetic algorithms might need tens of thousands of function evaluations, compared to perhaps hundreds for gradient-based methods. When each evaluation requires a full simulation of the robot completing the track, this can translate to prohibitive run times.\nStochastic methods also provide limited information about solution quality. Unlike gradient-based methods that can compute the Hessian to understand the curvature of the solution and estimate confidence intervals, stochastic methods simply report the best solution found. You cannot be certain whether a better solution might exist that the search missed.\nTuning stochastic algorithms requires expertise. Genetic algorithms have parameters for population size, mutation rate, and crossover probability. PSO has inertia weights and attraction coefficients. Simulated annealing has a cooling schedule. These parameters significantly affect performance, and good values are problem-dependent and often found through trial and error.\nFinally, stochastic methods scale poorly to very high-dimensional problems. As the dimension increases, the solution space grows exponentially, and random search becomes increasingly inefficient. While methods like genetic algorithms can handle dozens of variables reasonably well, problems with hundreds of variables typically require more structured approaches.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimization Methods for Line Follower Simulation</span>"
    ]
  },
  {
    "objectID": "optLineFollower1.html#method-8-reinforcement-learning",
    "href": "optLineFollower1.html#method-8-reinforcement-learning",
    "title": "10  Optimization Methods for Line Follower Simulation",
    "section": "10.9 Method 8: Reinforcement Learning",
    "text": "10.9 Method 8: Reinforcement Learning\n\n10.9.1 The Core Concept\nReinforcement Learning represents a profoundly different paradigm for optimization that comes from the field of artificial intelligence and machine learning. Rather than explicitly optimizing over control parameters or trajectories, RL frames the problem as learning a control policy through interaction with the environment. The key idea is that an agent, our robot, learns to make good decisions by trying actions, observing the consequences, and gradually improving its strategy based on rewards and penalties it receives.\nTo understand RL, imagine teaching a dog a trick. You do not give the dog a mathematical formula for optimal behavior. Instead, the dog tries different actions, and you reward it when it does something right and perhaps give a mild correction when it does something wrong. Over many repetitions, the dog learns which actions lead to rewards and develops a policy for how to behave. This is precisely the essence of reinforcement learning, scaled up and made rigorous with mathematical theory and computational algorithms.\n\n\n10.9.2 The Components of Reinforcement Learning\nA reinforcement learning problem consists of several key elements that work together to enable learning. The agent is the decision-maker, our robot in this case. The environment is everything the agent interacts with, including the track, the physics simulation, and the sensor readings. The state represents the current situation, such as the robot’s position, velocity, and orientation, along with sensor readings indicating where the line is.\nActions are the choices available to the agent at each moment. For our robot, actions might be discrete choices like “turn left,” “go straight,” or “turn right,” or continuous values like specific motor velocities. The agent selects actions based on its current policy, which is a mapping from states to actions.\nAfter taking an action, the environment transitions to a new state according to the physics of the robot and track. The agent also receives a reward signal that provides feedback on how good the action was. For a line follower, we might give a small positive reward for staying on the line, a large negative reward for going off track, and bonuses for making progress toward the goal.\nThe agent’s objective is to learn a policy that maximizes the cumulative reward over time. This is different from simply maximizing immediate reward, which might lead to shortsighted behavior. The agent must learn to consider the long-term consequences of its actions.\n\n\n10.9.3 Value Functions and the Bellman Equation\nCentral to most RL algorithms is the concept of a value function. The value of a state represents how good it is to be in that state, accounting for the expected future rewards if the agent follows its policy from that point onward. Similarly, the action-value function tells us how good it is to take a particular action in a particular state.\nThese value functions satisfy a fundamental recursive relationship called the Bellman equation. The value of a state equals the immediate reward you expect to receive plus the discounted value of the next state you will reach. This equation captures the idea that value can be computed backward through time: if you know the values of future states, you can compute the value of the current state.\nMany RL algorithms work by iteratively improving estimates of the value function. By learning which states are valuable, the agent can choose actions that lead to high-value states, thereby maximizing cumulative reward.\n\n\n10.9.4 Q-Learning and Deep Q-Networks\nQ-learning is one of the foundational algorithms in reinforcement learning. The Q-function, another name for the action-value function, maps state-action pairs to expected cumulative rewards. Q-learning learns this function through experience.\nThe algorithm works as follows. The agent maintains a table or function approximation of Q-values. When in state s, it chooses an action, perhaps the action with the highest Q-value with some probability, or a random action with some small probability to maintain exploration. After taking the action, the agent observes the reward and the new state. It then updates its Q-value estimate using a learning rule derived from the Bellman equation: the new Q-value is a weighted combination of the old estimate and a target value based on the observed reward plus the best Q-value in the next state.\nOver many episodes of interaction, these incremental updates cause the Q-values to converge toward the true optimal values. Once learned, the optimal policy is simply to take the action with the highest Q-value in each state.\nFor problems with large or continuous state spaces, tabular Q-learning is not feasible because we cannot maintain Q-values for every possible state. Deep Q-Networks address this by using a neural network to approximate the Q-function. The network takes the state as input and outputs Q-values for all possible actions. The network is trained by minimizing the difference between its predicted Q-values and target values computed from observed transitions.\n\n\n10.9.5 Policy Gradient Methods\nAn alternative to learning value functions is to directly optimize the policy itself. Policy gradient methods parameterize the policy as a function with adjustable parameters, such as the weights of a neural network, and use gradient ascent to maximize expected cumulative reward.\nThe key insight is that even though the reward is a complex function of the policy parameters involving stochastic dynamics and long horizons, we can estimate the gradient of expected reward with respect to policy parameters using sampled trajectories. The algorithm works by running multiple episodes with the current policy, observing the rewards received, and updating the policy parameters in directions that increase the probability of actions that led to high rewards.\nMethods like REINFORCE, Actor-Critic algorithms, and Proximal Policy Optimization are all policy gradient approaches with different strategies for stabilizing learning and improving sample efficiency. These methods have achieved remarkable success in complex control tasks, from robotics to game playing.\n\n\n10.9.6 Model-Based Reinforcement Learning\nAn important distinction in RL is between model-free and model-based methods. Model-free methods like Q-learning learn directly from experience without building an explicit model of the environment dynamics. Model-based methods learn a predictive model of how the environment responds to actions and use this model to plan or improve the policy.\nFor our line follower, a model-based approach might learn to predict the robot’s next state given its current state and control inputs. This learned model could then be used to simulate trajectories and plan actions, similar to how MPC uses an explicit model. The advantage is that learning from a model can be much more sample-efficient than learning purely from trial and error, since the model allows the agent to imagine and evaluate many possible futures without actually executing them.\n\n\n10.9.7 Strengths and Ideal Applications\nReinforcement learning has several unique strengths that make it compelling for certain types of problems. First, RL can learn from interaction without requiring an explicit model of the system dynamics. This is valuable when accurate modeling is difficult but a simulator or real system is available for experimentation.\nSecond, RL is highly general and can handle problems with complex state spaces, partial observability, and stochastic dynamics. The framework naturally accommodates situations where the best action depends on subtle patterns in the state that might be difficult to hand-engineer.\nThird, once a policy is learned, executing it can be very fast. A neural network policy might require only a few milliseconds to compute an action, making it suitable for real-time control even with limited computational resources at deployment time.\nRL is particularly well-suited to problems where you have access to a simulator or can safely experiment in the real environment, where the optimal strategy is complex and difficult to hand-engineer, where you expect to deploy the learned controller many times so the upfront learning cost is amortized, and where adaptability is valuable since RL policies can be fine-tuned with additional experience.\n\n\n10.9.8 Limitations and Practical Challenges\nThe most significant limitation of reinforcement learning is sample inefficiency. RL algorithms typically require enormous amounts of experience to learn good policies, potentially millions of interactions with the environment. For our line follower, this could mean simulating millions of laps, which is computationally expensive.\nAnother challenge is the difficulty of specifying good reward functions. The reward signal provides the only feedback to the agent about what is desirable. If the reward function does not capture what you truly care about, the learned policy may exploit loopholes or develop unexpected behaviors. This is known as reward hacking. For instance, if we only reward forward progress, the robot might learn to go off track if it means reaching the finish line faster.\nRL can also suffer from instability during training. The learning process involves credit assignment across time, understanding which early actions led to later rewards, and this can lead to high variance in gradient estimates and unstable updates. Techniques like experience replay, target networks, and careful hyperparameter tuning are needed to stabilize training.\nFinally, most RL methods provide no guarantees about the quality of the learned policy or how close it is to optimal. Unlike optimization methods that can compute bounds or gradients, RL is more of a black box where you evaluate the learned policy and hope it works well.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimization Methods for Line Follower Simulation</span>"
    ]
  },
  {
    "objectID": "optLineFollower1.html#synthesis-choosing-the-right-method",
    "href": "optLineFollower1.html#synthesis-choosing-the-right-method",
    "title": "10  Optimization Methods for Line Follower Simulation",
    "section": "10.10 Synthesis: Choosing the Right Method",
    "text": "10.10 Synthesis: Choosing the Right Method\nHaving explored eight different approaches to optimization, you might feel overwhelmed by the choices. How do you decide which method to use for a given problem? The truth is that there is no single best method for all situations. Each approach has its niche where it excels and scenarios where it struggles. Let us synthesize what we have learned into practical guidance for method selection.\n\n10.10.1 The Nature of Your Problem\nThe first consideration is the fundamental nature of your optimization problem. If you are working with simple, well-understood geometric features like straight lines and circular curves, analytical solutions are unbeatable. They are fast, provably optimal, and provide deep insight. Start here whenever possible. The analytical approach forms the foundation of our artifact-based optimization strategy, handling the majority of track segments with minimal computation.\nWhen your problem has complex geometry that does not fit standard templates but remains smooth and differentiable, gradient-based methods are your best bet. L-BFGS is particularly powerful for problems with dozens to hundreds of variables, offering rapid convergence with relatively few function evaluations. If you can compute or approximate gradients efficiently, perhaps through automatic differentiation, this is often the most efficient route to a high-quality local optimum.\nFor problems involving dynamic systems where you need to compute optimal trajectories while respecting complex physics and constraints, Direct Collocation and shooting methods shine. If your dynamics are stable and you have a good simulator, shooting methods offer conceptual simplicity. If you need more robustness or are dealing with longer horizons, Direct Collocation’s ability to handle constraints throughout the trajectory makes it the stronger choice.\nWhen real-time control with constraints is essential, Model Predictive Control is often the method of choice. MPC is particularly valuable when you need to handle changing conditions, unexpected disturbances, or preview information about upcoming track features. The ability to replan continuously based on new measurements provides robustness that open-loop trajectory optimization cannot match.\nIf your problem has many local minima and you need to search globally, or if the objective function is non-smooth or involves discrete choices, stochastic methods become necessary. Among these, Particle Swarm Optimization typically offers the best balance of performance and ease of use. Genetic Algorithms are more robust for highly multimodal problems but at greater computational cost. Simulated Annealing is elegant and has theoretical guarantees but requires careful tuning of the cooling schedule.\nWhen you want to learn a control policy that adapts to varying conditions and you have access to extensive simulation or safe real-world experimentation, Reinforcement Learning opens up possibilities that other methods cannot easily achieve. RL is particularly compelling when the optimal strategy is complex and depends on subtle state information that is difficult to hand-engineer.\n\n\n10.10.2 Computational Resources and Time Constraints\nYour available computational resources significantly influence method selection. If you need an answer in milliseconds, analytical solutions or pre-computed lookup tables are essential. If you have seconds, gradient-based local optimization is feasible. If you can afford minutes to hours, global stochastic methods or Direct Collocation become options. If you have days or weeks for offline learning, Reinforcement Learning is viable.\nFor real-time control running on embedded hardware like our Arduino, the story is different. The optimization must happen offline, and the resulting controller must be fast to evaluate online. This favors methods that produce simple control laws: analytical formulas, pre-computed gains from gradient optimization, or lightweight neural network policies from RL.\n\n\n10.10.3 Model Availability and Accuracy\nThe accuracy and availability of a dynamic model is crucial. Methods like MPC, shooting, and Direct Collocation require an explicit model of the system dynamics. If you have a high-fidelity physics simulation, these methods can leverage it powerfully. If your model is approximate or uncertain, model-free approaches like RL might be more appropriate since they learn from experience rather than relying on model predictions.\nGradient-based methods also benefit from smooth, accurate models since they compute local linearizations or second-order approximations. If your system has discontinuities, such as stick-slip friction or mode switches, gradient-based methods may struggle, and stochastic approaches or RL become more attractive.\n\n\n10.10.4 Exploration vs. Exploitation Trade-offs\nDifferent methods handle the exploration-exploitation trade-off differently. Gradient-based methods exploit local gradient information intensively but explore only along the gradient directions. They are efficient in exploitation but limited in exploration.\nStochastic methods explicitly balance exploration and exploitation through their randomized search mechanisms. Population-based methods like GA and PSO explore multiple regions simultaneously, while methods like simulated annealing use temperature to control the exploration-exploitation balance over time.\nReinforcement learning must carefully balance exploration and exploitation through its action selection strategy. Too much exploitation and the agent never discovers better strategies. Too much exploration and learning is slow. Techniques like epsilon-greedy policies, entropy bonuses, and curiosity-driven exploration help manage this trade-off.\n\n\n10.10.5 Interpretability and Trust\nFor safety-critical applications or systems that require regulatory approval, interpretability matters. Analytical solutions are maximally interpretable; you understand exactly why the solution is optimal based on physical principles. Gradient-based optimization provides some interpretability through sensitivity analysis and the gradient itself.\nMethods like genetic algorithms and deep reinforcement learning produce solutions that can be opaque. A neural network policy may work well but be difficult to analyze or explain. This is not necessarily a drawback for all applications, but it is a consideration when trust and transparency are important.\n\n\n10.10.6 Hybrid and Hierarchical Approaches\nThe most sophisticated optimization systems often combine multiple methods in a hierarchical or hybrid architecture. This is exactly what our artifact-based optimization strategy does: it uses analytical solutions where possible, gradient-based optimization for transitions, and reserves stochastic or RL methods for complex cases.\nAnother powerful hybrid approach is to use a fast global method like PSO to find a good initial guess and then refine it with a local gradient-based method. This combines the global search capability of stochastic methods with the local convergence speed of gradient methods.\nSimilarly, you might use MPC for real-time control but optimize the MPC tuning parameters offline using any of the other methods. Or you might use RL to learn a controller and then use Direct Collocation to analyze what the learned controller is doing and understand its behavior better.\n\n\n10.10.7 Practical Recommendations\nFor the line follower optimization problem specifically, here is a recommended progression. Start with analytical solutions for all standard track features: straight lines, circular curves, and common transitions. These form the backbone of your optimization and should handle perhaps eighty percent of your track with zero computational cost.\nFor transition velocities between standard features, use gradient-based optimization with finite differences. The problem is low-dimensional, typically ten to twenty variables, making it feasible to compute gradients numerically. L-BFGS will converge quickly, usually in tens of iterations.\nFor unusual track geometries that do not fit the standard library, start with Direct Collocation if the geometry is smooth. The ability to handle constraints makes it robust, and modern NLP solvers are efficient enough for moderate-sized problems.\nIf you discover that Direct Collocation gets stuck in poor local minima for certain track sections, use Particle Swarm Optimization to find better initial guesses for Direct Collocation. PSO can quickly explore the space and identify promising regions, then Direct Collocation refines the solution.\nConsider Reinforcement Learning as an advanced option if you want a learned controller that can adapt to variations in track conditions, robot parameters, or disturbances. The upfront computational cost is high, but the resulting policy can be very fast to evaluate and robust to variations.\nModel Predictive Control is valuable if you want to deploy the system in scenarios where real-time replanning is important, perhaps because the track has moving obstacles or the robot parameters change during operation. MPC can use the offline-optimized trajectories as references and adjust in real-time to maintain optimal performance.\n\n\n10.10.8 A Final Perspective\nOptimization is both an art and a science. The science lies in understanding the mathematical properties and theoretical guarantees of different methods. The art lies in choosing the right method for your specific problem, tuning it effectively, and knowing when to combine multiple approaches.\nAs you work with optimization methods, you will develop intuition about which approaches work well for which problems. You will learn to recognize the signs that a method is struggling: gradient-based optimization oscillating wildly suggests a poorly scaled problem or bad step size; stochastic methods converging to different solutions on different runs suggests multiple local minima; MPC becoming unstable suggests model inaccuracy or inappropriate tuning.\nThe field of optimization is vast and continues to evolve. New methods are developed, and existing methods are refined and better understood. The methods we have explored here represent the current state of the art, but they are not the end of the story. As computational power increases and new algorithmic insights emerge, the boundaries of what is possible continue to expand.\nThe most important lesson is this: optimization is a tool to help you achieve your goals, not an end in itself. Always keep in mind what you are trying to accomplish: a line follower that completes the track quickly and reliably. Sometimes a simple method that gives a good-enough solution quickly is more valuable than a sophisticated method that finds a slightly better solution after hours of computation. Other times, investing in a complex optimization is justified by the improvements it enables.\nUnderstanding the landscape of optimization methods empowers you to make informed choices, combine techniques creatively, and solve problems that might seem intractable with any single method alone. This knowledge is a foundation upon which you can build increasingly sophisticated systems that push the boundaries of what autonomous robots can achieve.",
    "crumbs": [
      "Line Follower Simulator",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimization Methods for Line Follower Simulation</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Arduino. 2024. “Arduino Nano (@ArduinoNano).” 2024. https://docs.arduino.cc/hardware/nano/.",
    "crumbs": [
      "References"
    ]
  }
]